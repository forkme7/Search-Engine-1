dataset = "cs225topic"
query-path = "../queries.txt"
indexer-ram-budget = 1024
inverted-index = "cs225topic-inv"
corpus = "line.toml"
end-exceptions = "../data/sentence-boundaries/sentence-end-exceptions.txt"
start-exceptions = "../data/sentence-boundaries/sentence-start-exceptions.txt"
forward-index = "cs225topic-fwd"
stop-words = "../data/lemur-stopwords.txt"
punctuation = "../data/sentence-boundaries/sentence-punctuation.txt"
function-words = "../data/function-words.txt"
query-judgements = "../data/ceeaus-qrels.txt"
prefix = "../data/"
libsvm-modules = "../deps/libsvm-modules/"
[language-model]
	binary-file-prefix = "english-sentences-"
	arpa-file = "../data/english-sentences.arpa"
[features]
	features-per-class = 20
	prefix = "features"
	method = "info-gain"
[parser]
	train-sections = [2, 21]
	section-size = 99
	test-sections = [23, 23]
	dev-sections = [22, 22]
	corpus = "wsj"
	treebank = "penn-treebank"
	prefix = "parser"
[sequence]
	train-sections = [0, 18]
	section-size = 99
	test-sections = [22, 24]
	dev-sections = [19, 21]
	corpus = "wsj"
	treebank = "penn-treebank"
	prefix = "perceptron-tagger"
[lda]
	model-prefix = "lda-model"
	beta = 1.00000
	alpha = 1.00000
	topics = 4
	max-iters = 1000
	inference = "gibbs"
[crf]
	train-sections = [0, 18]
	section-size = 99
	test-sections = [22, 24]
	dev-sections = [19, 21]
	corpus = "wsj"
	treebank = "penn-treebank"
	prefix = "crf"
[ranker]
	k3 = 500
	b = 0.750000
	k1 = 1.20000
	method = "bm25"
[diff]
	substitute-penalty = 0.00000
	remove-penalty = 0.00000
	insert-penalty = 0.00000
	dataset = "20newsgroups"
	base-penalty = 0.00000
	max-edits = 3
	n-value = 3
	prefix = "../data"
[[analyzers]]
	filter = "default-chain"
	ngram = 1
	method = "ngram-word"
[classifier]
	k = 10
	method = "knn"
	[classifier.ranker]
		method = "bm25"
