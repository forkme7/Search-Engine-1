Okay welcome to systems programming so let's get started let's write our first c program that makes use of a system call i'll do an example and then I'll let you play as well so uh here's a little virtual machine i've got up and running and i can write a little c file here so what we're going to do is make use of a system call called write so let's try this we'll say okay write and then i need to give it a file descriptor more about that in a moment a little message like hello and then the number of characters or bytes that i actually want to send here so h e l l o that's five bytes we're going to send so let's try compiling this and once that's going we'll see that whoops we've got a little bit of a problem here that write was not declared before okay so the c compiler here is warning us that we're trying to call a function called write which hasn't yet been declared so we could declare it now i happen to know for example that the write signature looks a little something like this it takes um, it's called write  it takes a file descriptor which is going to be an integer it takes a pointer to a character and it takes another integer which is the number of characters to write so it looks a little bit like that in fact it takes a void pointer which means point to it without any particular type so i could attempt to compile this for example see if this works and oh ho ho if we look at the left hand side we can see we managed to compile a program called program here and when we ran it we got hello alright so let's do a little better then that though rather than me having to manually write the declaration in here these are already included inside an existing file which I get for free it's actually unistd.h okay so let's tell the preprocessor to read in the contents of the file go in and find a file named unistd.h and include all the text that is in that file okay so now when we run this we'll compile it and run it and great it prints out hello if i wanted to print out hello with a new line let's increment this to six and now i've got a program called Hello okay great and of course i could make my program print out hello world and do it on two different lines alright so uh that's my program working now it's time for you to play you create which uses a system call write to write a little message on the two lines see you in the next video after you've said hello to the world bye
so let's talk more about that file descriptor I'm gonna make my program be a little bit more useful by printing out Hello World" a few times so for example, I have a variable 'count' here and a little for-loop Start with count equal to five, while count is greater than zero each time around the loop we're going to decrement 'count' In C, there is no boolean type. instead, if I've got an integer value which is nonzero, that is treated as a true value So, I could actually write this more tersely just by saying hey, count!" meaning is count a non-zero value and if you compare two things, you'll learn that with an integer value of either 0 or 1 to mean for example if they are either the same or different so, we're going to print out hello world" 5 times I want to show you just a little idea here that actually I've got two file descriptors which are valid when my program starts. And they're called 1 and 2. Why might it be useful to have two output streams? well, you can imagine we have a program that is calculating something for example it's thinking of something to say or it's going to write to a file but we may also want to display some error messages back to the user or we might want to print some progress information the first output stream identified by the number '1' is the regular output, standard output The second one is reserved for error messages. Let's, for example, use this. Instead of error messages, we'll put a little dot to see this We'll run this and we should (if we got everything correct) see Hello" and...lib lib lib lib Now, why do we see .lib", because we said "hey, I'm going to give you a pointer and I want you to use that pointer and take the next 6 bytes from it which is the next  six character So we just got whatever happened to be in memory after our dot. So, we only wanted to do the dot Change that and run it again And great, we've got Hello and dot Hello dot Hello So, right now, both the output and the standard error are going to different places we could actually change that over here in the console before we start the program Our terminal can actually control where the output goes So, for example, I might say, I want to take the standard output and put that into a file. So, output.txt" So now, if I run this before the program starts, I'm going to redirect it's output into this new file Okay, so what we see on the console output is anything written to standard error The standard output is inside output.txt To prove it, let me have a look at that file. Let me cat that file So, output.txt And here it is! It says hello, hello, hello, hello" Now, rather than writing 1 and 2 over here, perhaps we should actually have some constants which signify what those values actually mean so we could say start define things to say have a constant here, I'll call it say STDOUT_FILENO 1" And I'll say define STDERRFILENO 2 so anytime you do hash define, you're talking to the preprocessor to say hey, in the future, parts of this file, if you come across this character sequence, then replace it (in this case) with either a 1 or a 2 depending on what it is" We can compile this, except I've got a surprise for you which is that these particular macros are already defined inside unistd.h So, I don't actually need to define them here in my program. So that's my little program. You see it's got a return value of zero. Which is a convention for being correct (no errors) But it's up to us. We could choose a different value, for example we could choose the value 42. And, I don't see an output value, but I can find out what the last exit value was of the last process Let me print it out It happens to be inside special variables so I could say Hello terminal value of this dollar question mark." which means give me the exit value (or the exit status) of the last command run. So there's our forty-two. Okay so, we've covered quite a bit of ground. We've talked about how in C, any non-zero integer is considered true" and zero is considered false" And, we've talked about these two different output streams. Now it's your turn to play with this. After that, let's have a go at creating some new files directly from C by making system calls So, now it's your turn. Have fun playing! Bye.
Welcome so let's start creating some files for that we can use the system call open() and for open we need to say whether we want to append to an existing file, create a brand new file, and we need to give it a filename For example, I might have a file name called output.txt" so the open call takes 2 or 3 arguments. the second argument will be exactly what we want to do so in this case we want to say create a brand new file and truncate it back to 0 if it doesn't exist so, I want to truncate as well if we are creating a new file we better say who can read this file and who can write to this file and who can execute this file so we are going to have to say something about the mode flags  who is allowed to do what finally this call is going to give us back an integer, a file descriptor just like we've seen so far with file number 1 and file number 2 so lets store that inside a little variable ok, so now I better actually find out what the correct syntax is and the correct arguments are in order to create a file so lets go and look that up and that we'll find inside the manual And, if, for example, I type man open" on a command line on a real linux machine. it doesn't quite work yet in my small virtual one. we didn't have enough memory to include all the manual pages yet but heres a linux manual page I found on the web for the open() and you'll see here's the function signature here where we're going to pass in an integer for the flags and the mode type so, I'm going to look up now the flags I need to open and create a new file I don't want to do append() I want to use create" and I want to truncate it as well let's include O_CREAT" here. I'm going to say "O_CREAT" which is a constant and I'm going to bitwise OR it with the flag to say "truncate" so let's look that up as well alright and i want to say when i open it that i am going to open it for say reading and writing so let us grab that as well so that is the first thing now we need to do the mode Let's write this as a variable. and there is actually a typedef it is essentially an integer but it is wrapped up in this type here called mode mode_t and we'll say that with our file we want to be fairly private and only the owner of the file can access it Let's go back up and find those flags, where are you? Here we go. We'll say that the user has read and write permission We'll copy the read one and we'll have write permission as well. But no one else in my linux system will be allowed to read it and write it. So that's the permissions we want What can we do with this? Well let's write something out to this file. We will write a little message Great!" and a newline so how many characters is that? I've got one, two, three, four, five, six, and a new line so that's seven characters" then we'll close this file descriptor meaning we don't want to use this descriptor anymore that will ensure as well that all of the bytes that we send to the file stream have been saved We're not doing any error checking right now, we're just trying to write the smallest possible program to create a file and send something to it let's run this and see what we get we'll run into an error which is: we haven't defined what this mode_t is what we forgot to do, was to do the includes the good news is that the man pages tell us which includes we need to put at the top of our program so let's grab those and insert them in here i will just get the formatting correct and, run it again Right so our program ran and it's still printing Hello" to standard out and dot to standard error but hopefully, it also secretly created another file let's have a look at that file I can do ls" and see if anything exists starting with "out" yes we've got output.txt. great! let's look at the contents of that file and it says Great!" Fantastic Right so now it's your turn to play: create a file and see if you can send some bytes to that file. so you'll be using open(), write(), and close(). Bye.
Hello, suppose we want to actually print out some integer values write() doesn't give us that fuctionality write() is the low level call that we make to the operating system to say look, here's a pointer to some memory and please take so many bytes from that memory and send it out to a file" or, possibly, another device if we want to change a bit pattern into a sequence of characters because we want to read, say, one-seven for the value seventeen that's not something that the system does instead, we've got some C standard library calls that we can call that do this for us and they will wrap the call to write() so as an example, let's try printing something out we can say printf my value is" and I can say %d" this means that the next argument I give in printf() better be an integer value so the bit pattern we pass to printf() will be treated as an integer to be displayed so let's have a little variable called result and I can say result is sixty five if I attempt to run this, we're using printf(), we haven't declared it beforehand so we get a warning to say oh, you're just using it." and, what we should've done is actually declare the function signature of printf() and that I know from looking at the man pages is inside stdio.h if you're coming from a cpp background, there's no IO streams we dont have operator overloading. instead, let's use printf() so we've got my value is 65" and, you'll see that actually this was printed out after the hello hello hello hello here's why: printf() has a buffer. the C libraries have a buffer so it's only going to call write() when that buffer is full or if we explicitly tell it to or if we finish a line so let's put a newline in here and run it again this time, we've compiled it, and we should see that my value is 65" appear before my hellos so this time, because we sent a new line, printf() will be making that call to write() to send its buffer out to standard out so now we can actually print out the value of our file descriptor let's do that. after we've opened our file, I'll send fildes is" and, we will print out fildes. and, let's get rid of the first one and let's flush our little buffer by sending in a newline and we'll see that our value is three so, we've opened up a file descriptor who's value is three in fact, that is expected by specification because if we successfully open a file, we'll get back the lowest unused integer (the lowest unused file descriptor) as one and two are already being used, we get back three so just for fun, let's actually close one of the existing file descriptors before we do the open() so let's close standard error I'm sorry, we'll close standard out and, we won't close our own file descriptor until the very end of the program here so I'm going to move that line down to here great, so, let's run this so, what did we do? we opened a file descriptor and now if we look at the output of the program, you'll see we're only getting our dots printed out on standard error why is that? what happened to our standard output? well, we better check out file output.text and you'll see that everything printed to standard out has been sent to our file why? because when we called open(), it gave us back a file descriptor for stream number one. and, that is the. that is where all the standard output is going to go so, all future output is being sent to our file this is a neat way if you'd like to do logging and we've just changed our program so that all future output goes to output.text now what if we've got a problem with open() ? right now, our code doesn't check for any error and, a better program would actually check the return values of our different calls for example, it could be that open() could fail. suppose, for example, we gave it a bad file descriptor now so we can see what's going on, I'm not going to close standard out anymore. I'm just going to give it a bad file name now, our program compiles correctly of course but this time our file descriptor is negative one so, we should check that in fact, if we check the man page of open(), it's always a good idea to check the section called return value" and you'll see, it's specified here that we'll get back a negative one if an error occurred so the last thing we'll do today is let's capture that and quit if we get a bad error so, if fildes equals negative one a common error is to write equals instead of double equals for comparison and we want to quit here so we'll leave our program, so let's exit with a value to say: hey, we couldn't carry on" I could've returned zero but I wanted to show you an alternative way to quit a C program is to call exit and we'll print out an error so, something bad happened while calling open so, we'll use perror() let's run this and, I get some implicit problem here that we're calling exit(). I need to find the right #include to call for that. but, you'll see on the lefthand side that we've got open() failed, so that's the part of the error message that I supplied followed by a colon followed by no such file or directories so it's complaining that my file name is bad if I had included a dot here, this is also an invalid file name because a single dot corresponds to the current directory and, it's complaining that it can't open that because dot corresponds to a directory so now it's your turn to play. bye!
Hi, so C is designed to be a portable language in a sense that we could write a C compiler for many many different hardware architectures from small embedded machines to large mainframes so C does not specify a precise number of bits required for, say, and integer instead it specifies minimums that should be supported by the architecture let's have a look at that. let's see how we can find out how large or small of numbers we can store in different types and also how many bytes each different type is  and even further, what is a byte? so let's start with our integers I could say hello but what's the largest value I can store inside my integer type? fortunately, there's some macros, some constants, defined inside limits.h let's find out what these are the int min and max is going to be %d and %d and INT_MIN and INT_MAX so, we'll print that out. I'll get rid of my unnecessary variable here let's run that and we see that on this particular machine, that an integer can represent numbers from roughly minus 2 billion to plus 2 billion a very wide range of numbers C promises that we'll be able to store the numbers between minus 32768 and plus 32767 in other words, an integer will be at least 16 bits what else do we have? how about a character? well, here's a surprising thing, a character is one byte so what do we mean by byte? surely we mean 8 bits? no. though we often say a byte means 8 bits in modern parlance, it doesn't have to be true and in fact, C is very careful to say that a byte does not mean 8 bits it means at least 8 bits our character, then, is at least 8 bits so why this distinction? well, in being portable, C needs to be able to read and write every bit inside memory and each bit inside each memory should only live inside one addressable memory location and, it could be that architecture have very different numbers of bits it can read or write for example, an early PDP machine had a 36 bit wide addressable memory so, C does not attempt to say it's going to be exactly 8 bits so how do we find out how many bits are actually in a character? well, again, the limits.h includes a useful constants here a character is %d bytes let's go and see what that is so CHAR_BITS and we'll print that out on this architecture, a character is 8 bits that's typical on modern machines so what if I wanted to know the actual number of bytes in different types? for that, we have something called sizeof we can give it a type and it will tell us how many bytes (or if you prefer, how many characters) are required to hold that particular kind so for example, let's find out how big an integer is on this machine perhaps you can guess the answer already so, sizeof int is %d and we'll have a newline as well is it any surprise that the size of an integer on this particular machine happens to be 4 bytes and that's not surprising because we need thirty two bits to represent all numbers between minus two billion and plus two billion there are other integer types you'll see things like short (which is generally shorter than an int), long (which is generally longer), long long (which is even longer, still) and compilers even occasionally provide their own custom types as well notice as well that these types are signed so we can represent negative numbers and plus numbers C also provides the idea of being able to say that we can have an unsigned version so, for example, I can have an unsigned int now there is no signed bit that is included in the bitwise representation so that's great if you wanted to represent all the numbers between zero and 4 billion on this particular machine the character type can actually be signed or unsigned depending on the particular implementation of the C language for this particular architecture so that's enough for now in the next video, we will talk about pointers now it's time for you to play and learn a little bit about the basic C primitives. Bye!
Now let's talk about pointers and arrays how might I make an array of integers? let's say I had some data and I did this well, on this particular architecture we just found out that an integer is four bytes so I've now got thirty two bytes of storage and in fact, it's going to be thirty two bytes on the stack so what do I have here? when I say data square brackets eight, I'm going to get back four times eight, thirty two bytes all together all contiguous in memory and in fact, data is going to point to  the very first four bytes so I've got four bytes and then four bytes and then four bytes and then four bytes and so on let's have a look at that so, if I say printf data is at and this time do %p, that means treat data as and print it out as an address so we'll print this out and we see we've got a value here in memory that data points to the very first element let's do something a little bit surprising here let's add one to data and print that out so, data plus one and we'll do data plus two and so on so, if we look over here at our output, we'll see that each time we add one, our address in hexadecimal is going up by four each time so we've got 9d40, 9d44, 9d48 here's why when you add an integer to an address pointer C knows the type of that pointer so in this case, we're pointing at integers so each time we add one, we actually want to progress to the next integer stored in memory and as each integer takes four bytes, that's why our address is going up by four each time so how could I use this? well, one way is to use asterisk which means use the address so, for example, I can say data the parenthesis are not strictly necessary but we'll use them in a moment and let's say store the value a hundred in there what about if I wanted to store some value at the next entry? ok so, hundred, hundred one so now I've stored the value a hundred that integer pattern into the first four bytes and the integer pattern for a hundred and one in the next four bytes and I guess you could figure out what this would do as well the asterisks means use the pointer follow the pointer dereference the pointer in other word, we've got an expression which is a memory address, now I want to use it now I actually want to use that pattern that bitwise pattern to actually read or write some memory so that's what the asterisk does means actually okay it's time to go and talk to memory this is so useful with arrays there is an alternative syntax which is to use the square brackets so for example I could have written the following which means take my address pointer add two to it and use that address for the array so these last two lines are the same in fact, here's a little secret about C that I could actually swap these around so we could also write this in this slightly crazy way so this is crazy but actually two square bracket data would evaluate to the same thing so that's something to confuse your non-C friends with that's enough with me playing with integer pointers now, it's your turn. Bye!
so what about strings in c? what if I said hello" how is this represented? well clearly it's made up of characters and I've got five characters to display h e l l o, but actually C strings contain an extra character at the end a zero value or null character to say hey this is the end of the string" so this is going to take six bytes of storage let's see if we can prove that we'll say printf() and Size of hello is %d" and we'll have a little expression here to say what is the sizeof() hello" and we'll print it out and you see that size of hello is 6 h e l l o that's five, plus an extra byte for the 0 to say that's the end so we can use sizeof() on constant strings we could also run through the string to actually find the 0 byte ourselves so let's do that let's have a pointer to a character I will initialize it to my string hello" which means pointer is initially pointing to h the first character I'll have a little count variable here and let's say while the pointer the value is not equal to 0" I want to do something lets increment the pointer lets move it onto the next character and let's increment our count as well so we can find out how many characters we have and then at the end we will say how many characters we found which are not the 0 byte so if our program works this should find five characters lets run it and i'll put in a new line at the end our little loop went around five times and all it did was increment count we could have made it of course print out each one of those letters we could also simplify our program a little bit because as you know any non-zero value is treated as true so let's remove that and say while star pointer and when we get to the null byte we will finish so just for fun lets change our program as well before we increment the pointer to print out the next characters my format string is just %c. and what character would I want? well the one pointed to by the pointer pointers to characters that  each character is exactly one byte so when we add one to our pointer, line ten here we are actually just going to add one to it because each character is exactly one byte so there's our program and it managed to print out exactly hello" do we need to write this every time that we want to find out the number of characters in a string? no! guess what there's a function called strlen() so instead of my little loop if I include string.h I've now got strlen() so let me check the two results instead I'll say len is strlen() and pass it a pointer to my character I'm tempted to use pointer but that would be a bad idea perhaps you can figure out why so Strlen returned" and we'll talk about how to fix my program in a moment so we'll run this strlen() returned 0 why? because by the time my loop finished I'd advanced that pointer on until it had reached that null byte so when we passed that to strlen() it immediately found the null byte now what we should do is evaluate our strlen() before we change our pointer the last thing we'll do today is make our program crash let's try and change our first character to be someting else like 'J' turn it into Jello so let's dereference that pointer and use it to push in a character I don't want to have a string, i actually want to have a character let's try that and see what happens I get a segmentation fault when I try to run that line here's why, different parts of my proccesses' memory are valid for reading or reading and writing the program code, the actual assembly, the actual instructions for the cpu, can only be read and my constants, such as this hello" can only be read and the hardware is sophisticated enough to know which parts of memory are read and which parts of memory are read/write and which parts of memory are invalid so that's why I get a segmentation fault if I try to change the constant memory alright time for you to play with character poitners, bye
So this video is about how to have an argument let's have a look inside some directories that we've got on our little system so if I type ls /bin you'll see here's a whole lot of programs that I can run from my terminal window and some of them you might recognize already including ls for list the contents of a directory (what we just did) cat to list the contents of a file and print it out and echo simply to echo back whatever we type so I can say echo Hello World and we also can used echo to print out the result of the exit value of the last program run how is it that these programs then can find out the parameters (the arguments) that we supply? when they are run? and the answer is that actually our main method can have two parameters here we have an integer (the number of arguments here) and also an array of character pointers called argv for value so let's actually print out some of these things so we'll say printf and we'll have the argv, the very first entry, the zero-th index is this and we'll say argv of zero and we will also print out what the last thing points to so that's going to be argc so that's %p we'll have a new line or two alright, and change that argc so here's two surprising things first of all, the very first entry is actually the execution name of the program how we started the program here, our program is just called program" and secondly, there is actually one extra argument at the end and that points to the null string our pointer is null, it's zero so, let's now actually print out the other values we'll find out what the other values of argv is and we'll loop through and we'll print out all of those values so I'll have a little count. I'll start from 1 this time. because we don't want to print out the program name I can say: while count is less than argc, because I don't need the null pointer at the end and each time around the loop, increment count I'll print out the value of my count that's %d and print out its value as a string ok so that's going to be count and argv at index of count finally, let's put a new line in here here's my mistake: I should have said argc here for count ok, let's print it out when we start, argc is just 1. we've got just the program run it again but this time but this time have cat hat sat" and you'll see I've got three additional arguments if I had put that inside double quotes then the hat and sat would be one argument so you see that we can now send our arguments for example, I could write a little program that helps me add up some numbers and I need a simple way to turn a string of digits into an integer in other words, I want to go from ASCII to an integer so this is the simplest way of turning a string into an integer number but this function doesn't give us much error checking if it can't read it, it simply returns zero I'll talk about how we can do a better job using scanf in a different lecture so we'll add those up and we'll print the result. right so we've got a result of zero let's try running our program again with 10 20 30 and we see we get a result of 60 if I had put some non-numbers in here, I get the result ten because the string I've got here it's converted into a zero alright, that's enough from me. now it's time for you to play. bye!
hi so this video is about the environment so in addition to being able to set arguments to our little programs each program also has access to environment variables let's have a look at those now so in my shell over here so my terminal window if i type for example set i can see a list of environment variables so these can be used by the shell and any other programs that we start to help configure their behavior for example we see down here that I am running as superuser as the root on this little system here we can also see that my home directory is in slash root so that's where kind of root's files will be stored great so how will i get access to that in my c programs well there's two ways first of all there's a variable called environ which if we are running in an older posix environment we have to specifically declare  in fact we say look there is somewhere in there is already a variable declared called environ and we just need access to it so that's what the extern keyword means we are not trying to say give me additional storage for this rather that the storage for this environment variable has already been made and we just want to be able to reference it inside our program so if i use that you'll see that it's actually a character pointer pointer in other words i'm going to dereference it twice the first time i dereference it i get a pointer and that pointer itself is going to point to character strings and i can keep moving along then to print out different environmental variables so if i had the same kind of pointer  i'll call it ptr and i initialize it to environ i could print out the very first one if i say let me print out a string and a new line and if I do star pointer we can follow that money if you like we can follow where that pointer points to so it points to the first entry in this array  so we can run this and we see i get the first environment variable which looks like a key or a name followed by an equal sign followed by its value so if i was to add one to the pointer then i move on to the next character pointer and i get the next entry so let's put that in a loop how can i do that well i can say while i might be tempted to write pointer but that's not going to be particularly useful instead i want to say whilst the thing that pointer is looking at is a non null value in other words whilst i have a valid pointer why? because i happen to know that this array has one extra entry at the end which is the null entry meaning that its got a pointer that points to nothing and let's also increment our pointer at the end great so we can run this and get a look at all of the entries in fact why don't we set a couple of entries here so export secret to be 123456 let's try that and run our program again this time when we run it the environmental variable secret is part of the environment of our running program if you already know the name of the environment variable that you wish to use you can get to it directly so we can also say hey give me the environment variable and give it a name for example secret and this will give me back a pointer to a character array oops i better call it secret let's print it out and quit so the secret is and we can call exit great i've got a little program that can print out secrets so now i can make my program check that the secret is set for example for example if I try to get an environmental variable that doesn't exist then my pointer is actually going to be nil let me show you that let me try to print out the value of secret as an integer so my secret pointer is pointing to nothing we didn't set that environmental variable yet so we for example i could say look if secret is null then i'm not going to let this program run i am just going to stop so we'll stop and let's now change it so that very secret is something like abc and when we run the program again this time you'll see that secret is a valid integer value so that's just an integer representation of the pointer and we got back at that memory location the contents of that environment variable ABC okay that's enough for me now it's time for you to play bye
let's talk about strings today first of all, these two things are very different I could have a pointer to hello world" or I could have an array of characters to hello world" though both ptr and array points to the first letters some things that are noteworthy here is first of all they have different sizes so let's look at the sizes of each of these, perhaps you can guess what the result is going to be so you'll see the size of the pointer is the number of bytes to actually hold the character pointer which as this is a 32-bit machine is four bytes the size of array is the total size required to hold the whole array so when this code runs it's actually going to copy the contents of that string literal hello world" into the new array object so in this case we need twelve bytes for that, eleven for hello world" plus a twelfth to hold the null character at the end the bit pattern zero to say okay we've reached the end of the string their sizes is very different, plus remember that because we've made additional memory on the stack we can change it so I can change it to jello world" for example let's start manipulating our string we'll do this on our array so we can actually make modifications to it how about we change all the 'l's to a different letter so we'll change and we'll pass the beggining of the array so let's pass in the array and afterwards we'll print what the array is so that's %s alright so I'll have my function called change down here and it takes a pointer to that memory so we don't need to return anything because we are actually going to be using the parameter to point to some memory that we are going to change what can we do with this? well let's have a little loop that says while(p) that says while p is non zero actually what we care about is whether p is pointing to memory that holds zero in other words, we've reached the end of the string we want to follow the pointer we want to dereference the pointer and for that we need the asterisk okay so what should we do with this. well we could change all of the letters for example we could blank it out we could say star p equals and it might be tempting to write an astericks here but that's not right because the asterisk means I've given the address of the asterisk so I'd be writing an asterisk into the address of the asterisk into that occasion if I run this I get a few warnings but it runs and it runs it for forever because my loops runs forever so let me ctrl-c that to break it this time change the loop so I add one to p each time so now I've got a very strange character because it's taken the lowest eight bits and copied that into my character instead let's change that to the actual bitwise pattern of my character now I've got something which can get rid of swear words by over writing them with asterisks or perhaps a password or something but we didn't want to do that for all the characters, we just wanted to do that for the l's so let's see if my p is, at when I look at that memory location, whether it's a lowercase l and as I said before because we are working with characters it is ok to compare them so note the use of double equals here okay so let's run that we have a couple of errors here for starters we're not using pointer so I can comment out that line I've got another problem here which is that change is implicitly declared that's because we haven't declared what the function signature of change() looks like let's do that now I'm going to say later on compiler, I expect to actually define a function and I'll give you the actual code to create this change method but for now here is what it's signature looks like it's called change, it takes a pointer to a character and it doesn't return anything so if I compile that now my warnings should go away great so I've got a function that can walk through I could have another function that finds letters as well so for example suppose we wanted to find the first o in this I could change this so that rather than changing the letters if the contents of p is an 'o', let's return p now I'm going to change my method signature and I'd better have a return value that returns something if I get to the very end so for example, it returns where p is we can now update my original code so that it finds the first 'o' and gives you back a pointer to that if I print that out hopefully you can guess what my program should do okay so it gave us back a string and it this time the pointer was half way through hello world" that's OK, our pointers don't care what they point to we know that strings will continue until we reach the null byte at the end so that's how we were able to print out hello world okay that's enough for me, time for you to play. bye!
Hello! Let's talk about automatic variables so here's my main method I've got two function calls f1 f2 and today I'm going to actually define them before my main method so I don't need to put in the additional declares in so let's have f1 here and f2...ok so now I've got a syntactically correct program but I want to talk about the variables that we might put inside these so if I create a variable like this to say hey I've got a value here, something I need to compute inside f1" or maybe I want to make an array so here's my array and I can initialize it to, say, f1f1" here we go then the lifetime of my array (this variable) is only for the lifetime of the function when I return from f1, then the variable goes out of scope which means the name array" doesn't mean anything anymore inside our program but secondly, the memory that we were using for the array is automatically free'd up it can be reused for other purposes in a moment by the rest of the program so isn't that fantastic that's why it's called an automatic variable so automatic variables are very easy to use they also come with a big warning sticker and that's this which is to be very wary of just how long they live for let's do a couple of things here first of all, let's make it so that we can actually see the pointer in memory where array is pointing to so, let's print that out inside our function here remember that the name of the array (when converted to address) gives us the very beginning of the array and, we'll do that for our second function too okay, so, f2 f2 just to prove that they're making different arrays okay, so we'll compile and run this and, when we run it, we see that both f1 and f2 both these functions the array is actually stored inside the same memory location isn't that fantastic. we didn't need any additional memory and that's because after we return from f1, any of those automatic variables are free'd so they are no longer needed so we can reuse that space internally, later we'll discover that a stack data structure is used to implement this and I can show a little bit of this by having a either a recursive function or we can make another function call these so for example, I could have a function called eg and, this calls f1 so now let's have a look in the case that I'm not using f2 anymore so that can go away instead, I've got a function called eg and that can say have its own space so, blah and maybe say a thousand and twenty four bytes here and then we call f1 again so let's run this now so, in the output, you'll see that f1 is printed twice and the second time it's because it's being called from our function eg and in this case, it's further down in the stack. it's in lower memory f948 as opposed to fd50 because it's being called from eg so, we'll see more about the stack in a moment later on. I just wanted to show you that they really are stored in different places finally, to reinforce this idea, let's make a little recursive function so, I can have something which takes an integer say I'll call it level" and if level is greater than zero, let's call ourselves again with a slightly reduced value and I can of course make that simpler by just saying if level" so if level is nonzero, then call it again and let's call it with say five okay, a semicolon would help each case as we go deeper and deeper into recursion, our array is getting lower and lower and lower in memory so we have all of these arrays created. all of these different activation records in different places inside our processes's memory so the last point we'll make, which is the most important, which is that it's very dangerous to return pointers to memory that is no longer valid for example, rather than returning nothing returning void, suppose we try to return a pointer to our array then though this code might compile, okay, I can get rid of level" now it's certainly not a valid program because the pointer we get back from f1 now points to stale memory that memory is no longer ours to control it will be used in a moment for other function calls so always be careful if you are returning a pointer to something. make sure that that memory is still valid and never return a pointer to an automatic variable that's it for me. time for you to play. bye!
welcome so let's talk about some options other than automatic variables so here's a little problem i've got so far in my main method i want to print out the current time  and i'm going to write my function called currenttime that returns a new string array i already know that i cannot make an array in here to hold the result say with two hundred and fifty because when I go to return from this function the array variable won't be pointing to memory that is valid any longer so here is two options i could make my array static so how do i do that just by the keyword static so for example if i were to just say okay i've got myself a static array out here outside of that method then my array lives forever or at least for the length of my process so that gets rid of the problem of having some space i cheated i said look just give me some space for the lifetime of my program here  so that's what static does i can also put this inside the function that doesn't change the lifetime of the variable it just changes the scoping so as always that means simply that now the variable name array can only be connected to that piece of memory inside my little method so it's just changing how the actual name of the variable is bound to the memory so that's one method but instead i want to talk about a completely different way which is to use malloc so you're going to come across malloc calloc and realloc today let's talk about malloc  which essentially means give me some bytes and i can say how many bytes i need and that storage space is found inside the program's heap so for example if I want one hundred and twenty eight bytes I would say malloc one hundred and twenty eight so this is going to give me a pointer to the very first byte so let's store that inside my little character pointer here and i'll say there is my result it is possible that malloc fails if it is unable to give me one hundred and twenty eight bytes it would give me back an invalid pointer pointed to null or pointed to nothing so i could say look if result is zero or null or if i wanted to be really terse I could say if not result in other words result is null then just return that null pointer i am not going to try and use it it's not a valid pointer otherwise let's put some things inside this and I could turn the current time and store it inside that array so let me use a function called strcpy to put in the current time which is two fifty one pm #include <string.h> let's run this and my program calls currenttime creates some memory and then returns it this is fantastic right i've now got a way to make long lived pieces of memory and put data inside them but with great opportunity comes great responsibility here  so what we should do is let our programs is with every malloc we should at some point free up that memory to say hey i've finished with it so the correct way to do this is to keep a pointer around so let's have a pointer down here and when i finished using that memory i can free it to say hey this memory is no longer being used this block of memory of one hundred and twenty eight bytes is no longer being used please put it back into the heap and maybe we will reuse that memory again for a future malloc so good programs will have one free for every malloc  in the next video i'll talk about some of the mistakes that we can make with heap allocation but now it's time for you to play with malloc  bye
hi welcome so we have got a little function so far called currenttime() that requests 128 bytes from the heap and then providing we get a non-null pointer back from malloc we will copy in the time 2:51 PM into that memory and then return a pointer to the first byte of that memory so that's our little currenttime we've been careful to make sure that if malloc fails, perhaps our program has used all of the heap memory then we don't try to use that null pointer but now let's actually make it so that it actually makes a call to find out what the current time is the current time is known by the system so it's time to make a system call and then we will format that using a c function called ctime() to actually give us a human readable version of the time both of these functions can be found inside the include time.h I've commented them up here so the first think we can do is call time so when you call time you can pass it a pointer to a time_t variable or you can say actuall I'm not going to give you anything and it will still give you back the time in its result so let's just use the result so here's the number of seconds since 1970 we'll store that inside our little variable called secondsSince1970 but I don't want that as a value, I just want to turn that into a string for that there's a function called ctime, this a library function. there are other functions that give greater control to the precise formatting but for this demo let's just use ctime() which has some reasonable formatting that most people can understand this will give us back a pointer to the time so the time in ASCII, in otherwords in letters, in readable time and then we can use that and copy that result into new memory, into our result so one problem with ctime() is that it uses static storage in other words it's great if you just want to call it once, and it will use it's static storage to give you back the time in a readable format but don't expect that to stay around because if you call ctime() again in the future it is going to overwrite those bytes and that's why our little function here called currenttime() is useful we are going to take that temporary result and put it into some memory that is ours to control so it can't be overwritten we need to pass in seconds since midnight except we've got a problem here it doesn't actually want the value, it wants a pointer to this variable, it wants to know where in memory this variable is for that I have to introduce some new syntax, which is the & when you see & it means that I don't want to know about the variable itself, but where it is stored in memory tell me the address of the variable we didn't need this for arrays because that's what the array name gives us automatically but for other items we can use the & to find out where it is stored in memory let's compile and run it and we find out that my little virtual machine thinks it's Jan 1 2014 not very accurate, we should probably change it, but it did print out what it thinks the current time I promised you that I'd mention a few more mistakes that we can make with heap memory one mistake we can make is to double free the same pointer this can lead to all sorts of horrendous problems because when you tell the heap that you've freed with some memory it might actually use that memory for it's own book keeping so it knows that the particular block of memory is free if you free it again it can confuse the book keeping, the pointers that the heap is using itself once we've freed some memory, dont free it by accident a second time! another common mistake in C programs is to continue using memory after we've freed it we shouldn't consider that memory to be valid anymore perhaps it's going to be reused by some other part of the program that is about to call malloc() and certainly we shouldn't expect anything that we've previously stored in there to be valid once we've freed it don't try to use the pointer again so for example, this would be an error so how can we guard against some of these errors? one common defensive programming technique is once we free a pointer set that pointer to be NULL to mean that I'm not pointing to anything anymore so this avoids the problem of what is called a dangling pointer error that now our pointer is no longer pointing to invalid memory that's it for me. time for you to play, bye!
Hi, welcome! let's talk about creating more complicated data types in C so far, we've talked about integer and character pointers what if we wanted to make something more complicated like a linked list? for that, we will use a struct so, let's say we've got a struct and we'll say my struct I'll call it say Link and what should we have inside this? well, we've have a value to store and we'll need a pointer to the next link we'll need to know where the next link is in memory so, we can say struct Link and it's a pointer to that so, don't forget the asterisk so that's our little struct here. a semicolon is required at the end but it's kind of painful to keep saying struct Link" every time I want to refer to this type so I can have a link here called one" for example so quite often, we can use, or you'll find that people use typedef" to say here's an alias" and I can use typedef with any kind of type I can even use it with integers for example, I can say typedef number now I can say number x" instead of "int x" but today we're going to use typedef for our link so we'll say instead of having to write struct Link, I'll call this my link type so now I've got my link type, I can make a link here's one and if I declare variables like this, outside of my functions, then they live forever and, let me write my main method here so, my link called one" and my value live forever and in fact, they're initialized so their bitwise pattern is just all zeros so in other words, my value will be zero and the link one" will have a value of zero and its next pointer will have a value of zero as well if we wanted to change that, then we could say one.value equals fourty two and one.next equals well, where should we put it? well where should we send it next? we could say NULL" if we wish to use NULL, actually we have to #include <stdlib.h> to have NULL defined and now our Link says I'm the last thing. there's no one after me" if we wanted to be particularly crazy, we can make the next pointer point to the very same link we do that by saying one" except we don't want "one" we want the address of "one" we need a pointer to one" so how do I do that? I use ampersand to say give me the address" of this so that gives me a pointer to a link well thats great if we only need one link but that's not much of a linked list let's actually work out then how we can actually make a whole load of links for that, we'll use some heap memory and I'm going to use malloc which is also declared inside stdlib.h so, I need some memory how many bytes do I need? for that, I can say: give me the sizeof my link structure" in other words, give me the size of link_t be careful you don't put an asterisk here otherwise, you'll only be reserving enough bytes for a pointer in other words, 4 bytes or so that's not enough for what we need we need the size of our whole struct so that gives me back a pointer and I actually want to cast it so that it's type pointer to a link_t so I can now store that inside a variable and I can have it as my first pointer so, malloc does not initialize the actual memory. it just simply reserves it for us just allocates it for us. we better make sure that our Link is properly initialized so for my first Link, I want to set its value to something and I need to set its next" pointer to something so for example, I can set it to NULL or if I, oops, let me change that to put a one or if I wanted to make it point to itself, I can say ptr1" if I had two links, let's do that then I can again set up the values. be very careful when copying and pasting code that you've actually edited it correctly I can now make my first link ptr1 its next point to next ptr and the next link, its next pointer can go nowhere so, there's my simple linked list more complicated links might have a previous pointer as well so you can navigate both in the forwards and backwards direction throughout the linked list okay, so, let's now finally compile this and check that it works our program compiles correctly, but to be a well-behaved program, really we should free up the memory as well so don't forget for every malloc you do, we should responsible for freeing up that memory once and once only so free(ptr1) and free(ptr2) also, a more robust version of this program would check that malloc actually succeeded that we actually really got the bytes that would be something important to do if your program ran for a very long time or needed very large unknown amounts of memory so that's how we make linked lists in C now it's time for you to play. bye!
Okay so let's talk about how we can make it easier to create links and destroy them so i've changed my link class a little bit so now each link can have a key and a value in addition to the next pointer the pointer to the next link okay so let's make some methods to create links and destroy them we'll do the create one first so it's going to return a pointer to a link and i might call it say link_create and I'll expect a key and I'll expect a value so that'll give me two pointers if i wish to debug this I could have a printf in here saying hey creating link and I could have what the key and values are for example right so i need to get some memory let's get some memory from the heap because we want our link to last for a long time until we decide to destroy it so i'll say malloc give me some memory and how much well i better ask for how big is my memory structure link_t and i will cast that return type as a pointer to my link object why do i do that well i want to be able to reference the sub parts the components of my struct and i will call that say result and i need to initialize my pointer so now i've got that I can set the key to be a key and the value to be the value now when i do this i am copying the pointers i'm not creating new strings so in other words i've now got a pointer called key and it's looking at exactly the same string array as the parameter is i haven't made any new string arrays so let's remember that when i return this that those pointers better be valid for the lifetime of the link well that's fine if I knew for example that this will always be used with string constants or I am taking control of those values that I send in and I happen to know that their lifetime is longer than the link's lifetime so if that's the case then my code is relatively simple like this and destroying the link is also relatively simple so let's write a link destroy method destroy which takes a pointer to the link that is going to disappear so we can call that just p and what do i need to do in here well i can simply return the memory back okay so this works we could do a little better than this we could actually do some defensive programming here where we also destroy the information inside that link so for that i can use memory set so memset where I give it a pointer that I want to use the value will be zero the number of bytes can be the size of my link so this assures that i don't have any dangling pointers i have destroyed the key and value pointers i've set them back to null and anything else inside my link has been set to null so if someone happens to have a pointer to this link and they try to use the contents straight away then it will fail it will be null and secondly we are freeing it to say okay this memory can now be reused for other purposes so that's my link destroy method now suppose we discover that our strings we don't control the lifetime of these string arrays and that actually we should make copies of them so how can i do that well there's a method called strdup so let's do that strdup and this gives me back a pointer to a new string  a new character array that has been created on the heap and it's just a copy of that existing character array that we passed it so let's create our new string arrays and use those if we do that then when I destroy the link I better free up the memory associated with my key and value so before ending here I should free up those pointers so I should call free on my key and free on my value pointer as well okay so there's my code now to start working with a link with my main method I will need to always know the beginning of my linked list so that sounds like a great thing to actually have as a global variable here so let me have my link pointer here and I can call it root and so the first link I make I can initialize root to that to that very first link okay so that's it for now, it's now time for you to play with creating more links bye
hello welcome let's talk about how we can get single characters and print them out in c so here's some functions defined in std.io i can say give me a single character for example and why don't I just keep calling this so i could just say while getchar is not equal to a special constant called end of file (EOF) keep going around in a loop but if I actually want to print them out I better actually store the value of getchar so let's have an integer value called c and inside my while condition I'm actually going to assign the result into c so you'll often see this pattern inside systems programming where we take a systems call or a library call and we store the results inside a variable but because that may also signify an error condition or a termination condition we use it immediately to check inside part of a while loop or an if statement so we've got a little character loop here that is going to keep going until it gets to the end of the file so now I want to print it out guess what i can call putchar and we'll see that running  so let's run this little program ABCD it prints back ABCD okay so we don't have to display the character just as a character we can display it as a character an integer and hexdecimal values so let's use printf for that so I've got %c %d and %x for character integer and hexadecimal value alright so let's run this and you can see that the letter A corresponds to sixty five which is in hexadecimal forty one right so why don't we use our little program to print out the contents of another file so if I cat my source code I can see the contents of that great so I'm going to pipe it into my program so i'll do ./program and it reads every byte and prints it out as a character great so let's encrypt our file now so I'm going to modify our value of c if it's not a newline character so what we'll do is say if c is at least thirty two in other words at least a space an ascii space and if it is we will change the lowest bit we'll flip the lowest bit how can we do that let's xor it with one right and then we'll print it out okay so we'll run this CDE for example and it changed the C to a B and if I do 135 I get 024 so to say that I've got to the end of the file when I'm just typing you by the way you can do control d now see this working on some actual source code so let's here some text my program.c and i'm going to pipe that into my program to use as its input and you can see great we've garbled the program so if I want to I can then take that output and pipe it into my program again so now i'm going to unencrypt it because i flipped the lowest bit back   so we get back our source code so that's getchar and putchar i can also work with whole lines i can let's get rid of the loop here i can say puts hello or any pointer to a character array provided its terminated by a zero byte at the end and that is equivalent to printf by saying %s and \n at the end so i've got some character pointer here right so it's a little bit shorter to type than writing printf there is the opposite which is to get some input but this has a problem and we'll see why in a moment why this function actually call is being removed from the c standard i'm talking about gets so let's call gets and we will have a little buffer here so let's put a little buffer on the stack here i'll make it twelve bytes today  and remember when we call gets with buffer if you use the array name you are talking about the very first byte of the array and rather than printing out hello we will print out our buffer value so let's run this and we can type something in and it echos it back to us fantastic but what happens if we enter more than twelve bytes so in other words could something bad happen to our other variables well yes it could because if we go past twelve bytes we start writing into memory which is used for other purposes for example in my little program the integer is immediately after the buffer let's prove this let's set our hex value of c to be ten twenty thirty fourty let me print that out after we've called gets i'm going to print it again so we've got to remember that what we store is going to be our letters plus a null byte so in this case if I do ABCDABCDABCD I've already overflowed because the thirteenth byte is now going to be written into my integer but i am going to do just a few more I'll do ABCD there we go and we'll see that I've managed to change my integer value to 41424344 so the last ABC that I wrote in there actually overran my buffer i've got a buffer overflow and I've corrupted the contents of another variable so that's why gets is dangerous there's no way to tell gets that we shouldn't accept input that is too long for it so in a future video i'll tell you about getline and also fgets which don't suffer from these problems okay that's it for me thanks for watching and i'll see you in another video. bye!
Hello! Let's talk about how we can use scanf and sscanf and fscanf to read some data and convert that into say integers or floats or strings so we can actually use those values inside our variables alright, so, I'll start by using sscanf which can parse data inside a string inside memory so for example, let's have a little bit of data here I'll have my data be my name and a score and I want to take that and pull it apart into a string and an integer so I'll have a little buffer here, say, up to twenty characters and a little integer here and I could set this to be equal to some arbitrary value. we'll see why in a little bit and then I'm going to say okay, sscanf please read from this string array and what I'd like you to do is convert that into a string followed by one or more spaces and then an integer value" alright so scanf is going to look at our memory starting at wherever our data is pointing at and, it's going to first of all look for a string until it comes across one space and then there can be actually multiple spaces in our data and then after that, it's going to treat the rest of the string as an integer okay, now, our format specifiers say the kind of data that we want to interpret and also the number of bytes that should be written to when it is trying to parse its data so we better tell it where to exactly put these things so for our string, we want it to write it into a buffer and for the score, we want to write it into our score variable but hold on a moment when we say buffer" yes that gives us the beginning address of our array but not for score score is just going to give us whatever value score happens to hold in this case, negative forty two that's not what we need we actually want the address of this variable so we're going to say ampersand score so, lets read that and we'll print it out so here's the result and we'll say %s %d and we'll print the contents of the buffer and print the value of score so notice that scanf and printf, the arguments don't always look the same when we want to print out the values, we don't actually want to just print out the address of score we actually wanted to know what the value is great so that read that correctly scanf actually tells us something else which is how many arguments it correctly managed to parse so let's make a note of that and we'll print that out so, we'll say %d here print out the result in our printf statement here so now when we run it, we'll see that sscanf managed to read both iterms I got result two fantastic. so that's useful. now we can write robust programs to check if we really did write into both variables now you might be worried that scanf could result in a buffer overflow and, in fact, in our current code, you'd be right so if I had a very long name with no spaces here then that's longer than our buffer so what we need to do is tell scanf just how big our buffer is so in this case, it should be nineteen because we're setting scanf how many character to read from the input and our buffer, of course, if going to need one extra one to hold the terminating byte for this string so let's run this now and you'll see that first of all the name is truncated and that secondly, the return value of our scanf call here was one and it only managed to read into the buffer it gave up trying to read the integer because our buffer wasn't long enough and, in fact, our score variable still contained its original value of negative forty two so good defensive programs must check that the return value is reasonable also, when writing scanf or sscanf or fscanf, it's always a good idea to carefully check to see whether you should be looking at the address of the variable or if the variable itself actually is a pointer and is already going to give you the memory address that you'd like scanf to change alright so we've read data from a string  we can also parse data from a file stream and how can we do that? well you can use not sscanf but fscanf and if you did that, you better give it a file stream there's one called stdin already if we didn't want to use that, then we could open up a file using fopen and then pass in the file handle here and reading from stdin is such a common occurance that in fact there's another form of this which is just say scanf and if you do that, that means hey, just read from stdin" so now, let's run our program here and, now it's waiting for input so let me typing something I'll say Angrave one hundred" great! and it managed to parse both variables okay so that's enough introduction to scanf remember this next time you're trying to read 3d data and points and you want to say convert those ASCII numbers into actual floats and doubles and also remember that its important to read exactly how scanf uses these format specifiers because its not quite the same as printf alright, that's it for me. time for you to play. bye for now
hello welcome let's talk about getline so it's very very common to read in a single line of text either from the user or from a file and we would like it to be very easy to say hey let's not worry about making sure my buffer is large enough" I just want to get the whole line and thus getline was born this is being adopted into the posix standard if you are working however with older standard and an older compiler we have to ask gcc to explicitly enable it so before doing our includes with stdio we need to define _GNU_SOURCE so if we do that we would like the gnu source additions to the standard functions right so if we do that now we have got a getline declaration included as part of the #include <stdio.h> so here is how we can use getline with getline we actually set up two variables we get getline to manipulate these directly  we are going to have a pointer to a buffer and a little int to say how big is our buffer well let's just check to see really if it is an int or if we should be doing a different type so let me pull up my favorite manpage on getline see that actually the correct type to use is size_t which is essentially an unsigned int or larger on some systems so let's just make a note of that that is the declaration that we are going to be using and so we will have not just a buffer to our character array but also size as well to say how big is our buffer and i will call this say capacity right so we could start calling this and we could say okay get me a line and oh i need to pass in a pointer to my buffer variable right and notice that the declaration here is star star asteric so it's a pointer to a pointer right so how did i get that i say okay give me the address of my variable and similarly for the capacity as well the size of the variable so give me the address of my capacity and getline is going to modify those two variables directly essentially if my buffer is not large enough it is going to free up the old buffer and then call malloc so that we get a larger buffer okay technically it might call realloc but let's not worry about exactly which library call it calls we just know that it's going to do all that buffer maintenance for us automatically and now we need to give it a filestream so why don't we use say stdin now right now our code suffers from a terrible flaw which is that we've assumed that our automatic variables buffer capacity will be set to nothing so the getline knows that it can't reuse what it happens to be pointing to so we actually need to set these to explicitly to null and the capacity to zero so the first time we call getline getline will see that the buffer is certainly not large enough and will allocate enough space we can now find out what the result is which is the number of characters getline has managed to retrieve or a negative value if it failed so let's make a note of that and we'll print this out so i'll print it out as an integer and let's have a look to see what we can find inside our buffer so we want the result and we want the buffer and lastly let's put a newline here okay so we'll run our little program here and now it's waiting for me to type something okay great so it says i have got six characters wait and i printed ABCDE actually the last character might be a newline character and quite often we don't actually need that so why don't we overwrite the very last character with null with a terminating byte so let's write the code for that first of all we only want to do that if we get at least one character back from getline so let's check that the result was positive and also we only want to do this if we are going to overwrite the last character which truly is a newline we could imagine for example reading from a file where the very last byte is not actually a newline so we should just check to see what we're going to write here so let's look inside our buffer and where do we want to look? well if we read one character that would be at the beginning of the buffer so we need to look at result minus one so if that is equal to the character of a newline then let's truncate the string the easiest way to do that remember is strings are just terminated by zero so let's just put a zero directly into that byte so we are going to say at the same spot set that equal to zero right so let's run our program again okay so this time it read it correctly and in our printf we didn't get that unwanted extra newline alright our program right now is allocating memory on the heap we don't do it we let getline do it but it's actually up to us when we finish using getline to free that buffer right so let's do that let's at the very end here we can call free on the buffer we don't need to do that every time we call getline because getline by default will try to for performance try to reuse the buffer for each line it gets so for example we could call getline twice and it would try to use the same buffer but the big take home message for getline is first of all you are going to need a pointer to a buffer and a capacity variacle which getline itself is going to change the contents of as you call it it can make the buffer as large as each time you call getline it might change that buffer to point to some new memory if the buffer needs to be larger secondly it's a great idea to check the return value of getline to see how many characters it managed to read and also to see if there was an error or not and the return type for that is ssize_t for a signed size integer type and finally it's good practice to don't forget to free the memory that is pointed at by your buffer variable okay that's it for me have fun playing bye
Hello welcome so this video is a little introduction to signals so signals are like a software interrupt we can use them to control our processes and even do things asynchronously so let's have a look at a little program i have written so far that doesn't use signals yet all it does is ask for the environment of home in other words the user's home directory and then we have a little loop that prints it out and sleeps for three seconds so every three seconds it is going to print out my home directory and on this machine i am root so it just keeps on printing out slash root so of course we can stop this program by pressing control c and when you do that you actually are sending a signal sigint or sig interrupt to the process now it maybe that our process doesn't like being interrupted why don't we catch that signal and install our own little handle for that so here is how we will do this i am going to say at the beginning of my program that if you get a certain signal say sigint  rather than having the default behavior which as we know is to stop the program or quit the program let us run my code instead so i will call it say nothankyou so what is nothankyou it has to be a pointer to a function how do we do that easy just write a function and in this case the correct type is something that doesn't return anything but does take an integer in fact it is the signal that is being sent to our program and so that we know that this is being called let's write something out directly to standard output so i can say write and i can say no so what is that that is a little message of three bytes to send so let's run this now okay so here is my program every three seconds it is going to print root but now i am going to press control c and it prints no no so it's refusing to quit you might also notice that the sleep also immediately returns more about that later it is still possible to stop our program here if we do control backslash then we force it to quit so sigint is one common signal that we send our programs there are many others just for fun let me show you one called sigalarm so this time i am going to say alarm seven seconds and so when you call alarm you are going to say give me a special signal called sigalrm in this many seconds in seven seconds and we better install then well let's just run it and see what happens to begin with so the default behavior of this sigalrm is to actually stop our program it quits the program that's a pretty aggressive alarm clock i think you'll agree and it also as you see prints out alarm clock on the shell perhaps we don't want our alarm signal to be so menacing so this time instead of sigint i can say look for a certain signal called sigalrm please call my function instead okay so there we go our alarm went off after four seconds and this time we asynchronously ran our code that printed out no to standard out so this is pretty exciting right you probably thought about interrupts on the hardware level now we can do interrupts at the software level and we can respond to things which happen in our environment very quickly so we will find signals to be very useful when we start dealing working with more than one process we can control our programs and we can also work with very large amounts of data coming in alright that is enough for me bye
so usually we think about our programs as just turning into one single process now i am going to show you some systems programming magic where actually we can turn our single process into two here is how we are going to do it let us have a very simple program that says hello world and here it is so between these two lines however i am going to call fork and here's a surprise we get hello world world yes we get two worlds why is that well at the beginning there was a single process but then we called fork and now our single process is actually being cloned it has been split into two so both the processes print out world and so we see both their output on our little terminal here okay what else can we do with this well let us first of all show that there really are two different processes i am going to look at their processor id and we will print it out so i will call getpid() and you will see that yeah i have got two different processes both trying to run at the same time in fact i have got a parent child relationship here i have got the original process the parent and you can think of fork as saying let us clone this original process right here right now so that i get a child that looks just like me or at least almost like me in many many respects it is the same memory it has got it's own variables but because its got its own address space what the child now does in terms of its memory is seperate from the parents okay so let's show you what we can then do with this first of all fork actually returns something here it actually returns back an id so let's make a note of that and we'll print it out so we'll say %d and we'll print out just here okay so here is what we see that the process id 681 has fork value of 682 and process 682 has a fork return value of 0 so the fork value is different for the parent and the child and in fact fork if it returns a positive number is talking to the parent and is telling the parent here is the id number for your child so let us make a note of that let us call this here is my child so i can call my child and then i can write an if statement to decide if i am the parent or the newly created child or not so we will say look if the child id what i return from fork is actually greater than 0 then i am the parent so let's put something like hey i'm the grouchy parent if it is zero however then hey I'm the carefree child! so we will let's remove this  i'll get rid of that line now okay so now we have a little program where the parent and child are going to do two different things and in fact it is standard for the parent to wait for the child to finish we don't have to but quite often we need the child process to do something for us perhaps in the background but we don't actually want to continue until the child has finished so let us do that what i am going to wait for my child to finish so i am going to say waitpid and i need to say okay what is the id i need to wait on well here is the childid and later on i can ask for some status information about my child and for now the last argument i am just going to put as 0 so i need to have a variable called status just a little integer and in fact we are going to pass not just the value of status but the address of our little variable and later on we can use that to find out say did our child exit normally or was it terminated in a surprising way so let us run this now and what we will expect to see is that we'll wait for the child to finish before we print I'm the grouchy parent so let's run this okay so this time the child process got to print out I'm the carefree child then it exited meanwhile the parent was waiting for the async condition and when that happened the parent is able to continue and is able to print I'm the grouchy parent so i want to finish on a common programming error that can really bring down a server and that is suppose we made many many many processes so it is one thing to create a few let's call say fork a couple of times and perhaps you can guess how many worlds we'll see here that's right we see four worlds and in fact the parent finished early so this is the hash of the terminal saying what would you like to do now but we had four processes all printing out world and if we had three forks now we have eight okay so let us make something now called a fork bomb which is where we keep creating lots and lots of processes and this often happens by accident by people who are new to systems programming but just for fun because i am just doing this inside a browser it doesn't matter if i bring my little virtual machine to a halt i can always just reload the page so let's print out my id i will put this in a little loop that says while one let's fork let's print out my process id and then i will sleep two seconds so initially i have two processes and then each of those processes calls fork so we got four and then each of those processes call fork prints it out and sleeps and so every two seconds i am doubling the number of processes that are in my system so that's a lot of processes and in fact pretty soon the kernel will run out of space it won't be able to keep track of any more processes and fork will stop working and now we see here's the kernel printing out all sorts of debug messages desperately trying to make the system stable again as it arbitrarily starts to kill processes in an attempt to recover some memory and space in its process tables so amazingly my little kernel here has managed to recover to the point to where i have a working system but that is fork bombs and you should avoid from accidentally doing this otherwise you will have a system administrator telling you that you cannot log onto that machine anymore okay have fun and i'll see you in the next video bye
okay, good morning class, how are you I'm good thank you alright, for those of you that weren't paying attention, cs241 has started. good morning class, how are you?! alright, great. so, in the next 15 minutes the game of course is for you to leave this room with more passion for system programming and maybe some more knowledge about how to do it as well and maybe some knowledge about how not to do it as well so one of the intents here is cover gotchas and common programming mistakes so, if you have a burning question, there's probably someone else in this room that has the same question I will endeavor to answer as many questions as possible without derailing the lecture so feel free to speak up if it's not appropriate, I will tell you and, just stay, come down and talk to me afterwards also, I hold office hours usually three times a week immediately after lecture because I figured thats the best way to reach most of the students so feel free to stop me I may not be able to stay for a full hour every time for example, there's a faculty meeting today where we're talking about how to take over the world uiuc style but most times I'm there to help you and I love to see people progress. its fantastic stuff when you start from the beginning of this course when you don't know anything till the end where you can actually do some pretty cool things and by the way, last semester many students came to me to say hey! you know what? I just had an interview and they asked me to explain X" where X is a cs241 thing such as, what's the difference between a process and a thread? whats the difference between stack memory and heap memory? how would you do that? what's a common gotcha with this? why would a C program crash? that kinda stuff so you might find that the knowledge you gain in this class actually has an immediate impact for you outside of this class and if it does, wonderful! alright, so, let's get started with a couple of trick questions that we have here, wanna go to overhead, right! okay! how do you look up information for C library calls and system calls? easy! okay, here's the beautiful thing. with POSIX, POSIX includes many things it includes an API (application programming interface) in other ways, instead of calls, you can call and also, a manual of man pages about those calls so guess what? we're actually going to look up different calls the art of course is knowing which calls you should use and the POSIX man pages aren't going to tell you that you already have to have a basic idea of oh yeah! I need to use open" or "or yes! I need to use write or stat or lstat or fork()" so that's the main thing you're going to get out of this course is the vocabulary with the then end expectation that you would actually then start to use this stuff and look it up so we've got two different kinds of things. we've got C library calls and system calls the C library is the part of your process okay, what's the difference between a program and a process? well, the program is the code that you've written turned into bytes which say you stored on disk and then when you actually execute it, or actually run it, it becomes a process and of course you can have multiple processes running for the same piece of program code but part of that process is the C library it comes kind of bundled with or loaded at runtime and it's a set of code and maybe some constants too that just runs as part of it so what kind of C library calls do we have? well for example, perhaps you want to do a string copy where you want to say okay, copy all the bytes into a destination from a source" and we're gonna pass two pointers and it will keep copying those bytes starting from source into destination until what? until it reaches a zero byte because that's the definition of a C string of course, bad things might happen if you accidentally put these in the wrong order alright, if you tried to copy from some arbitrary place into a different place, who knows how many bytes its gonna copy before it gets to zero? oops. who knows where its going to immediately crash your program? for example, it might be that you try to write into some read only memory and the hardware say ah ah excuse me? excuse me? you see that process over there? it's being a baaad baaaaad process" ok lady gaga I might so, look I enjoyed that joke personally so, let's um, this is an example of a C library call. it doesn't need to go into the system to run this we can do this entirely inside the process space inside the virtual memory of our proces ok, what about system calls? well, here's an example of one, you've already seen it: write()" we want to get outside of our system. we want to break out of our system and get the system to break outside of our process and do something to the rest of the world okay, so, the system itself needs to handle that particular call and in fact it does that using a hardware interrupt that's the red pill, if you follow the matrix movie that's how you escape out of the box. out of the sandbox that your poor little process is stuck inside anyway, so we want to look up say some information about these and so for that we can use man" which reads man pages which are incredibly terse and utterly useless if you dont have some basic knowledge but pretty useful if you already know something about what you intend to do so let's try one box pc okay so let's try looking up for example printf()" there it is and it's in section 3 of the man page okay yeah, we want to open it. there it is now what do we see about these man pages? well the things I want to show you is that first of all it tells you what includes you better have it also includes a whole load of function calls which do similar things so, as well as printf, we've got sprintf or snprintf and, then we've got some really terse information on what it's gonna do and usually its got a return value as well so they might return say the number of characters printed excluding the NULL byte used to end output strings notice how those display little parenthesis here as if its not that important as if the number of bytes written is not that important to you as if that could never cause a big program to fail accidentally, you might assume that that is the actual number of bytes written no no no, it excludes it and it's an off by one error it's actually going to ignore the fact that it may have written a zero at the end because it's the end of a C string oops! that's exciting. you may have not had enough memory. you may have overwritten something else so, when you read man pages, read them slowly and try to understand everything they say and of course, it's always useful to find an example oh, this one actually has one, look at that! amazing most of them don't bother with an example so you end up doing any google search to say okay, easy example of blah blah blah blah" but yeah so they're a good reference material now you'll notice we had different sections
Let's do another one Let's look for fork - create a child process. Yes, that's right, you create children by forking I knew you'd remember something from this lecture. We'll play more with this later because it's an amazing thing you can do with posix. You're first process can actually clone itself, at that very moment to become two separate processes It's like you pull a switch and suddenly you've got a doppelganger If you're a physicist and you think about the many worlds theorem, it's a bit like that. The world from a process point of view splits into two. Suddenly you've got two processes for the price of one OK, so we'll see that. But again, notice we had different sections The sections you're going to see are.... can you see this? let's see if we can make it bigger section two, alright. This is where all the system calls live section three, this is where you'll find the C library stuff and section seven, you'll occasionally find there's actually longer articles. I hesitate to call them tutorials, they're not that useful but more long winded articles that have some better practices. it's worth reading at some point during this course you might find some useful information there. for example, when we talk about signals, but most of the time you'll be using these as reference unfortunately, let's go back to here and look up stat. some words appear in multiple places and if I make a new window here and I do man stat, then I get the wrong one. I get the one that would happen from the shell. So i have to say 'no, no, no I really wanted section two' so sometimes you have to force it to find the right section that's enough about man pages. you will be using them. when it comes to quizzes, i'll talk more about that later, but i will have expected you to know something basic about the return values, some of the common gotchas of using different calls do you remember how to allocate memory on the heap? if your neighbor said 'malloc' congratulations, you made a good seating choice yes, malloc is one way to say 'hey, I need some memory and it's mine until I what?' free it, yes!  when you call malloc you are going to point to some bytes. will those bytes be zero? do you feel lucky punk? the answer is maybe, but it's not guaranteed.  if you get a brand new, fresh page of memory from the OS it's likely to have been zeroed out by the OS to make sure you don't accidently get any information from another process remember, we're trying to keep our processes separate, so you can't accidentally read someone else's password, or secret key, or something else that's secretly happening inside another process the OS makes sure to usually give you some zeroed memory however, if it's reuse of your own memory, it's quite likely there's just garbage in there it could be that because it's zero it lulls you into a false sense of security, you assume memory is zero why did C do this? sounds like a terrible thing to put the onus on programmers to make sure their programs always work. why didn't they always zero out the memory? time consuming, yes! C is all about trying to be as efficient as possible and if you can't cope with that, get a different major That is C's attitude, maybe we can find tools to spot memory errors, but it's very much a case of we're trying to write a language which is just a little bit above assembler. it's meant to be that it's almost as efficient as assembly code, just a lot easier to read and write malloc has to be very efficient because we use it a lot. think about your java programs, OK I'm sorry. I know that was a bad experience, but think about all the times you've made new objects, etc. underneath that we're saying 'OK, I need some more memory' so malloc's job is to find some bytes. you say 'oh quick, I need another thirty two bytes and I need it right now. I can't continue my process untiil you give me thirty two bytes fo rme to play with. And, yes, I promise to free it later when I'm finished with it.' some processes are allocating a lot of memory all the time. so malloc tries to be efficient and when you free some memory, we can put it back into this pool of bytes that we can use later again. That's why it's called a heap, it's just going to be a big disorganized mess of allocated space and unallocated space And, in fact, it's tricky to write malloc and free, so we are going to ask you to do it in 241 we've got malloc and free. later on you'll also see halloc and realloc, but let's not talk about those now you can just implement those on top of malloc suppose we wanted to write our own string copy function. here it is! because these are character pointers, I should mention, how big is a character in C?  the size of a single [byte] if I do sizeof character,the answer is one. everywhere, at all times, before I even compile the code. it's a definition that the size of a character type is one sizeof gives you the number of bytes so a character is always one byte. If i put a variable name in there I'd get one when I add one to these pointers, it is going to be incrementing along one byte at a time. I read one byte and I add one to the source pointer and add one to the destination pointer this code is slightly broken. perhaps you and your neighbor can figure out how it should be fixed. i'll point out the following what does this do? while star source thank you, yes! remember star means dereference, follow the money, take this expression and use it as a memory pointer and actually tell me what's in there because we're talking about a character pointer, we are asking memory to read just one byte. if we had an int pointer we might be reading four or eight bytes but, no, we're reading one byte. while this is non-zero, do something. with C, anything which is a non-zero value is true what a wonderful simple world
my love for you is 42 so this means this is going to continue until we get that null byte alright that's enough hints let's fixed that code right so see if you and your neighbor can fix this code faster than your other neighbor that you're not talking to it's not copying the string, that's one of the bugs copy the bytes so actually we didn't just want to copy src into dest  all this would do is whatever the value of src is whatever the value of src is i is just some memory location, we set that into dest but dest is just a local variable so that would actually do nothing, it would actually just change src into dest what we want to do is just use src as a pointer so we need to put a star in here there we go right so we should have read the value at src hey go back to memory and then use dest as a pointer we wanted to dereference it  we wanted to say okay now write that value into whatever dest is pointing to so we've done that, we've copied one byte and we increment both pointers and then we go back around the loop so we're going to keep writing bytes until we get to the null byte is my function finished? no, what's wrong with it? yes thank you, yes we forgot to copy the null byte so this function is broken it forgot to copy the null byte but it might work if you test it if you happen to test it with memory that was already zero and you think aha I finished my mp right, no your code is broken because is forgot to terminate the C string and then some future function would start reading this and it wouldn't come across a null byte because there would be garbage after it and it would start printing random characters until it eventually got to a null byte of course if it didn't get to a null byte maybe other bad things would happen anyways so let's fix this we needed one more line to say after the while loop  alright the src should be a null byte which I could write like this okay here's another example of a classic C error which is when you've got two pointers you're probably using the wrong one okay so make sure that we change the very last byte at the end to be a zero byte so we terminate it we could have also fixed this by using a do while loop instead of a while loop so we would have only done the check at the very end we would have copied at least one byte alright so that was my string copy how about something that actually duplicates strings right so we want something that takes a character to some memory and we are going to make a new memory object and we're going to copy the contents of the original into our new piece of memory right so how do I get some new memory? easy I remember what I said ten minutes ago and say malloc so I've got malloc I've got the right size I copy.. whoops wait a moment I've got two pointers am I using them in the wrong direction? if in doubt, yes I probably am right? how do we check? easy go back to the manpage alright man let's try strcpy and BSD kindly calls them s1 and s2 okay copies a string from s2 into s1 yes we managed to do it the wrong way round what we should have done is swap these around by the way is this text large enough to see at the back? can you give me a thumbs up if it is? alright so most of you alright I'm assuming the people who didn't are going to sit closer to forward in the future but seriously let me know if it's not okay right is our code finished? okay we run it and it doesn't work, it might crash here's one problem, what's the size of src? what will this give us? one, we've managed to allocate enough space for one byte and then we try to write into that one byte okay that's fine if our string is very short, just one byte long not so fine if our src strings were longer so we shouldn't have done this right? what we wanted to know was the number of characters at the src so how can we do that? call strlen of src so now we test it and it almost works but it still crashes here's the issue, strlen tells us about the number of characters excluding the null byte at the end look C is trying to help you give off by one errors what a polite language, if it's not my fault it's your fault alright look we only need to add one to that that's just evil huh? who came up with this alright so when you write a language don't do this make your strlen actually say how many characters, how many bytes it actually took okay so we've got now we're calling malloc and we copy from the src  so this should be p, this should be from the src into our memory and finally we return p is it okay to turn p because look p is an automatic variable it's a local variable is that a problem? no because we are not returning a pointer to p itself we are running the contents of p and p is just looking at this memory that we've malloc'd and that memory that we've malloc'd will exist until we free it  now malloc itself returns a void pointer and if we wished we could cast that changes type into a character pointer in practice you don't need to that if you have a void pointer it's okay, it's allowed to cast it implicitly to a different type
alright so, is our code any good? yes, question? okay, so, this was discussed on piazza. it makes the code a bit more cluttered. if you do too many casts, you're forcing your way, you're saying: hey compiler, trust me I know what I'm doing" which is fine until the day you don't know what you're doing and you've just casted something which is incorrect maybe you're casting a pointer to a pointer to a pointer. and you would've potentially gotten a compiler error but by explicitly casting, you won't get any error so that's probably the biggest issue yes oh, I'm so, yes, you're right. I forgot that it's a character pointer. it would not have returned 1. it would've returned say 4 or 8 or however big your pointers were on your platform so, if its a 32 bit platform then how many typical bytes do you need? well, 4 bytes to hold 32 bits if its a 64 bit machine, then you'd need 8 bytes right, so, our code looks pretty good except one little issue. if you read the manpage of malloc, you can discover that malloc() can fail. and when it fails, it returns quick! read the man page! right, when it fails to give you any memory, it returns NULL so, we should check for that because right now our code would attempt to write into that 0 location if malloc fails so what we should do is, here is, we should, if p or not p which is another way of saying hey, is p zero" I didn't give any memory so no new string duplication for you and hopefully the code that calls my code actually bothers to check to see whether it got a valid pointer or not alright, okay, any other questions? alright, what's a double free? okay, so, let's say we free pointer, and then for some reason later, we free the same pointer in other words, we called free twice on the same memory block is that a bad thing? yes, that's a bad thing okay, here's why when you call free, the memory allocator says oh, look!" he or she is finished with that memory so I can put it back into my free pile and I might allocate it again when someone asks for more memory but I'm going to update my linked list structures and whatever internal structures I have to keep a count of what memory is free so if you call free again, bad things may happen to those linked list structures bad things may happen to other code that's already actually using that memory space alright because between you freeing it and freeing it again later, it could be that another malloc has come in and been given that memory so when you double free, really exciting things can happen you have no idea what's gonna happen next. you have broken the universe at this point because, artibrary things can happen to your heap memory and who knows what the rest of your program is doing to your heap so, how can you avoid it? well, there's a couple of ways. first of all, don't write this code secondly, it's a good practice in production code to set your pointer to zero in other words, don't have, what are these pointers called now? the dangling pointer! it's a pointer to some memory address that is no longer yours to play with because say you free'd it and you don't want another piece of your code to accidentally use that pointer so, when you free memory or decided to use memory for some other purpose, it's good practice to set pointers to that memory to zero this of course looks very easy and trivial to avoid. in practice, these two frees could be somewhere arbitrary in your program. maybe someone kind of tries to free your data structure twice and then you end up calling free on some memory twice right, okay, let's have an example of a buffer overflow well a buffer in C can be anything. for example, it could be just a simple array so, let's make an array myData and this says, okay, I need space for 8 bytes or 8 characters" and let's set one of those entries to p. is that allowed in C? okay, so that's a trick question. yes, the compiler will compile that for you, it might give you a warning, it might get an error if you've racked up enough options but remember, what are we doing here is we're just simply saying okay, take whatever data's pointing to, add 8, times whatever the size of each entry is, and then use that to change some memory" we actually want a bit representation in our p but, when we did this, we only asked for enough space for 8 entries. and we're trying to write a 9th entry. oops! we could also have run into the same problem if we had string copy one two three four five six seven eight ahh, I did it the wrong way around okay, so there's two things wrong with this code. first of all, the arguments is the wrong way around second of all, how many bytes is this going to write? into memory? nine! I've got the digits 12345678, and the NULL byte at the end to say hey! my string is finished" but we only made space for 8 so that ninth byte. what's that ninth byte being used for? maybe it's being used for another variable in which case we've just overwritten the value of another variable and that is how many C programs are vulnerable to buffer overflow that is how you could hack into say, a web application which didn't put enough space on a buffer and you could then overwrite nearby variables
let's do our last little thing here. what is typedef? it's just an alias we've got some basic types in C, but you can use the keyword typedef to say 'hey I need something else' I might have an unsigned int OK, that's a lot to type. I'm just going to call that my u int or I'm going to use an unsigned int to represent process identifiers for example. So don't be scared when you see typedef, it's just being able to alias a particular type so that you can have a short name for it questions? yes! because writing struct x is painful and people don't want to have to write the keyword struct everytime let's say I have a struct called poem now I'd have to say 'right suppose i wanted some memory' I want a pointer to a poem, so struct of poem pointer malloc sizeof struct poem it's kind of annoying to keep writing struct everywhere, yes? so instead you'd say typedef and that can be my poem struct And then you might go further and say I want a poem pointer, so poem_s star poemptr then you might write this code and then you might write this code and that would be wrong whoops, look, i just tried to get the size of my pointer. that's going to be four bytes or eight bytes I didn't want that, I wanted the sizeof my original structure. be careful when you start playing with typedefs you'll see typedefs commonly used with structs and for things like unsigned ints let's not compile this code for now instead let's print some things out here. how can I print strings out and single characters? well you've seen printf, fantastic. guess what? there's also putchar sixty five and that's going to print a single 'a' so if you wanted to print out a single character, there are these C calls like putchar if you want to print out a line, there's put s Hello World 'It prints a new line too' so that's useful if you know that all you need to do is print out a C string. it will print out a c string followed by a new line all of these calls underneath end up calling, what?  yes, they call write <gibberish> some point your C library says I've had enough holding these bytes, I want to get rid of them, I want to flush them, I want to send them out and when it wants to do that it calls write to the OS it turns out actually you don't need to print everything to stdout. your processes by default have two output streams. one called standard out, one called standard error. let's prove that let's use fprintf. I'm going to say something like 'this is using printf' and we'll try to run that and it doesn't work we get an error because we haven't given enough arguments to fprintf and in fact the. let's look it up fprintf, yeah we need the file stream first. we can say standard error here's the thinking, here's why standard out and standard error exist and they're not quite the same quite often when we want to use these tools we want to process the output of one tool and send it immediately into the input of another tool but what about errors? well we'd like to see them still in the terminal, we'd like to send them to a different file you're compiler for example, might send - ahh what have we done wrong here? standard error undeclared? ah OK, great, that really did print. This is using fprintf. We can send things to these two different output streams and you too can make your own output strings by using fopen And also they have different bufferings What've we got here? I've shown you things like puts and putchar how do I print - use fprintf, for example, I can send it to standard eror, blah blah blah is standard error buffered like standard out? no! standard error immediately calls write, it doesn't try to do any buffering standard out is a little bit diferent. standard out tries to have better performance, so rather than writing every single byte, let's collect a few up and once we assembled enough bytes then we'll call write and make it appear standard out by default when you're just looking at things in terminal buffers until you see a new line so if we see a new line, let's flush that buffer! in other words, call write on the whole buffer and out it goes
let's prove this while one do nothing  right so we got the very first line over here from printing to standard error but we did not get the standard out line so look at my code, I said hey this is using printf and this is using printf exclamation point" the difference between the two is that one of them went to standard error and we saw that straight away standard out that text is still sitting inside my process inside the c library because we didn't include any new lines and now my process has got stuck inside this infinite loop so now when I control C the program never has a chance to flush that buffer it never has a chance to write it out if I did just exit normally, if I did just say return 0 here then as part of the exiting, the C library says oh look I've got some open file descriptors I will make sure that my buffers are flushed so it does that at the very end as the program is finishing right oh and one last thing here, if you actually want to print into a C string the best thing to use is sfprintf but I'm not going to talk about that today but that's assemble things into, yes quick question there is two different streams so it's up to the terminal at the end to combine it into one and display it but we could make it so that the standard error goes to a completely different file or goes somewhere else let's have a look at page two okay when you free a null pointer, nothing happens, it's a safe operation by definition of the spec being thinking beings, you want to see errors as soon as possible you can actually change it there's a call called setvbuff if you want to change it but that's the idea right okay so which one should we do here let's do these three, these are the funnest ones the first three questions on this you can see on the wiki book I want to kind of go through these, first of all let's write our most exciting system program today I'm going to use this fork and for that we need to include unitstd.h so let's do that so let's print something out in our little program here, let's find out what our process id is so I'll just do %d for now, that's good enough for this lecture let's call getpid to mean get my process identifier so we'll run this and next time I run it I'll have a new line as well so when I run it this time my program was process identifier 61 and in fact if you do ps on a command line you can see all these different process little numbers and we'll use that later because we'll control them this little virtual machine doesn't have much going on right but if I was to run it again, I'd probably get a different process number one hundred and seventy five, okay
so now let's do something exciting let's call fork() look, I get two different numbers, 188 and 189 I've actually got two processes running here's what happened: the moment you called fork(), your little process gets temporarily stopped for a nanosecond so the CPU's not going to execute anything in your code and we duplicate it we now have two nearly identical processes running and then we'll let them go so remember when I said, you pull a switch and you get an immediate doppleganger there's immdiately two processes now one thing you've noticed already is that they have different process identifiers another way that they're different is that one of them is the parent of another let's get that back to result, and let's say...fork gave me the following My pid is that okay, let's run that so, look at that! I got two processes running at the same time. one of them says hey! fork() gave me nothing. it gave me zero. and fork() gave me 203!" so these two processes are now running in slightly different worlds. one of them had a different return value. one of them had a non-zero return value and in fact, the return value is the child process! so as a parent, if you wish, you could create a child by forking and then immediately kill it but I'm not going to show you how to do that today instead, I'm going to show you what happens when we fork() too much while 1 is greater than 0 let's print that, let's not return, and let's sleep for one second just so we can kind of follow what's going on. actually, let's sleep for two seconds Are you ready? let's see what happens now okay! I've got two processes. OH! how many have I got now? FOUR processes. now I've got eight processes. now I've got 16. Each process, remember, sleeps for a second and then forks. it makes a copies of itself. so I've got all these running processes because say, I had 4 of them, and all 4 of them called fork(). oh dear, my system has crashed alright, eventually, my poor machine of course runs out of memory and it's unable to continue. alright. so, actually, at this point, the system does its best to preserve itself it does its best to say ahhh, I don't want all these children!" I cannot cope and so it prints out all the debugging information and then decides at random to start killing user processes. the idea being that that's the least bad thing that we could do in this case because we want to preserve the actual main operating system (the kernel running) and maybe we'll have a few processes left that are still useful so let's see if I've even got a- no, I don't got anything do I? no, it's dead but that is an example of a fork() bomb. as you can see, it's pretty mean to everybody else that happens to be logged in to the system at the time so, when you start using forks for the MP, good luck! and try not to write fork bombs and with that, we'll finish there and I'll see you on Wednesday!
your laptop before we release the official instructions ecetera but that is it. that is coming up alright, so, next question, who here is ready for section this week? and actually got a little working editor? alright, who here is still working on it? okay, who here is procrastinating and has not started yet? alright, okay, so note that if you raised your hand on that last question, you are definitely the minority. remember, the purpose of this work is for you to be on top of using these calls, understanding how memory works, understanding how to put them together so make sure you're ready and it's gonna be great prep for when we do the harder MPs right then so today here's what we're going to do. we're gonna talk a little bit more about C programming. I'm going to show you some more gotchas i'm gonna talk about getline I'm gonna talk about assert(), I'm going to show you some fun little demos and as usual, feel free to interrupt me and ask a question or two and as usual, most of this material is also in the wikibook. which was created last semester. So most of the lecture content, you'll see inside the wiki book alright, also, these lectures are now recorded so feel free to review them as well right so, let's have a look at our little handout. overhead!!... doo doo doo doo doo right! so here's something you can put inside your C programs. if you write line underscore and undersore or file underscore and underscore, something magic happens they get expanded by the C preprocessor into a number, as if you actually typed it, and a string, as if you actually typed in the file name that's currently being compiled so the value of line actually changes and the preprocessor knows which actual file line it is currently compiling so that can be useful for putting in debug information, so we can discover for example which part of our program is executing by printing this stuff out so, let's have a look, box pc okie dokie, so for example, I could say hey!" or, let's just print it out. I'll do printf "bad stuff happened in file %s at line %d" we'll put in, let's see I need the file and the string so that's a underscore. oops. can't get it back inside. thank you. file and line number. alright, so we will put a new line there...let's say exit our program so nothing else happens. okay, let's run this alright, so there we go, bad stuff happened in file program.c at line 14. that's pretty useful if we want to open our editor and go back to that particular point. so that happened at runtime. and in fact that idea is used by another macro called assert so you can imagine we want to be able to say things like look, if my pointer is non-zero" so I could say "not equal to null" or I could say "not equal to zero" or I could just say "if not p"  in other words, if its not a valid value print an error message and quit right? that's a pretty useful thing to do during debugging. just do a quick test. before I start using p, I may be crashing in really strange ways so I just want to check if the following expression is true so that is actually what the assert macro does. so, I can say things like look, I want to assert that 2 is greater than 1" let's check that. let's assert that 3 is less than 7 times 0 right, let's run this we didn't get anything, did we? and, I'm wondering why let's see, we compiled asserts include assert.h and we don't seem to be. AH. we want to compile it in debug mode okay there we go, right so this time we, haha, yes! this time we remembered to include the assert.h and assert is actually a macro. it expands to include that underscore underscore line thing and underscore underscore file so now, here we go, when we run this, it prints out program.c at line 15 inside my function main assertion 3<7*0 it's pretty useful. it actually shows you the expression it's a nice simple development thing to use asserts because then you can check that people that are calling your functions are actually giving you say valid arguments and you can check that your assumptions are correct before you try to write complicated code and, it kills your program. it aborts so that's assert now then, pretty easy to use, remember to include it, include...assert.h and then, and then inside your program you just say assert and write an expression you expect to be true like Hey! its wednesday!" if that expression is true, nothing happens and in fact, when you make a release build, this expression isn't even tested this compiles to no code so it's good for performance but then you realize that you've been living on the edge. it doesn't actually check it. and it's a macro, because we want to be able to print out the actual contents of the expression we're going to test. and also we want to print out the line number. and also it's a macro because we can make the contents of the macro disappear when we do a release build so, with that, let's see if you can write a version of string cat. and what you want to do for strcat is append the contents of another string onto the end of the first string. but, we're not sure that people are giving us valid arguments so how would you write this so that it aborts if either one of these were NULL ? what would you write? so see if you and your neighbor can finish this
this function it should at the end simply return a pointer to the beginning of the target and i'll give you a hint, how do you actually determine where a string finishes? You walk along the string until you find a null character so the plan should be walk along with a little loop until you find a null character and then start copying the bytes from the source at that point to keep copying them across until you get across a null character in the source and then you know you're done copying and then before you finish make sure the very last thing you put at the end is a null character to terminate your string see if you can finish that code in about five minutes and I'll walk around answer any questions you have questions? ice cream? popcorn? yes? if you wanted to check that these are valid pointers, we want to check that they're non null so actually we could just say assert dest you could even say dest and source, however, that wouldn't give you very much debugging informationÂ all you'd discover is that one of them is broken so personally I wouldn't do that, I would write it as two different things on two different lines so that when it does it break I can discover at least whether the problem was with the source or the destination address OK, right, so if I get past that I know that both of those pointers are non null. my next challenge then is to walk to the end of the dest I could do that using a little loop. I could say things like while star dest  keep incrementing dest so that would work, in other words whilst - when I read the contents that dest is pointing to - whilst that's non null keep walking and it will keep doing that until I end up on a null byte. I also heard people doing things like, let's just add into dest strlen dest in other words find out how many characters excluding the null byte, are pointed to at that destination and add that to dest so both of those would work now we want to copy. OK, how could we do this? well maybe I call string copy, but if I wanted to write this in a loop, let me write this little do while loop going to dest and do I want to go into there, the contents at source I can't spell source, nevermind. whoops, and then increment both of those. dest plus plus, source plus plus. there we go
alright and keep doing this while either one of these is valid okay what do you think about that code? hold on hold on you can't see it is this code correct? does it copy the null byte at the end? okay alright if your neighbor thinks it copies the null byte get a new neighbor right why does it not copy the null byte? because we've incremented the source pointer right so we copy a byte, we keep copying characters and then we increment the source pointer and then we say while source so we are checking the next byte, the byte that we haven't yet copied so no, that code doesn't actually coy the very last byte you see, C program is easy or actually C programming with bugs is easy, writing correct programs is harder and we wouldn't have spotted this if our destination memory had all been zeroed by some fortuitous accident so that is incomplete, we still need to copy the byte at the end so at the very end I need to put a null byte in so I could write that as zero, I could write that as backslash zero that means the null byte and then finally return dest okay what do you think about that code yes, so if source is just an empty string what would happen? correct, we put two null bytes at the end so that's dangerous right? our code would actually copy more bytes than say the standard specification so now we've got a bug that only happens when we copy empty strings what else? there's another bug as well. yes? I'm writing memory that isn't part of dest or source okay, so I haven't malloc'd a new buffer yeah. okay so let me first mention the error I was going to point out which is actually the specification of strcat says we should return the beginning of the string we are actually returning the end of the string whoops, so we probably should have kept a copy of what the original value of dest was as it happens, most people don't tend to use this return value and so your code might work in most places until the day it doesn't now let's get back to that question of oh we haven't malloc'd any memory so strcat actually assumes that the destination is big enough for all these bytes that we are going to copy it doesn't do any mallocing itself, it just says okay give me a pointer, I'm going to assume that there is enough bytes available for me to copy whatever is available at source and if that is not true, well let's hope this code isn't actually driving a car or an expensive robot or flying a plane or something inside your bloodstream so strcat is dangerous, you have to promise that you've got enough bytes allocated at the target and for that reason many people avoid it and use strncat instead which I'm not going to talk about today and that saves you from some of these gotchas so it's better but it's still not perfect you can still have problems with strncat but I don't have time to talk about it right now okay right so for your next serving of C, I've got some code down here that uses strcpy and strcat and arrays and pointers to stuff what errors do you spot? if this was say a code review or in an interview and they said hey look at this code, what can you tell me about this?" what can you and your neighbor find? what errors? what kinds of errors and how would you explain them? [long pause]
okay, alright! so, what do we got here I got three variables: var1, var2, and arrrrrayyy!!! alright, just to point out that this is an array. and they all initialized to hello world! bounjour!" now, there's a big difference between these and to point it out first of all let's talk about this very last line no, it is not possible to do this what this line is trying to do is say hey! I've got a pointer called array. make it point to the same thing that var2 is looking at" no, you cannot do that. if you use just the array name here, it's treated as a pointer but there's a couple of big differences first of all, you can't change it this variable is the beginning of the array you can't make it point to a different piece of memory secondly, if you ask the size of array, you'd actually get back the number of bytes of the actual array unlike a pointer where it would tell you the number of bytes required to hold a pointer so no, you can't change array and make it point to something else you can, however, make a pointer to a character point to a character array. that's okay! now you've got var1 holding the same address that array hold alright, now, what about these other things up here? okay, strcpy! I want to copy into the array var1 is that okay? if you said it's okay, you're correct! okay, why is that? well, here's what happens. we're actually saying I need an array and I need it to be big enough to hold the following data" (bonjour) and when we run our program, when we start the process, we have a little array, here it is, and bonjour is copied into this array so, our array lives in memory that you can read and write so if you want to copy other stuff into the array, yes, go for it. it will work. just remember that the array isn't an infinite length. it's fixed size. so you better make sure you accidentally copy too many bytes into this data structure so we're fine, we do strcpy into var1 so that's okay, what about strcat var2 into array one? that looks fine too, ary is mutable, we can change it okay, here's the exciting part. yes, we're calling strcat so we are appending characters onto our array but you and I know that this array is not going to be big enough to hold whatever it is hello world" we're gonna write the data w-o-r-l-d and a NULL byte past the end of the array who knows what's going to happen? woohoo. we don't know! it depends on how things are laid out in memory but I'll show a little demo in a moment just to show what happens whoops, what we have here is a buffer overflow. we had a buffer which is just our little array and we went past the end of it we wrote into memory that we should not have been writing into. we didn't own that memory. oops. and, I want to point out that this can happen not because you were just thinking about. you didn't think about memory slides. it can happen through typos. when you intended to say strcpy and instead your fingers wrote strcat bad things could happen. alright. especially if your pointer happens to point to arbitrary data at this point strcat is going to say okay! I'll copy this data for you. I just need to walk along this data and find a NULL byte" and off he goes! bye! so be careful when you write strcat strcpy, just take a moment to check you actually wrote the intended one. of course, I've never had that mistake hahaha. and, what about strcat var1 var2? can I copy from what var2 points to into what var1 points to if you said yes, at least say it confidently because you're incorrect no you can't. var1 and var2 hold the memory address of this constant so yeah, you can change var1 you can make var1 point to something else. here we go. var1 equals hey, point to this other thing. hey, hold the value NULL ecetera. I can certainly make the contents of var1 be different but in this particular case, what it's pointing to is memory that is read only so if you try to start writing bytes into that address var1 points to, ah ah ah! no, you won't. the hardware will detect that and say you can't do that" I'm only giving you read access to those bytes alright, any questions? yes! yeah. yes. the compiler will spot that so array names are special uh, it can be treated as a pointer. if you need a pointer, the compiler will turn that name into a pointer. and the pointer is at the beginning of the array alright, so, if you do things like ary+3, that will add 3 times however big each element is so if you point to an integer array, it will be array + 12 bytes if you're on a 32-bit machine with 4-byte integers alright so, remember, the compiler is just turning this into assembly code so it uses the type information and if its trying to get a pointer, it turns into a pointer okay, other questions. yes! uh, so var1 the variable itself is mutable. we can make var1 point to anything else. but yes, you are correct. I could now write strcpy var1 after this okay, so, this is okay now. because var1 is pointing to the array. so of course I can copy okay into the array alright, we should talk about uh, I forgot to free memory. we do not need to free these memories. these are not on the heap you've actually got more than just the stack memory and heap memory you've got static memory where you'll discover these constants go where also our global variables go as well so you see heap memory when you call malloc. alright, that's how you get heap memory we haven't done a whole lot of malloc-ing yet and you see stack memory when you make a variable inside a function alright so here we go
that is going to be inside my heap well we're not doing that right now. we're playing things which are either constants or declared outside of functions let's do a quick demo. right, good here is the code we've got. I don't want this right now but I've done one extra thing, is I've made another array called demo. It's got the characters 1 2 3 4 5 6 and I'm going to print it out twice. so we should see 1 2 3 4 5 6 twice, right but of course, because you know it's a demo, we're not going to see that. let's see what we get. oops, we have to turn off the asserts OK, we're not going to see that. this is what we saw instead. 123456. OK, so we've printed out the characters and then d and a smiley face. where did that come from? for some reason demo got obliterated by a d and smiley face and of course the null byte why? because first of all we copied var1 in and then we did a string cat and copied var2 into our array. but our array was not big enough to hold 'Hello..!' and 'World:-)' strcat doesn't know that, it merely copies the bytes until the end. and so it kept on going and it ran into the memory that is being used by demo and we could kind of prove that they are next to each other. let's have a look at where they are. so we can say, hey the array is at this address and demo is at this address there we go. so array is at some low address and demo is at another low address, but just next door doing the mental arithmetic to subtract those two numbers is left as an exercise to the reader. but it's pretty close, yeah? it's about ten bytes right, that's our little demo. let's go back to our sheet. so let's talk about converting things if I've got a string and I want to convert it into a simple integer, how can I do that? well here's the easy way. use atoi so for example atoi of a hundred gives you the integer hundred what do you think atoi of bananas is?  place your guess now it's zero! so here's the downside of using atoi, yes it's really really quick. it's trivial to write code, but you'd better trust that what you're going to get is a valid integer that can be converted into a standard c integer because if it can't it doesn't crash, it doesn't complain, you have no way of knowing other than the fact that you got the value zero so this returns a value of zero. so you don't know whether the user typed zero, entered zero, or whether it was invalid input so use it for little demos, quick hacks, etc., but if you actually want to check whether things are valid or not then it's time to use scanf because scanf will tell us how many things it successfully parsed. lets make a little scanf demo OK, three integers walk into a program. there you go x y z. and I've got a string that I want to extract some values for maybe this is some 3D vertex data for example and I could use this function called scanf to say 'alright here's my input and I want you to treat it as an integer followed by some white space, another integer followed by some whitespace and another integer' OK, how do I push that out? I need to give it the address of my variables. so remember ampersand means tell me the address of this thing OK and now if our program works tick tick tick tick, yeah! z is twelve! hooray! great, I've written a parser that can now read 3D data. watch out minecraft OK, what about 10 11 x? what do you think the value of z is now? well it's claiming that z is zero,but we should try something here. suppose we initialize z to be something else like 42 z is still forty-two. so what our scanf did is it started eating, started walking along that string, it got to a point where it said this not what I expected and it choked. it just gave up and stopped so what we should do to write robust code is see how many things scanf actually managed to bite out of the input so let's have a variable here called numread and we can now check to see how many things were actually read by scanf and then we can write code that says, hold on a moment, I died trying to parse this line now you can see numread equals two
extract out the x and the y and we failed when we tried to parse the third integer right, so scanf looks pretty easy and it is it is very easy to write bugs using scanf I've already mentioned one, okay so scanf - you saw that there are already different versions of it I was using sscanf because that allows me to start from the string which is good for demos there is also fscanf which guess what, starts from a file pointer so for example, I could read from stdin or I could read from a file that I've already got open and then we need the format string, okay so here's the first problem that you can run into this looks a lot like printf, printf's format string yes? I just showed you one with %d's and it is until it isn't it's actually subtly different, so the day that you actually need to write a scanf, open up the manpage and check the format specifiers because it's not quite the same for example floating points are slightly different so that's the kind of first gotcha. that second gotcha I've just shown you, which is that the number of items that you've read isn't necessarily all of them, so you should check that and then the third gotcha is guess what, we can put in addresses here and sometimes you want to put in an ampersand and sometimes you don't so I showed you one way we did ampersand y ampersand z because I actually wanted to know the address of my integer variables can you think of a time when you might not actually want to put in the ampersand? yeah, if you already have a pointer to the thing that you want to change so if you've got a pointer to an integer variable, there we go, let's put in pointer here and provided that pointer is pointing to something a variable I want to change, everything is fine everything is not fine if I was to write in ampersand pointer because now what am I changing? I'm changing this, I'm not changing the thing its pointing to and if you think this is complicated or confusing, it is! so my advice is don't write scanf code until you've had three cups of coffee, you're completely awake and it's the most important thing in the world to get it right and even then, assume that you've got it wrong scanf code is incredibly hard to write correctly and you can get nasty little errors just by missing an ampersand or putting an ampersand when you don't need one scanf is not going to detect that, you have to be extremely clear about whether you mean to talk about the thing, the address of the thing or using the thing that the thing is pointing to so it's not for the feint hearted and with that warning, let's carry on I can promise you I've spent hours debugging scanf code that I thought was correct here's some other things that will kill us or get you gets is easy to use, you just say gets and you give it a pointer to your buffer to some characters description, never use this function the reason I bring it up is because people like to ask about it occasionally in exams and occasionally in interviews it's a classic example of how to hack a program, hack a C program because gets like strcpy has no idea how big this buffer is how many bytes it can safetly write into whatever address you give it so if the data that it's reading from stdin happens to be bigger than your buffer, arbitrary things can happen now someone could use this to supply data that is longer than your buffer and start overwriting arbitrary memory locations and those arbitrary memory locations probably correspond to other variables so now someone can use your program to do bad things, to do things that the program is not designed to do so how do we fix this? answer: use fgets instead right and I'm not going to talk about that because there's some more fun stuff we can do down here let's do environment stuff, I don't think I've shown you environment stuff yet have I? okay right so every program when it runs has arguments and an environment  so if we do env for example, you can see that my program has actually when it runs, has all of this information all kinds of useful stuff like the current user is root, where the home directory is for example, the current directory is probably in there as well so I can get access to this stuff when I write my C programs so let's write a little C program that does this for example, I'll say I've got extern, environ, now this extern means that look, this thing exists don't allocate any space for it, but when we finally link all the pieces of my program together the compiler is going to look for this variable because we've simply declared that it exists somewhere and I want to use it inside my C program right now so let me put the contents of the first entry of environ and then we'll exit okay so you see we've just got a string a simple C string which is in the form of key and equals and a value and I could write a little loop to go through all of them and when I find once which is null at the end I know I've finished so if I want to enumerate all of my environment variables, I can use environ if I actually want to look one up that I know exists, I can use getenv, so let's getenv and say look for user okay so that will give me
uhh, an answer and I'll print that out. okay, so we can see that my program when it says getenv on the current user, it prints out root woohoo! so, environment variables are one way of passing useful things to your program. as we've seen, so say you can look at the current user's home directory and store your preferences there. or if you're mean, you can delete all their files so that's one way to get a general general environment. the other way you've seen of course, is that our main method has two parameters. argc and argv which is a character pointer pointer so, let's all look at this. first of all, some important points about them (come back!) the first is that the very first entry of argv is not one of the program arguments. it's actually the program name so I for example, could write a usage thing. blah blah blah blah and, if there are any other arguments, we can find out how many there are arguments %d our count alright so, it's program name, the way its actually executing we can actually discover from the program itself. it's the very first zeroth argument. and we've got one argument so this is like another kind of classic off by one thing again so if I have, you know, cats, it thinks its got two arguments what it means by that is that that array has got two entries and the first one being the program name the second entry being cats and in fact, that's not even quite correct either because it happens to be always one final entry at the end which is NULL so we could go through and look at all of the arguments so let's do that. we'll have a little pointer. let's make it point to argv + 1, in other words, we're not going to print out the program name this time (come back!) yeah let's get rid of that stuff okay, right, we'll stuff [something] we'll print everything we find at the pointer so I need a pointer to an array and a pointer while the entry is non-zero, let's print it out. and we'll add one! okay, so let's now try our little program. oh I forgot to follow the pointer. okay cats are cool alright, so, we can access each of the arguments that the program has
okay, hi. I'm gonna ask you to volunteer (student: oh okay) alright. I'm going to ask you to volunteer for something in a moment Okay! Good morning class! how are you? great! so, here we go, uh today we're going to talk mostly about fork() and exec() maybe we'll have time to talk about signals as well yes there will be an in-class exam/quiz coming up next week we'll see when it happens I guarantee it won't be Monday Or tuesday or thursday alright, more details next week. so first of all let's just start off with a little demonstration of how fork() works for that, I need a volunteer, yes! thank you! please come on down alright, so, um, here's my process and of course [something] today you're gonna be my process, right? so, a process to run of course needs some instructions to execute here we go, stand here, you're my process, right. okay thank you. and, here's the code that I've already compiled right into something the CPU can execute okay, we've got inside the process memory you've got a pointer called neurons and an int called capacity right and we run this function called init brain it's kind of complicated it does a lot of stuff when we pass in the address of neurons and the address of capacity, so there's init brain when it returns will set where the neurons being held and the number of neurons that we have so, it looks a little like readline, yes? and, manage to actually return a void pointer so we can actually use that perhaps okay so we're running this code, okay, and the next thing to do is think of a number, right? so, think of a number between 1 and 10 don't tell me! don't tell me... and then you're gonna print the number to standard out alright, so, this is my standard out here you can write a number...okay accept! oh you need a pen accept here's what we're gonna do, right. you thought of a number, yes? it's in your head. inside the process before you print it out, I'm going to change the program now in just here, I'm gonna call fork() okay? between thinking a number and printing it out I'm calling fork() so, what does fork() do? it doesn't not restart the process. no. here's what fork does: it says take a process that you've got and clone it yes? make an almost-exact copy of you! now I've scanned the audience and I've found the person who looks exactly like you I need my second volunteer. thank you, come on down [laughter] alright, so, at this point if you'd like to write down your number. so we've got two processes. don't show me your number and of course, thank you. so, we've got two processes and because we've cloned it, inside their memory, it should be exactly the same so if we now were to say to both of them, okay, continue executing, remember these are two completely different processes their own memory happen to be following the same assembly instructions here. the same code so if we asked them to print out their number, let's find out what they would say! here, hold them up and show the audience please look at that! alright, they're both printing out seven which is also what you wrote okay, that's a miracle. [laughter] alright so, well, a 1 in 10 miracle, not a big miracle, but we'll just leave it so this is how fork() works remember that this is what happens. it doesn't restart the process. it splits it so give our volunteers a round of applause, thank you very much [clapping] because we're going to use that now in C and remember anything you write in C could, in principle, be done in any other program as well. in any other script language like python python, for example, has a fork() but underneath, python's written in C, and underneath that, it just calls the fork() command okay so, I've got a little example of that in terms of code. here it is here we go, can we read that? okay, so here's my little example this srand() here thing, this says okay, system, tell me what time it is?" and I'll use that to initialize my random number generator so remember to actually generate random numbers, we cheat. we just do some mathematical bit shifting tricks so it appears to us to be a random number and it appears to satisfy some basic statistical tests but there's not really a random source here it's just a mathematical stream of numbers that appears to run all over the place so later when we call rand() we get back a random number but look at this for a moment! I've called fork() this time beforehand so the question is, what do you think will happen here? will my two processes. so, I have a new job process created. will they both print out the same thing? let's run this and find out. okay so what do we get? well each process is told to print out its id number so we get two different id numbers of course and look, my random number is 6! they both printed out the same thing! was it an accident? no. they actually both print out the same number so, why do you think that is? yes! at the back. thank you, yes, they both have the same random seed and the random state is part of the process so we've just cloned the whole thing so actually, you can use one process to guess what random number generators the child process is going to create as well because they are indentical it's like your cloned brother or sister or whatever your genetic clone knows exactly what you're thinking so this actually is potentially a vulnerability if you know, if you completely understand the state of a process, you can predict what it actually might do alright, so that's a silly example but I'm trying to show the idea that you start a process, you call fork() and suddenly, you have two processes continuing on past that fork() call
if I've got two processes how could I make the two process start to do different things? right now they've done the same thing, I want them to do different things here's how, we'll check the return value of fork because that is one asymmetry that we have to play with if child is greater than zero, so if the result is greater than zero for my fork guess what? it means I have a child! therefore I must be the parent so now our parent could just exit what's going to happen now? this time only one process gets to print out their random number, the child process we could make this more complicated and we could have our child calling another fork, for example. have many many many more children if we wished the main point to get here is the idea that you are duplicating the world at this point. you are duplicating the process by calling fork and you have two to play with let's put that aside for a moment and talk about that very first program. the very first program we've got here does quite a bit this is an example of quite a bit of system call programming. now we're actually calling system when we're making lots of different calls my question to you is can you explain every single line of this program? if you can, if you've been reading ahead in some of the manuals now's your chance to explain it to your neighbor. if you're not sure about something ask your neighbor. see if they know more system programming than you what is this program doing?  what does every line do? you want a handout? sure. this is the (cut's off) (speaking to a student) oh ok, what was the question? (still speaking directly to a student) we killed the parent process, but now the child process carries on yes, that is how we write the code. we say if I'm the parent just exit so the child carries on. yeah, sure anybody else missing a handout? OK, let's start with a quick demo. This very first line is close one, alright, so if I print something here, woohoo 'hi!' and 'oh no'. ok, right, let's run this we're calling puts, I could've called printf as well. I get 'hi!' but that's all I get, I don't get the 'oh no!' because standard out is gone, we've closed itl  so yes, puts might eventually call write but it's just ignored, that output doesn't go anywhere. I could've for example put printf here, I could've put write into one the following the bytes it doesn't matter, all of this stuff just goes no where, we've closed that file descriptor so one doesn't have any meaning anymore the system just ignores any attempts to send bytes to that particular file descriptor we've closed it, but then where'd my line go... we call open open says hey I'd like a file descriptor please let's see what this returns where's that return gone to, come back here and I'll print it out but I'll print it out to standard error and fd equals what error did we get? I better have some includes here. so if we check the man page for open and I need section two, we are going to need the following three includes. let's grab them so we printed 'Hi!' and we get back from open an integer one it's opened a file descriptor for us, a stream, somewhere we can send bytes. except this time rather than making it appear in our console we're going to make it appear in a file and we gave these options to open to say 'OK, I'd like to open please this file called log.txt, I need to open it for read and write, I want to create it if it doesn't exist, I want to append to it and then finally I'm going to give some options which I also bitwise or about who can read it and who can write it these options are saying that only I can read and write it so let's start printing some things out, like 'Hello', right and we'll run this
okay so we did not see hello in our output but if we have a look down here we'll see we've got a program called log.txt let's have a look at log.txt and it says oh okay it seems to be working, let's see if it appends to it and then it says hello hello alright so we're appending stuff to our log file we've changed the output of our process to go to this file now why is it that that happened? well if we were to read the man page carefully enough about open it says it returns the lowest non-negative integer for a file descriptor and we just closed one so when we do this, it's going to open file descriptor one which is what everything then uses when you call puts, printf, etc so we've now just changed our standard output to go to a file right then we call chdir, what does chdir do, it has nothing to do with cheese change directory! yes, our core process not only has memory for say the variables that we create we've got other things inside our process we've just seen one thing, which is it's got these file descriptors each process has file descriptors also each process has a current directory so when we say hey I want to open a file called log.txt and we haven't specified it's full path it's relative to its current directory so for example, if I had put up here hey chdir and let's change our directory to just kind of slash" okay, let's run this then slash is the root directory and if we look at the root of our disk drive, now we've managed to make a file called log.txt here we go and it's contents is just hello hello right so okay what have we done? we've done chdir. so we've said chrdir to usr/include let's just have a quick look inside there because what is inside ls /usr/include/ a whole lot of dot h files remember in your c files and your c++ files when you say #include std.io hash include this hash include that they are just files, here they are! so next time your friend walks away, why not edit one of them? uh do I have vim on this machine? maybe I have stdlib.h oh I need to be inside that directory okay cd /usr/include/ let's so stdlib.h and it's a bit of a mess but nevermind we can say things like whoops not working, not implemented anyways... we can do #define if while so if you hash define if while, that means anytime you see an if, it's going to replace that with the letters w h i l e very useful if your class is curved, right alright so we've talked about chdir and we've talked about /usr/include now we can have some fun, so we have this, let's just go back to my original directory uh hello, alright I'll reboot the machine right so we have this exec exec thing okay here we go what does exec do? alright suppose you were thinking about something, you're running a program inside your head exec says hey forget that program, do this other thing instead it's a complete mind wipe of your process whatever it was doing, whatever variables you created, whatever memory allocated, it's gone! you're saying this process will now actually be executing this other image right, load this other executable from disk and run that instead so we will run this right alright so when I run my program now, it actually runs ls it actually gives me the contents of the current directory which is just a dot now here's something weird, I can understand that the last argument here might be null to mean hey i've got no more things I want to talk about here" but why is it that I've got /bin/ls twice? okay, here's why: the first one is the command that you actually want to execute so inside /bin there is a whole load of commands here I think we've looked at them before but remember, when you run a command, you want to give it arguments so when I call say ls, so here it is exactly, I need to say okay what do I want to do? well I want to look inside /usr/include but that's not what the program sees the program sees the arguments you provide also its own name the name that it's running as so that's why you see the exec/ls twice because this is the program that we want to run and this is the argument zero that it will get inside main so we could probably change this to just say ls for example okay so that'e exec, notice that my program never printed hello world that's right, it had a mind wipe if exec works, we never return, we don't execute anymore code here so the only way to say print out hello world is to make it deliberately fail I'm pretty confident that that program, that image does not exist so exec will fail, it will return -1 and now it prints hello world it continued on and in fact we can actually print something useful by using perror my exec failed and we used perror it prints out your string a colon and a little message here so here we go, my exec failed: no such file or directory doesn't tell you which line it failed on but at least you have a hint as to the kind of error that happened
right so that's our program in a nutshell so, perhaps we can decide what its actually going to do as a whole time to interview you neighbor what do they think? see if they can describe it tersely in 10 seconds or less what does this whole program do? what does it create. what are the contents of that log file? [students discussing] okay! so we know that all standard output is going to go to log.txt we print out captain's log" to that file and then we run bin/ls let's see what happens I ran it, I didn't see anything on the output here, so presumably, there's something waiting for me inside log.txt let's have a look. oh yes! look at that! there is a whole long listing of .h files inside my log file how did they get there? well yes, when we call the exec we did a mind wipe and it's going to start executing the code of /bin/ls but standard out has already been redirected to go to a file so we change the context in which /bin/ls runs and we print. and because we changed the directory of this process to usr/include, when we said turn me the current contents of the current directory", we got the contents of /usr/include so that's our first significant system program uses all sorts of little commands I encourage you to play with it now, I want to show you a little challenge this is one of the. this is the only algorithm I know that was actually published on 4chan cesspool of the internet okay, so, my question is, what's it do and how's it work? so this is you versus 4chan. what does this program do? notice its got a fork() in it [silence] okay, I think it's time for a demo. see if your expectations are matched, right. so let me give you some values yeah lets do that. okay, here we go. yes, what we have here, ladies and gentlemen, is a sorting algorithm, system programming style it's clearly O(n), right? all we saw is a single loop yes this can sort integers. here I have another example look at that! isn't it brilliant? badum badum badum badum it's still calculating...ok. alright. so how does my order n algorithm work? alright so it goes by the name sleep sort" and like I said, this was invented in 4chan, it's not actually published anywhere else but it's a nice cute example of using fork() and atoi that we've talked about these things and sleep() so how does this thing work? well it makes a whole lot of processes in fact, remember that C tells us the number of arguments to our program so this is going to pause every single integer when it does, it makes a whole lot of processes that because we're counting down C, it makes enough processes one for each integer that we provide and each process gets a different value of C because it exits the while loop at different times so, each process ends up calling sleep() for the right amount and then prints out the number so, if you entered 1 it sleeps 1 second if you enter 100 it sleeps for 100 seconds
alright, the only other thing I want to say about this. this is the second semester I've presented sleep sort. Before that CS241 didn't have a sorting algorithm and it kinda felt lonely because 125, 225, every other theory class you take has a sorting algorithm. now we can proudly say, yes, system programming has a sorting algorithm right, so, questions about this algorithm? other than never use it! right so clearly it's got some limitations. sleep's going to count for a second in seconds etc and also it relies on the operating system to implement sleep so it's not truly an order n algorithm. the operator is just delegating all the work to the operating system to make sure the processes sleep the right amount of time. in other wrods, when you call sleep your process gets stuck, it's not going to execute anymore instructions until the operating system wakes it up. we'll be talking about how it does that when we talk about scheduling later on in the course let's go back to some more serious questions. what does the child inherit from the parent? all the money, right, no.  what've we got? what've we seen so far, what does it inherit when we call fork? what do you think it inherits? what do you get? i'm sorry? variables, yes! so you get a copy of the memory all of the processes memory you get a complete copy of that. ok, what else? that's kind of all in the memory, yes all of your c variables etc, the state of any kind of libraries like the rand. state of the random number generator. what else might you get? OK, I'll give you two. current directory and open files if you've opened a file you'll fork will also be able to read and write into that file. more about that more later in terms of the details in terms of what happens when both the parent and child read and write into the same file what's different between the child process and the parent process? here's a couple of differences. first of all, guess what, if you call getpid you get different numbers what else is different? the return value of fork  if the result is greater than zero you know you have a child and therefore you must be the parent oh yes there's something else that's different what do you think getppid does? yes! parents! hey I want to know the ID of my parent so of course that's going to be different you could probably write out a program to print the parent ID in two different ways. in the parent if fork returns a number it's easy, it's my ID. if i'm the child then I should be calling getppid to get the parent so if I've got these two processes and I've shown you that we can write an if statement so they can do two different things, how can I make it so my parent waits for the child to finish? easy, we call wait or waitpid. let's have a look at this I will write a little program that immediately forks if result is greater than zero..what? I'm the parent OK, what should we do with the parent? let's wait for our child to do something so how do we finish? for this we'll look up waitpid we'll say who are you waiting for? I could pass in minus one to say 'hey I'm waiting for anybody', but actually I care about my child finishing then I can find out what happened to them, so I can basically do a post mortem on my child here and I can pass in some options but I don't need them for this lecture so I want to put zero let's have an integer and notice that I'm passing in the address of the integer if I do that waitpid can write it's notes into that integer because I've given the address of the integer now we could print something out about the child. percent d... waitpid said ah, didn't save it our program get's result. what does our child do? our child does nothing. well actually it just gets to the end of the program, it finishes so the child says 'oh my result is actually zero so let me do what's down here. OK, nothing, I'll just finish, I'll just quit' we could write some special code for the child though. why don't we say sleep for a little bit like two seconds and then quit byeee
okay so if this works, then what we should see is the child will sleep for two seconds and our parent will then be paused also for two seconds because it had to wait for the child okay, so one, two, bye and then our parent can continue right? so we've made the parent wait for the child now there's a little bit more to using waitpid that actually there are some macros down here  here they are, that actually to put useful information out of this, I should use these macros so for example, we can find out the exit value of the child but only the lowest seven or eight bits sorry, eight bits, so if your child return a value 42, great we can see that if it returns a value 304, I'm sorry you won't see that as a value, you only get the lowest eight bits we can also check to see if it was terminated by a signal right, how can you generate a signal? pull our a whistle from your pocket, yeah but you could also press control c on your keyboard to interrupt a process and when you interrupt a process, you are sending that process a signal there's other signals that can happen as well so if your process tries to write into read only memory, your process dies how does it die? it gets sent a signal that in cannot ignore so as you can see, we can actually find out some things about our child and you'll be using that in this week's little assignment before section alright so let's make it print something out, right so in this case what we'll do is we will say if it exited, so let's check the value of status then we'll print out the exit value WEXITSTATUS we'll get those lowest bits and we'll make the child return 42 did it run? one error, what's my error? oh, okay so I have not included something.. one two yay, okay great so this time you can see our waitpid got some arbitrary value if you actually want to pull out the exit value then you should use those macros alright so if exited, then we know that we can actually pull out an exit status as well right, so how do I wait for my child to finish? waitpid! and on here how do I find the exit value? you should use the if exited then we can use the WEXITSTATUS macro and all these macros do is just pull out the relevant bits and do some bit shifting from that original integer okay, right so are you ready? page 2 how do I start a background process? well a background process is something that we want to run in the background right we don't care about interacting with it maybe I want to actually say compile a program in the background let's do it from the command line here so for example if I want to look at the contents of /usr/include/stdlib.h right, I could say that actually I just want to send that to a file but I don't want to wait for this to finish well I can just put an ampersand at the very end that means run it in the background and I can continue doing this whilst that copying happens we could do the same thing in C by not bothering to wait so I've got my fork here and I could do other stuff in the background  sorry I could do other stuff inside the parent and not wait for the child to finish so this is why fork is very powerful right? now I can fork and start a process to compile something. I could fork and start another child process to connect to the internet and I don't have to wait for these things to complete I can do things in parallel yay right, so now if you've got 4 CPUs you can use all four at the same time to compile different parts of your program for example there is a problem though good parents don't let their children become zombies suppose you created a child process and off it goes and it starts compiling stuff and then you the parent process finish, you quit what happens to the child process? it's still alive! ha ha ha compiling alive, it's still going right! but it has no parent uh oh, right, so, uhm, so here's what happens, if nobody is around to wait for the child when it finally finishes if you don't call wait on a finished process, you get a zombie so a zombie is a dead process that no one cares about so waitpid is like going to the gravestone and saying yeah I remember you let's do a postmortem  if you don't do that to a process, the system says well actually somebody might want to know about that process they might want to know its exit value for example so it's going to take up some system resources, not a lot, but a little bit to remember what happened to that child so that's what a zombie is, it's a dead process that nobody cares about
alright, doesn't sound too bad, right? but what would happen if we had too many zombies? eventually, the system says I'm not creating any more processes for nobody" yes? I will kill another process so your fork(), for example, would fail or another processes fork() would fail. okay so, you can do that. the child will continue and the child will do what it wants to do. okay? um, so, uh, the system has one thing it will try to do to prevent zombies. which is that in this situation if the parent finishes, and the child is left running that child is re-parented given a new parent so if it called get ppid(), it doesn't crash, it doesn't explode, no it has a new parent. I'll tell you who the parent is process 1 the ultimate of processes. the first process in your system. the first process that ever existed when you booted up: process 1 well, kind of the first process the first process with a process number anyway the ultimate of processes right? which classically has been initially or just initiate or just init goes by various names and it calls wait on the poor little orphans alright, to ensure that we don't get zombies. so, life is not too bad if your parent dies right? the children as they finish, they will get reparented onto init. then init will make sure it calls waitpid on any future children that die so, we run into problems, though, when we have a long-running parent. so let's say you made a webserver well the parent tries to live forever, wheeeeee, it's going to keep going around, hey! lets just run forever, right? and I'm going to serve the web request. and for each web request, I make a new child so if we have it so that the child does the work, each web request, each HTTP request we might run into a problem now because the parent is making all these children and never cleans up after them so in this scenario, when you've got a long-running parent, you've got to remember to call wait() or waitpid() because if you don't, you'll have a whole lot of zombies you'll have a whole load of exit values and other meta information about the process thats still just lying around inside this system okay, so, you must remember to call waitpid() to clear up or to prevent zombies okay, alright, so, we won't talk about signals today. instead, let's see if I've got some notes okay! right! just a heads up, we'll shortly be publishing this so, your assignment for this week is two-fold first of all, time to jump into android get the SDK and the NDK installed and working on say, your laptops or start using the lab if you don't have a laptop we want you to basically make something simple and [something] to get as many people as board with actually using the NDK/SDK if possible secondly, you'll be using fork() and exec() and the stuff we've seen today to make your own simple make" program which we've called "fake" instead of "make" so, let's have fun with learning to program fork() and exec() and enjoy your weekend! thank you very much! Questions come and see me now or find me in the coffee shop. questions come down and see me now or 5 minute coffee shop
good morning cs241 people. how are you this morning? great, how's everybody else? alright, let's try this again. okay, alright, yes, good morning! you've enrolled in cs241, for better or for worse, you'll learn a little bit about systems programming and for the next 50 minutes, we are going to talk about some new stuff, some old stuff, some [something] stuff, some blue stuff I lied about the blue stuff alright so, all I have to do is open my mouth and talk and type. all you have to do is open your brain and think how hard can it be? let's try again: good morning people, how are you? great!! good morning class. alright, so, the reason I do that is because maybe we'll get a few brain cells working before we actually dive into this stuff, okay? so, here's the exciting news. yes there are exams in this course. there's no single midterm. instead, there are multiple choice exams scattered throughout the course and the first one will be on Friday yes, so, please come on friday, bring your icard, bring a pencil, and look forwards to multiple choice questions which go over the things we've covered so far anything we've done in lectures or you've done in previous sections, it's fair game. okay, so I'm looking to make sure basically that you understand the basics of C programming so as a result, some of the questions we've got today are to do with [something] in C. alright so, where's my handout? okay, let's have a look at this first question then, right I've written a C process, or any kind of process really, that runs for a long time and it's creating other processes so for example, it might call fork() and then the child process that you've just created calls exec but we never wait for our children to finish but they do. but we never call wait on them what have we created? zombies! yes! we've created dead processes, processes that have finished but no one's cleared up after them now, if you see any zombie movies, you'll discover there's different ways to kill them. right. but, running away is usually what's recommended in most zombie movies but fortunately, what we do in C programming is just call wait, and when we do that, the system can kind of clear up the mess left by the zombie if we don't do that, then eventually, we're unable to create new processes. the system runs out of space alright so yes, we've created a zombie in this case so a zombie's a dead process where all we're returning essentially is it's exit status. but it's still taking up a little bit a system resources because we haven't finished cleaning up after itself and it only happens if no one ever calls wait so for that, I need a long running process so let's see what happens in the other case where my child outlives the parent. would you like a handout? we have a question that happens when the parent dies. okay? so that's why the question up there says long running parent". the parent hasn't died. it just doesn't care about its children the children have finished, alright, perhaps they've called exec" and done an "ls", perhaps they finished doing a computation, perhaps they finished serving a webpage to a client. the point is, the child processes, once they finish, they're still taking up space alright so, let's not have a look at a zombie. let's have a look at the other case that you just brought up which is what happens when the parent finishes first? ok, so, I've got a little bit of code here, and uh, first of all you could ask, what's it actually print? the answer being nothing! because actually if you look at it, you'll see this #if #endif those are preprocessor directives to tell the preprocessor to say well if this expression is true, then include this, otherwise don't" and, so of course right now, there is no main method. compiler would never actually see the code we wrote in here right, I could write garbage in here. like, alright, you know I could write superbowl" um, and it's not gonna find an error in there because the actual compiler doesn't check for the syntax. it keeps going until there we go alright um, so let's fix that, let's just say #if 1 okay, right, and we'll run this and a question for you is, before I run it, how many times is it going to print I am process" cuz you see it happens before fork() and secondly, who's sleeping? is it the child that's sleeping or is it the parent that's sleeping? if you made up your mind, tell your neighbor. see if they agree with you if you're not sure, at least have a guess okay! alright! so, who's sleeping? is it the child or the parent? the child! remember, fork() returns twice, if you like. because, when we call fork, after it executes, we've now got two processes. we've got the original process, and the clone the doppleganger that believes it really is the same original process because it can look back in its mind and say yes, I was born in kansas" right? it remembers all the variable states but its actually got a copy of everything (well, nearly everything) but there's one asymmetric difference which is that, if you're the child, your return value of fork() is zero so we are asking the child to sleep() okay, meanwhile then, both processes carry on independently, you can imagine them running on two different CPUs they're completely different processes. just like you can be running Minecraft and working on your chemistry homework at the same time and we print something out. we print out our pid and our parent's id. so let's run this...see what happens
alright, so, the first surpise is that we see 'I am process' twice that's weird, why did that happen? let's talk about in a moment and then second thing is one of the processes said: and my parent is 1 okay, how, why? well remember we made the child sleep. we made it sleep for an extra second. in that second it's original parent finished it exited. so now what are we going to do with the child now? who's parent should it be? and now's where the system says 'I know what! we will reparent you back to the ultimate process' parent process id one so that's what happened there. if we didn't have this sleep then we have a race condition. maybe the parent finished first, maybe the child would've finished first we cannot say for sure who would finish first so that's why we put the sleep in okay, but why is it that we saw 'I am process' twice? OK, if you think you have the answer wave your hand in the air like you just don't care. you care alright, very good yes. okay! so, a few people know. i'll give you a hint I'm going to change the program very slightly by putting '\n' in there and now you only get 'I am process' once. so by putting  '\n' in there I changed the output of the program quite significantly. what does '\n' do? yeah! thanks. in our little example here, C decides to flush the buffers. so there's abuffer inside the process and it's just collecting bytes. just collecting the characters to print out but it didn't bother to actually write them out to the system yet. it only decided to do that when we saw the new lines. so in this example we ended up callling write(), we printed it out, before we called fork() in the first example it was still inside the process so when we forked it was still there inside the child as well. the child says 'oh yeah,I've still got these bytes to print out. I haven't got round to it yet' so be wary about this. the other thing to note is that at the very end of the program part of the clean up that the C library does is says 'hey ok any open file descriptors if you have something to write out do it now because this process is closing. it's time to flush all the buffers' so it does that as part of the standard clean up process right, so that's a little example there. how much buffering actually happens depends partly on wheter your trying to send it to a terminal or a file if you're sending stuff to a file it will actually keep buffering beyond the '\n' so it tries to have even better performance by buffering stuff out to a larger amount before writing them questions about this example? yes? right, so if we choosed fprintf()  aha, OK, right, so puts() is equivalent to printf() %s \n. OK so that would've actually flushed it as well and so if I used fprintf() the same thing would've happened if I sent it to standard out because the buffer of standard out by default when I'm sending it to the terminal is to wait until I say new line if I send it to standard error, well lets just do it. we would have seen it once because the default for standard error is just to push things out. we don't want to wait, we're not trying to get high perforance. you want to know your error messages as soon as possible just in case the process dies very quickly alright, so, if we wanted... remember how I said we've got somewhat of a race condition? I've just put in a sleep for a second and that kind of works on this particular system if we wanted to actually wait for our child  then I can call waitpid(). so how's waitpid()? let's check the old man page. waitpid so, you see we pass in the pid we got from fork. we can get some status information and there's some flags as well that we don't need today so what we'll change now in our output? ok, what's our little error here?  oh I didn't declare a little variable. there we go OK so this time the parent of the child is still the, huh. OK. why would that be? so the parent is waiting for the - oh. okay, yeah we called waitpid() on two, we should only be doing that inside the parent, so let's do that for the parent. so if I'm the parent then  we'll wait for our child to sleep OK yeah now thats sorted, that makes sense. right, so, what've we got there? the orignal one is 198 and it's parent is 43 which is probably this little shell program here that's running and the child is 199 and it's child is 198 so we should have two numbers right which are the same this is the child saying 'oh look here's my parent 198 and this is our original program 198 saying my parent is 43' so, you can actually discover all the processes running on your system. this one doesn't have that many and I don't know if you've got pstree involved you can use ps and pstree to kinda get a hierarchal view of all the processes that a process has. there's different options to say OK, I want to know about my process or everybodys processes but don't worry that's not on the test, okie dokie...
so, now it's time to talk about signals unless anybodys got any last minute burning questions ok, right, signals are called. there's a lot to signals we're just going to do an introductory part today but signals are the software equivalent of hardware interrupts so, think about hardware for a moment  i can have things like a clock timer that goes off every say hundred milliseconds  and interrupts what the CPU is currently doing and when the CPU sees that it says 'oh I'd better stop doing what I'm currently executing' and run some additional code thats gonna cope with the fact that my little clock timer has gone off or I've got some bytes from the disk which are ready to read and I want to stop what I'm doing and execute some different code or some information on the USB bus has arrived like someone plugged in a USB keyboard or typed something and I need to handle those bytes right, so interrupts allow us to stop doing what we're currently doing and process some different code we could do the same thing with hardware and that's signals and, we can send signals to our children and we can get a signal back evern when one of our children dies, which is useful and we can have a lot of fun with them because they can do differnt things so, first of all, that's a list of all the processes let me send a signal to one of these processes so, uhh, ok, do I have a pid variable here? no I don't. okay so, let me just send -9 to say process 43. what've I just done? yeah, I've killed myself ok, the kill command says 'send a singal' and -9 is the ultimate of signals - hint hint - terminate this thing with [something] it can't stop this signal if you send this signal to a process that process is gone there's no way to protect against this signal this is the big weight falling on top of a signal. this is how you can kill processes so if you know - if you are a superuser and you know a processes id, you can get rid of it OK, so fortunately I have another processes here. let's see if this one works unfortunately I can't actually write any code so it's time to reboot my machine okay, so! we can do something similar in our programs as well let's pull up some example code here alright, we won't do that straight away, ok, so here's some typical fork exec() code the child decides to run /bin/ls and the parent will do something else so, let's first of all just start off with this. there's nothing new in this code, I just want to prove to you that the child runs exec() here and should print something out here we go, so yeah we'll move on it. the child runs okay now, what we'll do this time is I'm going to make the child sleep for one second because now I'm going to call kill() from my program here. I think you can guess what's going to happen here alright so, we'll check kill() on section 2 and you'll see that we can send a signal to a process alright so, we have the id that we wanted to call, there it is, it's called child, and what should we send it? well let's send it signal 9 oh, we had a sleep there. so this time you'll see the poor child never got to run /bin/ls, we klled it and it didnt' stand a chance we could also send a signal called SIGINT, in fact, rather than send it to the child, why don't we send it to ourselves let's do it straight away I wonder what SIGINT stands for ok, so the SIG is a standard thing you'll see prepended toward the singal of different names INT stands for interrupt remember how you can press ctrl+c and the program stopped? this is how it works the shell says 'oh look, look, someones trying to press ctrl+c, I will send SIGINT to the running process' and that's how we break our processes well, this is where the fun begins. I don't have to see my processes die when you press ctrl+c we can do other things for the SIGINT and for that we're going to look at SIGACTION SIGACTION allows us to register a callback function that's going to be run when the signal is given to this process ok, so, here's how sigaction() works. I didn't want to use sigaction(), I was going to use the simpler version yeah, let's use signal()  we'll talk about sigaction() later on in the course ok, this is what I wanted to show you. so our typedef here. is that large enough for people? can I make it larger? can you read that at the back?
okay alright so, we've got a typedef that say typedef void (*sighandler_t)(int)" and then this sighandler underscore t. let's talk about this for a moment. as to how to parse this alright, so we know that typedef just really means hey! I'm an alias" I'm just defining a new type and in this case, this is a function pointer so, we can [something] this by unpacking it from the inside out. so, we can have a function that takes an integer and returns nothing and, our type goes in the middle (between the parenthesis) so have a pointer to a function. in other words, just, where do we want to send the CPU to actually execute some code? here's our little function that's gonna happen and then I can install this handler for a particular signal so should a certain signal happen, run this handler alright, so, let's do that I'm gonna have a signal handle then. and I can call it noway. I can call it anything I want, really. remember it takes a void. call it agentsmith alright, you'll see why in a moment. and remember it takes an int so, at this point, we'll write something out. like, you can't stop me!" okay, how many letters is that? who knows? about 13 and, we want this to run anytime someone tries to stop this program so, let's use that signal() thing so we'll say signal when I get a SIGINT, run agentsmith and, then i'll have a little loop that does a. keeps itself busy. while(1) loop forever so, while true, keep going alright so, let's run this little program here okay, off it goes, and let's try and press Ctrl-C oh no! alright, you can't stop agent smith here. anytime you press Ctrl-C, that signal is delivered and fortunately, you can press Ctrl-\ and that should okay, there we go, alright. I can at least Ctrl-Z it so I can actually stop the program. so something else to show gives me the ability to pause the program. and if I wish, I could actually put that into the background. does it support it? okay, yeah, it does and now its in the background and now it's just running and using up my CPU if I do ps", there it is. it's running. it's used up 32 seconds, now its used up 34 seconds of CPU, I'd better kill it. okay, kill minus 9 106 it's gone! remember, SIGINT you cannot stop. so you could try to. sorry, SIGKILL or SIGTERM you cannot stop SIGTERM alright let's go back right, so let's first see what it's going to do with child processes. here's the whole thing. let's change our message to say child finished" and this time, we will make our message a string here so char mesg I can get a signal when one of my children dies so strlen(mesg) okay, right, so, write out the number of bytes that's in that message so now, rather than doing SIGINT, guess what, there's something called SIGCHILD and let's make this a little larger and this time rather than looping forever, we'll do our fork() and now when the child is finished running ls, why did it, oh, aha! that's not gonna be very useful, okay. we'll get rid of the sleep() there as well so, this time, the child runs ls hopefully, oh, no. SIG, oh, I can't spell yes, for some reason, CHLD is spelled without the I I guess bytes were expensive in those days? okay, alright so, hooray! here's what we've got the child ran and then the parent was notified asynchronously that the child finished so if you wanted to do some stuff in the background and you're worried about zombies, this is the perfect place to put that waitpid to say hey! I need to clean up my children" so that's in fact a very common convention with these kinds of programs is, if you don't want to just fork() and then wait() immediately, just write yourself one of these signal handlers and then we can put our waitpid in here so, we'll need to know the child id, we have a status variable, and a zero here, okay the last thing I need to do here is that child itself [something] out of scope here. so instead, let me declare as a global variable now, global variables in large programs considered [something] programming practices. however, you will often see them in small, single-file system programming examples because it's an easy way to communicate with signal handlers alright so now, okay, well, you can imagine if I was actually able to type, you can see that we're being good citizens and we're cleaning up our children using a signal handler
right, so, let's go back and up. what've we got? alright, what is a signal? It's a software interrupt. it interrupts what the current process is doing how do they work? that's a good question. there isn't a quick explanation of that that's any good I suppose a short answer would be 'hey we'll cover more in later lectures' but a slightly more useful answer would be that the kernel delivers a signal to the process  and I've shown you two kinds of examples an example where a signal where we can register a handler for that signal and we can change the default process the default example of the SIGTERM where you cannot register a handler and instead the system will actually destroy your process. will actually quit your process right, how do I send signals programmatically? remember? OK, so it's not signal(). if you call signal() - it's not the right answer - if you call signal() this registers a handler instead what you need is to say kill() seems pretty mean, right. all of a sudden we're having a bad day when they designed these things my assumption is that the very first signal that was developed that was useful was the ability to kill other processes because they got out of control and then this interface was extended to include other signals like  'hey my children finished' or 'hey I've got some bytes that need some processing' so with kill we pass in the process identifer and then a signal name such as SIGINT or SIGTERM how do I send a user defined signal? easy! we can call kill and ister them sigusr1 and sigusr2  why should I use signal symbols not the constants? well because the actual constant value varies from operating system to operating system exception being the early signals that were defined way back in the history before I was born and the one that everybody knows is that nine is the same as SIGTERM, just kill a process so it's a common idiom to say 'hey kill -9' meaning this process cannot escape, we're going to stop it and finally what's the alarm signal? ok, this is fun. when I make a process we can set up a process so that it gets a signal in so many seconds. so it can say 'ok I won't have an alarm in 3 seconds' so now I can have a little program here for - let's do it the old fashion way of C for i is zero, i less than something, i plus plus printf %d, i and we'll sleep a bit OK, so, we've set an alarm and then we just start printing out the numbers to start counting this is the evilist alarm clock you've ever seen. it kills your process! um, most alarms don't do this yeah, the default behavior for the alarm system is to kill your process and, where does the word alarm clock come from? that is actually the shell saying I'm going to call waitpid() on the program and then I'm going to use those wait macros that you've seen to determine why my program finished or what happened to it. oh look my program finished because it got a signal alarm clock. and so the shell prints out something useful to alarm clock we of course could do something different form that. we could register a handler for this ok, so SIGALRM - if I could spell it correctly ok, and I'll call it thanks void thanks() takes an int and I'll write one Thanks!" and how many letters is that? I don't know, about six, right? so let's run this now and if it works then in three seconds we'll get thanks hooray! good and now you see our program continues and now I need to get out of it so that's the alarm signal you could use this for example to give a child so many seconds to complete if it doesn't complete you could deliver the alarm signal to it questions? ok, page two! <pause> alright, so we did this. we did this, right? we talked about how this is inside the process it's inside the C buffer for standard out because there's no new line so when you call fork we end up with two processes which now continue and they both have I'm a process sitting inside the buffer waiting to be flushed, waiting to be sent
right, now then, let's say I want to review some C code let's say that you're trying to write a function called your version of strdup and it's purpose it to take a pointer to a C string and create a new C string by allocating some memory say on the heap or yeah, let's say on the heap and so let's have a look at the following code, perhaps we can figure out what's wrong with this code so, here's the code so far, we call assert() on source then we write a line of code which is going to be a, b or c then we say 'ok character p equals result' and then we have this idiomatic C loop here by idiomatic I mean here's a comon way that you see C code written where we want to copy things written from one side to another what's it do? and then finally we'll return p so, here's what it'll do, here's where you come in. I've got three different versions and also do you notice any errors?  anything you want to change in this code? ok, and two other kinda questions down here alright, have a go with that for five minutes. see if you can answer those questions. what happens for a, b and c and those other two questions. question two, question three. I'll walk around in case anyone's got any questions ok, so, that assert() call at the beginning. the nice thing about assert() in production code it disappears, there's no performance overhead. it's not even evalutated the macro compiles to nothing, so the purpose of this is during debugging I want to catch early if someone gives me a bad pointer right, so if we say character result, then anytime we use the variable result in the future it will point to the beginning of the array  sounds great, we can use up to 256 bytes, in other words a string with 256 pics, 255 letters and a 0 byte at the end which fits however, this is an automatic variable stored on the stack, which means it's scope is only for the length of this function and, if we try to store anything in here, that's ok, but it becomes meaningless after the function returns so, yes, we can return a pointer to this array, but don't expect that memory to be valid after the function returns so, that's no good. we need memory that's going to exist for longer than that so we turn to malloc() to say 'hey give me some memory on the heap please'
right, okay uh, couple of problems here. one is, size of source so this tells me the size of a pointer so that's either going to be 4 bytes or 8 bytes oops. I didn't want that. I didn't want the size of a pointer. I wanted the actual number of characters stored at the pointer so, okay, let's fix this, oh yeah, that should be a pointer in there of course I want result to be a pointer to some memory. so let's call strlen on source hey! keep walking along until you find that zero byte. what's wrong with that code? yes, we're not going to reserve enough memory. so, in doing the copy, we will put that zero byte into some memory that we don't own that memory might be being used for something else so, we have a buffer overrun there alright, so, and then, the rest of this code walks through copying bytes and it might seem a little unusual to put an expression like this inside that while(), but this is kinda of a common example in C where we copy a course of bytes from source to the pointer, we increment both, and we keep going until we've copied the zero byte and when we've copied the zero byte, the result of this expression is zero, so the while loop terminates many compilers, by the way, would require us to put an extra set of parenthesis around this. otherwise, it would give us a warning you will also see similar code inside if() as well. where we assign a result to a variable and we also use it to [something] an if-expression alright, how are we doing on time, okay, we should keep going. so what's the purpose of 2? to check that the argument is non-null. when will it have no effect? well, when a macro is a defined so its when no debug happens to be defined...whoops, and you can set that as part of an option to gcc and if you do that, then assert compiles to nothing alright so if malloc returned null, where would our program crash? would it crash at line 4? if result was null, would this crash? no, it wouldn't. p would just simply hold the result of 4 we haven't tried to follow the money okay, so we've got an address (think of an envelope) and we haven't written a valid location on it, but we're not trying to read that memory we're just pointed something bad. we haven't actually followed the pointer yet so, it would actually crash when we try to dereference it. when we try to write memory in. so, its when we actually try to write to that location, our program would crash so how do we fix this? we could say well look, if the result is not valid, in other words, if it is 0, then maybe print out an error message and exit or perhaps return nothing" just say okay, I'm sorry, I could not duplicate this" and hopefully whoever calls this code is checking to see if the value is also NULL right. so. okay. did I ask a question for this one? right, what will this print? let's see if we write this out. so we've made an array of ten bytes and we, copy in 'ab'. so we've got the following: we've actually copied three bytes: we've got an a, a b, and a NULL byte or a zero byte at the end to mark the end of the string and then we make a new variable called p2 which is p1+1 okay, so what type is p1? it's a character pointer. so p2 is pointing at this memory location, where we copied the b into now we do strcpy into p2 and we copy 1 2 so we're going to copy 3 bytes we're going to copy the 1, the 2, and a NULL byte so when we try to print this out, we're going to print a12 and then stop because we get to the NULL byte alright, oh I've got a few minutes, we'll be okay. alright, what about the next one? is the following code valid? what have I got? so I've got a pointer a and it's going to point to xyz I'm not copying it so think about this for a moment. when you load your program in, and it starts running this process, at the bottom of the memory that we've got, we've got the code! and then we have our constants okay so a is pointing to some memory inside this constant. the stuff that we've loaded off disk. the xyz. those bytes. a is looking at that address in there and then we say I've got a pointer to a pointer to a character" in fact we read this backwards, so b is a pointer to a character pointer and it holds the address of a so b hold the address of a. it holds the memory location of a. so I could use that, I could use b to change what a is pointing to, and that's what we do here so, why didn't what b is pointing to uvw" ? so what have we done? we've changed a. so now a is pointing at a different location it's now looking at a different constant inside our memory so we didn't actually copy any strings. we're just changing pointers around right, we'll do this one. what's special about sizeof(char) ? it's defined to be 1. a character in C is always one byte yes, uh, oh yes yes, I'm sorry I forgot to, yes, there is one bug in here. which is, we should've returned result not p okay, last two things: printf puts putchar and all those other C macros end up calling write() on stdout which is 1 and the final question for today: what will the following code print? we malloc 128 bytes. if it failed, if it gave us NULL, we just exit so lets assume it didn't fail, and then we do puts what will it print? okay, so we can answer this and say here's the most likely thing it might do" it's the very first byte of this might be zero so, that's just an empty string so, all that's going to happen is that it'll try to print an empty string. what does puts do? it prints out the string followed by a new line so that's probably the most likely thing to happen however, does malloc zero bytes for us? no! that could be anything in those bytes. it could print I love [insert your worst football team in here]" whatever! it could print anything! it could print out more than 128 bytes it could print I am agent smith" arbitrarily, what is in those bytes. and with that, have a wonderful week! and I'll see you on wednesday!
alright, good morning class, how are you? oh! good! great! how's everyone else? okay....fine...ehhh...middle of the week blah blah okay so here we go. in blehh try again so, in the next fifty minutes here's what we're gonna do: we're gonna make sure you have a good understanding of fork exec wait, we're gonna look at a couple examples. we're gonna start about some common gotchas and a reminder that some interesting things are due for tomorrow's section! so, you might say well hold on a minute, this week's section makes me jump into the deep end with android and commit somehow to subversion. no explicit instructions. yeah, welcome to the real world or at least, welcome to a simulation of the real world as we kind of say goodbye to CS125 CS225 ecetera, we lose the training wheels a bit so yes, we will give you more explicit instructions in the future, don't panic quite so much. I just wanted to give you an experience of saying look, this is what its like" yeah! It's evil it's tough. instructions are never as clear as you'd like them to be and something strange happens. people start looking at you as if you were the expert in the room just because you know a little bit more about say the other people working just because you've taken the time to say read the man pages or do twice as many google searches or just figure out the best way to work it and yes, in setting up things like android, it doesn't work first time so now, you need to be a hacker in that sense. of saying, what can I change? what can I break, what can I unbreak? perhaps I should try a different device. perhaps I should try plugging it in again. perhaps I should try turning off and on again, right? perhaps I should learn about uh, trying to, I've got a problem say it doesn't connect to android well. is it my device driver? how have I not set thing up correctly? perhaps I should I reread the instructions to see if I missed a step these little basic skills a software engineer has to have so, one one key skill that I hope you get out of this week's setting up the section is tenacity damnite you can be more stubborn than it that you can figure out ways to try and break down the problem. maybe I should try someone else's tablet. maybe someone else should try my tablet. maybe I should umm, uhh, do an experiment to see if something at the low level of the USB is noticing if the tablet is connected that kind of thing. maybe I should check to see if it's using the right version of java. etcetera etcetera etcetera. try to take a problem and breaking it down and using your brain cells to try to make progress. I didn't say it was going to be easy, yeah, welcome to the real life. okay, well, welcome to real life right, so, enough! let's put that aside. the next thing you'll need for section is to make make" or as we fall it, fake", alright so, why? because make allows us to build larger programs and at the end of the day, guess what? it's just a C program it reads in a set of commands to execute...and executes them! except it tries to do it with some sophistication so rather than, for example, compiling all possible programs, why don't we compile the ones which have already recently been edited? or let's make it so that we can make a debug version and a release version or let's make it so that it works not just for C programs, but with python. you can even use make" by the way, to generate thumbnails of images so next time you change an image, you can automatically generate thumbnails I used it in the videos because when I exported each of the little 7 minute videos as an mp4 file, I wanted to have an old version, I wanted to have a webm version, the basic 3 formats of video on html 5 these days and so I used make". any time I made a new version of the, uh, I, anytime I exported a new mp4 file, I produced make to say "oh! look! this source file (my mp4) is newer than the targets (or the targets don't exist)" then I get make to run a transcoding program to generate the other versions so make is very powerful and you can also set it up to do things in parallel which is fantastic if you happen to have, say, 8 cores, or 200 cores you can make things go much faster alright so, let's turn our attention to some code here. we're playing with fork() and we've got it set up so that after fork returns, I'm going to get the parent and the child to do completely different things I put them into two different functions so, remember, after fork returns, so let's write our little fork here you've now got two processes, you're writing code for two separate processes, isn't that cool? they happen to share a common ancestry so all of their variables currently have the same values for example (apart from the return value of fork) so, now we make them kind of have different futures. different histories. okay so, that's the kind of first important thing, first importantly to remember is that you're writing code once, but it's going to go for multiple processes. it just so happens that we can use return value of fork() to do two different things. okay so, I checked so that the value is greater than 0 if it is, then I must be the parent if it's zero, then I must be the child so let's run to the code. there's actually one other case. fork() could fail. if it does, what's it return? negative one, yes so, we should print an error to say hey, fork failed" what's the easiest way to do that? just use perror() ! so print perror prints out whatever you said, followed by a colon, followed by a completely cryptic error message which is completely useless to users but hopefully gives you a little idea about at what point your program failed. so as you start to write more complicated programs, it becomes important to check for the return values. and in fact it's quite usual (just read the man page) to discover that it returns, say, zero, or more likely negative one if things fail so when writing more programs, when it doesn't work, say oh okay! when did it stop working?" maybe I should actually check return values and discover when it broke
ok, so that's the beginning of my program. I've made some gaps in here and so perhaps you and your neighbor could fill in the necessary code on this program and figure out what we should write for the child and the parent in the child process we want to ask for an alarm signal please so we can say alarm() one, which means in one second or so the operating system will deliver, will send a SIGALARM to that particular process and once the - what happens by default when you send a SIGALARM to a process? it kills it, right! that's a pretty evil alarm signal, yes? but that's what the default behavior does we could stop that if we wanted by registering a sig handler, but today we're not going to do that. instead we're merely going to sleep for two seconds after we sleep for two seconds we're going to print something out and then we want to exit normally how do I do that? i just say exit() and let's give a return value like 0 so my child process is pretty simple now the parent is going to wait for the child to finish how do we do that? we can call waitpid() pass in the process id of the child we'd like to collect some information so status and we don't need any flags today ok, so how do we decide if the child has exited normally or not? well let's do that one, so that one was - what WIFEXIT or EXITED, I'll have to look it up in amoment and now we need the exit status so let's find out what it said
ok, we can also discover if the child exited due to a signal, so let's do that as well so let's say 'look if WIFSIGNALED then let's find out what singal it was okay so how do I pull out that? I think it's WSIGTERM? -TERMSIG, ah. ok and we can print out a helpful message right because not everyone knows those numbers so what is the number for SIGALARM? it's just this constant here SIGALARM right, shall we run this? let's try it. see what errors we have here ok, what have I messed up. SIGALARM, argh, right, let's try that ok, where's the mistake? line two hooray! ok, so it prints 'Hello World', starts up and then the parent says 'child exited due to signal 14 alarm clock' let's make another program over here that - let's see, I'll tell you what I'll have a pointer there we go, and it can be a random number just cast that into an integer pointer and into p we will write the value 42 will it crash? who knows what it'll do ok, so this time we go 'child exited due to signal 11' what's signal 11? well ok it's not going to get you invited to any parties but it's turns out signal 11 happens to be segfault so, we could keep going with this and say 'look if the thing was' - I'll just write it - 11. I could spend some time - oops, seg fault - write a better a program!" so you see those messages like segmentation fault and an error that commonly comes up that says 'segfault write a better program' right, so, you see those messages like alarm clock, segmentation fault, that kind of stuff. they dont' just appear in the terminal by magic, no! the shell is doing what we're doing here and that's what your fake program is going to do as well. that after a command finishes use these macros to discover what happened to your child and print out the relevant information so, questions about that? alright, so, now you actually have enough knowledge to write not only make, but a shell and we're going to have an MP based on that where we can take just user input, what you type onto a keyboard and then start executing programs so the shell that we normally see is either bash or a simpler version called just sh, but it's just a C program that reads input and then calls exec() based on what you typed ok, other questions about this? alright then, let's have a look at some other questions on here so, when I start my program and I want to find out what arguments it was given. so for example, suppose someone did this how would I actually discover the first argument?  it would be in argv[1] so what would we expect to see in argv[0]? argc it's ./program and i'll make this the right size it's just the name of the actual program itself and let me show you actually how - yes? uh huh. yes. what? yes. so a segfault happens because for example your program tries to write into some memory location that it's not allowed to and this generates a hardware interrupt by the memory controller to say 'ahaha, you are trying to write into say a kernel address space or into a page of memory that doesn't exist. this doesn't look good to me' at that point the kernel says 'this process is not behaving well, I'm going to shut it down. you never get the CPU again' and so the process is pulled away form the CPU, it's not allowed to execute anymore of your assemlby, anymore of the satemetns and instead the kernel makes a note of the fact that this is a bad process. we killed it due to a segfault. yes? yes.  the alarm can go off during sleep all the sleep says is don't allow this process access to the CPU for about two seconds there are actually some possibilites where it might come back early or - there's no guarantee it will be exactly two seconds we're not playing here with perfect real time operating system. it's to the best it can do give whatever load the system's under
and we'll talk about scheduling later on in the course okay so, just a quick little bit a fun here let's have a look at /usr sorry, /usr/bin alright, whole load of programs but I want to show you something slightly surprising about these programs, umm they're actually, they're all fakes the programs like who which ls, etcetera, they're all just pointers. they all point to something called busy box" so, the busy box program is written so to support all these different commands and the first thing it does when it starts up is it says what am I running as?" am I running as ls? am I running as wc? or some other command? in which case execute different code and so you'll see this in this little example here. you'll see in router boxes. you'll see it in your android phone, because it's a way to include a lot of commands without requiring lots of large programs all tend to do kind of similar things so it's a way to save some memory alright, so that's one use of argv[0] alright, what's special about argv and argc? it's a NULL pointer! so, next time you want to scan through all of the arguments, either just use argc to find out how many are there, or just have a little loop that keeps incrementing through those pointers and when you get to NULL, you know you've got to the end so typically, if this is the array, you're gonna ignore the first one because that's not a real argument you know the first one is the actual arguments it was sent so in this case it would be kind of file.txt" and then we'll have some other arguments that the user might have supplied, and the last one will be NULL. won't point to anything so don't try to strcat that, for example, don't try to read from that location or you'll get a segfault okay, let's do page 2! so why do shells exist? could we have an operating system without a shell? yes we could. but it would be hard to type stuff in. right it would be hard to execute anything and it would be hard to call things because before you could call things on the operating system, you'd have to write a C code and compile that in order to call the system calls. but what I want to impress upon you is that all of the commands that we might call from our shell, are really just more C programs well, they don't have to be C, but for the system programming stuff, they tend to be and some of those can be, tend to be, very very small so for example, you might stat that we'll see later to find out something about a file let me go back to my home directory okay, stat program and this tells me some basic information about a particular file on disk. when it was last modified. who owns it. where it is. what kind of file it is. etcetera. but guess what. this little program just makes use of system calls and if I was to call, find out the manual of stat, uh, you discover that on section 2, there's a call called stat" where I can pass in the name and pass in a pointer to a buffer to get all that information out so that stat program, fundamentally just makes this call and then has a couple of printfs in order to format the information inside the buffer so, the shell exists in order for us to basically make, uhh, to be able to do things efficiently without having to continually create new programs so how would we get our shell to print segfault" or "alarm clock" ? easy! see page 1 hello let's flip back over we've just done it! alright, call waitpid, find out how the process finished, and then take an appropriate action like hey! your child process just quit due to a segfault" or just quit due to an alarm message or just died because uhh, you pressed Ctrl-C and we sent a SIGINT to a process you can do that. now, just using a fork and exec alright then, so, here is an attempt of implementing a shell it's called the lol cat's shell and but there's a couple things wrong with it perhaps you could figure out why this is not a good shell. how many errors can you see in this code? [long pause]
 alright, so this is an attempt to write a shell it's attempting to get the users input one line at a time and then call exec() based on what the user entered the first thing you might conclude is that you need to fire this programmer and get a better one but let's see if we do better that. let's see if we can actually identify a few specific mistakes here let's see, does it even run? ok, so no we at least need to semicolon there alright fine good so enter your command and I will exec it. ok, great we've got a shell lets try it! we'll try ls try cat ok, this is not a particularly useful shell yet how can we make it better? for starters let's print out an error message here saying exec() failed and see if we can figure out what's broken with this OK, ls. no such file or directory. what? well try /bin/ls. no such file - oops, come back now it's just sulking. it always prints no such file or directory what did we do wrong? OK, so here's a couple points from this. as you know the first argument should be the program name so let's change args[0] to point to the buffer what is args? it's an array of character pointers so we can change the entrance of that array. we're just changing the addresses held inside that array it's a very simple shell right now and it's just set up to be an array, a very simple array it's just set up to have two entries the first one initially points to a character string and then second one is null we want to change it to it at least points to the buffer. and we'll try this ok, right, ls no such file - ah - ok /bin/ls no such file or directory Darn <rand chars> still not working, but like what I said, part of being a systems programmer is to be tenacious your code is no longer the most complicated thing in the room and if you don't get things right it will bite you hopefully it will bite you sooner rather than later then we have a chance of fixing it maybe we should test our assumptions like what are we actually sending to execvp() for example let's actually have a look at the buffer alright, so let's run something we know exists look it's printing it out certainly we're sending it the right thing I'll even get rid of the fgets() whoops we've got an error. oh yeah I'm sorry it's an array so I have to strcpy() into the buffer and that worked what is our error? if you think you know tell our neighbor ok, so here's our mistake. fgets() yes does read everything from the user including the new line and if I was to put a new line into here we would see the same thing and exec is very simple, it's looking for a program called ls with a new line that's part of it's name so this would now fail so what we need to do now is get rid of that new line okay how can we do that  well let's find out how many characters that we got into our buffer we'll assume for now that fgets() worked it may not, for example if someone closed standard in on us it would return null so we should do that when we want to write better programs right, so let's find out the number of characters in now the buffer how does it do that? it needs to walk along until it finds the 0 byte so for example we know that buffer[len] is the null byte yes? so we actually want to go back one byte and write in 0 or \0 the null character will this work? let's try it 
/bin/ls hurray! finally we've got a basic shell that takes a single command we can't give it any arguments yet but we can execute it and woah hold on a moment, it stopped! what happened to my while loop? perhaps your neighbor knows why it didn't work? [silence] okay we have another problem as well, in our assignment in running about that while loop, we've just written code which is actually kind of dangerous we made a assumption that the newline is always going to be there is that true? so it could appear to be true if we're testing it but it could be that someone is sending us data from a file and fgets simply returns because there is nothing left to read so a safer program might check to see what we're actually replacing so for example, it only make sense to do this if len is at least zero and the buffer[len - 1] is what we expect, a new line character okay so we've now got a safer program, it still works, but our while loop never happens, why? yes thank you, our little process has had a mind wipe  its assembly language has disappeared, it's variables have disappeared basically everything we might have put inside the processes' memory is gone to be replaced by the code associated with our program ls so how do we make a shell? how do we make it so that it can execute more things fork exec, yes! so our plan is to do this in the child and in the parent we want to play our standard waitpid and then the exited stuff so that we can print out useful messages when our programs finish and that is the basis of the mp alright so we're well on our way to having a working shell in real shells, you can execute things in the background, how do we do this? don't call waitpid, just in your shell go around again go back to your line that reads input, either fgets or readline  and let that child process carry on how do we make it so that we can read from a file? well we've got two possible ways to do that you could use say fopen or if you want to go low level, you could use open and then when you call fgets you can pass in the file descriptor you get from fopen and you would read from that file descriptor there is another way as well, which is to close standard in so you would say hey close zero and then call open and pass in the right arguments to read from a file and we need to read the manpage of open to look at how we can open a file readonly for example and when we do that, future reads at the C level will be reading from this source file how about this? suppose I want to execute file.c inside a child but now I want to redirect the output of this command to a different file how would I do that? so how do, ah right, so I'm not going to try and change cat, this is just a command, I want my shell to do this part I want my shell so that the output goes to a different output okay and where would I do that? here's a suggestion: you could after the fork, inside the child code, the child could close one, use open and then call exec we saw an example of this in a previous lecture where we made our program send the output of ls I believe to a log file so all we've really done is taken that idea and put it inside the code that we're writing for the child process and we've put it inside the child because our parent is going to go around that loop and execute other commands and we don't want everything to end up inside that log file, inside say output.txt, we only want the child to execute that code
what's POSIX? does anyone know what it stands for? ok, so, a long time ago back in the '80s the standards committees of IEEE were trying to formalize a standard set of interfaces for an operating system or what operating systems should support and it went by an IEEE number which was hard to remember so at some point, i think it was Stormunds said why don't we call it the Portable Operating System Interface, or POSIX for short so POSIX is just a set of standards and what do those standards talk about? well they talk about system of interfaces to the actual operating system in others words what system calls can I make to control the operating system or request things from the operating sytem and also it's a set of utilites that you expect to exist so for example, there should be ls in order to list files or cd in order to change directory and also it describes what you can expect on the platform like I can expect to work with files,I can expect to work with the network so a POSIX operating system provides an abstraction of the low level hardware I don't need to worry about the exact way to communicate with a flash drive I can simply say 'oh look well let's assume theres a file system on here' and I want to be able to read or write files to this and the operating system provides a lot of support for those different pieces of hardware it also provides security. so what kind of security does an operating system give you? does it give you a warm blanket and a teddy bear at night? no so what do we mean by security? if you were to design an operating system today, right now, what security features would you have? make it memory safe, what do you mean by that? why? ok, so what you're saying is you don't trust his programs? I'm sorry, yeah it's a fact of life. what we want to try to do is provide some insulation between different user programs  so that a malfunctioning program I'm sure you write fantastic code most of the time, but let's say a malfunctioning user program cannot bring down the rest of the system ok, so how are we going to do that? well one thing you've already seen is memory protection and if I read up on operating systems give us virtual memory so each little process runs inside it's own padded shell sorry padded inside its own padded room it thinks it can read or write any possible memory address it can think of of course if it tries to do that it might crash and we might just kill the process by the first flush one process cannot actually access another process they live in completely different universes so they are living in dfiferent virtual memory spaces ok, what else? yes? file permissions yes, so I can make it so you can't delete my file or append to my file but I will let you read it or I can make it so that my file is unreadable by anybody that's not inside a certain group interrupts, what about interrupts? ok, interrupts - i'm going to talk about processes because I thought that's where you were going to go that you can't kill my process you can't just call kill -9 on my processs so you can only kill processes which you own unless you happen to be root or super user in which case you can kill any process you want on your system so, yes, security in terms of process control the last thing here is scheduling try to have some fairness which is an open ended and debated term, but imagine your process tries to take the CPU 100% of the time and never gives it up. just has a while loop if we were not careful no one else would have access to the CPU, it wouldn't get any work done so the last thing we'll say in the closing part of lecture is yes there is a quiz on friday and here's going to be our next topic - how do we allocate memory on the heap and I will talk about this in a future lecture on monday alright, great, see you friday, be ready for the quiz thank you very much, have a good section tomorrow
Okay, good morning class, how are you?  Fantastic, right!  So here's what we're going to start doing now, we're going to start talking about memory. You could imagine if we went back into the early, early hours of computing, we had it easy, right?  Well, there's proper instructions here, and we'll use location 100 to mean this and 112 to mean that, and we won't have to worry about dynamic memory allocation; we'll just make all those decisions upfront as we actually design the program. Then later, we say, Well actually, we want to have functions."  And later, we want to have functions that can call themselves and be able to recurse.  So, for that we need a stack. And for that, then, as we make function calls, our stack pointer needs to move.  And inside the stack we'll store our temporary variables and also our point where the CPU should go back to when it returns from the function. So our stack... we'll start a lot higher up in memory and as we make more recursive calls our stack will get larger and larger and larger and larger, of course - until we run out of memory.  And then we said, Well actually, we don't want to decide what memory we'll need upfront either, we want to be able to have dynamic memory allocation, and we don't know when we're going to free up that memory.  We don't know when we've finished with it.  We want to make that completely dynamic and it's part of our program. And thus, the idea of the heap was born. The idea that at any point, we can say, Oh!  I need more memory!  And give it to me now and this is how much I want and I'm not going to tell you when I'll be finished with it." So it's very different from the stack memory.  Stack memory: you know you'll be finished with that memory when you return from the function. So with stack memory, you've got automatic variables.  They automatically disappear - no more work... With the heap, of course, now we actually have to say, Okay, give me the memory" and "I'm finished with it." So you've used the heap of course in Java and in C++ when you said 'new' and 'delete' in C++.  Typically, they go on the heap memory. I say 'typically' because C++ can do some amazing optimizations when you're not looking the compiler will quickly say, Hey!  You didn't need to write that!" Here!  I'll optimize your code, so that actually there's no code written at all." When you write new/delete you explicitly create, well, we'll just simplify it and say Yes!"  We're making things on the heap.  So we need some memory, so let's call malloc(). So malloc() is part of the C-library.  It's part of your process.  It decides where your memory's going to be. If you like, it says, Oh look!  Table of four.  Right, I need  four seats.  You can sit over here.  This table over here is free.  You sit over here.  Oh, you've finished with that table?  Oh, great!  Get out of there because I'm going to reuse this table for something else." Alright, so malloc() has to very quickly decide where it can assign you some memory. Now, it gets harder because we don't know in which order our memory is going to be allocated, and in which order memory is going to be freed. And even if you knew that order, it's an NP hard problem to do it well. Called the Knapsack Problem. So even if you knew exactly which order the malloc()s and free()s were going to come in, how would you do it efficiently is a non-trivial problem. That sounds computationally expensive, right?  If we made our malloc() perfect, it's going to take a long time.  Yeah, I could put this table of two here, but you know what there's a big order coming in in a moment and so I don't actually want to put them there I want to put them over there."  There's an infinite number of possible ways that we could arrange things in memory. So malloc() has to be efficient but fast. So this is the basic game we have to play. *picture problems* Don't write this down, this is just a visual.  You don't need to copy this down. Here's how it works: let's suppose our process has some memory to play with. You promise me you're not writing this down?  Good. So my little blocks here indicate 1 kilobyte blocks. And during the execution of my program it says, Well, I'm gonna make a linked list or I'm gonna make an image, and I need some memory."  So part of your code says, "I need say 2 KB." So malloc() now has to look through the memory and say, I tell you what, I'll give you these two blocks here." If anyone else calls malloc() I promise not to return any pointers that point to this memory in here. So malloc() is going to return the address of the first few bytes and internally it has to do some book-keeping.  It has to make a note that these first 2 KB are being used. And then your program decides to malloc() some more memory.  So it says, Okay, I'll have 2KB now please."  What should malloc() do now? Well, it can't use this area of memory.  It has a choice: it could put it here and here.  It's not going to allocate here and here, though. Why not? Why does it not say, I'll give you some memory there and there"? Yes! Thank you, we've fragmented the memory, but also when malloc() returns a pointer, your assumption is that all the bytes you've been given are contiguous.  You might want to use it as just a simple array, for example. So we've got a problem here.  We have to allocate memory that is in the same area so let's say we put these little x's in here.  And then of course someone says, malloc(2 KB)".  What happens now? We can't! right? We don't have enough spare memory.
Now if this was a very small... two things could happen: our program could just crash - malloc() could just give a bad answer.  But we want to be a bit more systematic than that.  So at this point we'll go back to the operating system and say, Hey!  You know that memory stuff that's really valuable?  Give me some more, I need some more."  So actually malloc() at that point has to go back to the operating system and say, "Hey, you know that memory you gave me?  I've run out." I need some more. I'm addicted to the stuff, right? So, I need more memory.  So malloc() can get some more memory from the operating system. there we go. How does it do that?  Well, classically it would call something like sbrk(). What is sbrk()? You can write this bit down if you want to.  Let's jump into the rabbit hole for a moment and think about our process where we've got all these memory addresses to play with.   So what do we find inside memory?  We've got our code, we've got our global variables or the static variables... up here we've got the environment and the stack...where's our heap live? Just here.  It starts off just here. So it can grow, right?  We can say, Excuse me, system.  I actually need some more space."  And that's what sbrk() does. It says, Look, you've got this watermark (this threshold) of what the maximum address is.  I want to bump it up, I want to play with some more room." So this means we could write a really, really simple memory allocator.  Here it is. Any time the program asks for more memory (x bytes) all we will do is say to the system, Hey!  I need more bytes.  This is the number I need." And anytime the program decides it's finished with some bytes, what should we do? Nothing! That's the simplest memory allocator we could write. It's not a very good one, though.  We're not re-using any memory. Because we're not keeping track of which pieces of memory are actually being allocated.  We're just simply saying, Oh look!  I've got some more passengers on my boat, I need a bigger boat."  Or, "I've got more people on my bus, I need a bigger bus." And not keeping track of how many seats are actually unoccupied. So it's really, really fast but completely inefficient.  We're very quickly going to exhaust all of our memory. And so this sets the stage now for our memory allocator.  We actually need to start keeping track of which bytes are currently being used and which bytes are available for suitable calls to malloc(). So we only want to call this sbrk() thing when we truly are out of memory.  When we have no way to allocate any more memory.   So the MP (which will be out maybe the end of the week or maybe next week) is actually going to ask you to write an efficient malloc().  And it fact it's going to be a competition. So there'll be a page with results and you can see if your malloc() is faster than your neighbor's malloc(). So remember when they step away from the keyboard to put a sleep() call into their code. Okay, so what's to stop you from doing this all the time?  Easy: the competition is actually going to put a hard limit on the amount of memory that you are allowed to play with. So now we have to start coping with the fact that memory's being freed. So if we are working with writing a good malloc(), let me show you a little problem that we might run into. Here's some memory that's been allocated.  Here's some other memory that's been allocated at different times.  And then our program says, You know what?  I'd like 2 KB." Now you can see from my little diagram that I've actually got 3 KB of memory which are unused. But I cannot give you 2 KB.  I cannot find any space which is 2 KB because my spare space has all been fragmented.  It's no longer in a contiguous block. So why can't I just take all the contents of this memory and just move it into there, and then carry on? Why can't I just move that? Why can't my malloc() just start shuffling stuff around? Yes, thank you! Yeah, I can copy stuff!  My malloc() can copy it to there.  However, the rest of my process is using pointers.  It assumes that the stuff that's inside here is where it is so it assumes that if I've got a variable that's pointing to a linked list that it's using this area.   So all those pointers will be invalid.
So malloc() by itself cannot do that. Java does a little trick here, by the way.  What Java does is its pointers are actually pointers to pointers. So remember when you had a pointer to something, like an object pointer?  And next time someone says, But there are no pointers in Java!"  And then you say to them, "Well why does Java have a 'null pointer exception?" So how does this work internally? This pointer points to a pointer which points to the actual memory that Java's using. Why does Java do that?  So that it can shuffle things around.  So that it can deal with this fragmentation problem. So here's what we're trying to solve here is fragmentation. And the reason I mentioned this thing about Java is because when you are using the JNI, on the Android NDK, you are going to discover that you have to pin and release things. As part of your C code.  And what you're doing is you're saying (to this intermediate pointer), Oh no no no, I've got a bunch of C code right now that is using this data, so you can't start moving these things around.  You can't shuffle this block of memory around right now because my C code is using it." So Java uses a counting mechanism to note that C code is currently using these pointers and can't shuffle the memory contents. You'll discover this stuff when you start working on the Android NDK challenge. Right, so, our game then is to try to avoid this fragmentation. This fragmentation's bad, right?  Now we have memory that we can't use for large allocations. Our game is also to do this efficiently. So, here's where we're gonna look at three little problems. So this is actually an exam question.  It's one of the easier exam questions.  And what we're gonna do is forget for a moment this whole stuff about sbrk() and going back to the system to get more memory. We'll just say that we've got a heap initially of 13 KB. And we've got an order of calls. So as new calls come in, we can decide where to put them.  And here's three different placement strategies. Best fit, worst fit, and first fit. And we'll see as we do this that they lead to different assignments, that our malloc() will decide to place these requests in different parts of memory and so we'll have different fragmentation so that if our program continued, we might discover that future large allocations are impossible. ok, so what do we need to know about this? First of all, if you've got a choice, you choose the earliest segment. Okay, so what that might mean is let's say with best fit, let's say I've got space here of 2 (which happens to be a perfect fit; in other words, I'm trying to find space for 2 K, then I would just choose the one with a smaller memory address. Worst fit.  Oh, how contrary can you be?  The idea here is that if I've got a space which gives me the maximum amount of space after I've done the allocation, I'll use that. Okay, so let's have a look at worst fit, where I've got a 2K space here and a 10K space there and I'm trying to allocate 2 KB. Worst fit would not put it in this spot here, it would break apart this 10 KB space and say, I'll tell you what: here's how we'll change.  I'll allocate my 2 KB there, giving me a remaining space of 8." What do you think first fit does? Pretty obvious, right, from it's name.  We're simply going to walk along our free spaces until we find the one which is sufficiently large, and use that. So, if I'm looking for 2K, oh look!  There it is, I'll use that one.  If I'm looking for 3K, oh, it's not gonna work for me, I'll have to keep searching. Okay? So they're very obvious placement strategies (from their names).  Now, it's up to you to actually run them. So here's the actual order of calls to malloc() and free().  Where do the allocations end up?
There was a question about best fit.  Best fit will scan through, looking at all the possible holes.  Obviously we can ignore all the holes (or spaces) which are too small. And it will use the space which is at least as large as the request, but hopefully no larger.  And if it so happens that there's two spaces that satisfy that search, then we use the one lowest in memory. So, question? You would split it at the beginning. Right so, anytime you've got a space, you do the allocation at the beginning of the space. *nothing happens here* *again nothing, class discussion, Angrave filling out sheet* Okay, so.  Let's have a look at this.  So first fit: I've gotten as far as filling out A, B, and C and now I've called free() on B, and now I need to allocate another 3 KB.  Where could we put it? Well, we've got space here and we've got space at the end.  And we're trying to do best fit.  So best fit is going to put it in here because it's a perfect fit.  If I put it starting at 3K, I would've had a space of one left over, so that's not quite as good. And then we free A, and we allocate one KB.  Where could we put this?  Well, there's only one place.  There's one big giant space over here. So we'll put E there. What happens in worst fit? Nothing changes at the beginning here.  C, C, C.  Okay, so.  Now we free() B. And we allocate 3 KB. So: where's our choice? We could stick it here, or we could stick it at the end.  Which one is worst fit gonna use? B, yes! Because we have the largest space if we allocate it there. So let's put our D in here. And now we free() A. And we want to allocate one byte.  So what are our choices?  We've got a space of 3, space of 1, and space of 3.  Where's worst fit gonna put our final allocation? Yeah, it's a tie-up between the first few blocks here and the last few, so we'll put it just here. Okay, and first fit Okay, let's do this quick.  Right, so, we'll do the D.  3KB.  First fit is the Scrappy-Doo of fits.  As soon as we find enough space, we'll stop.  And we've just cleared out our space of four so yes, we can put D in here. And now we'd free A, and finally we allocate 1 KB.  So we run along our spaces - oh, look!  Here's our free one.  And we'll stick E in here. I'm sorry, yes, you're right.  We'll stick it just there. Okay, so this was a pretty trivial exercise.  But what I wanted to show you is the mechanics of these programs, and that they also lead to spaces in different places.  Also, there's a little thing that we did quite easily but you'll have to remember to do in code, which is: look at this, we had A and B, and at some point we freed up two allocations next to each other.  And so we had to go from thinking that this is a space of two and a space of four into think that this is just one big space of 6.  And if we didn't do that, then if somebody asked for a malloc() of 6, then your algorithm would say, I'm sorry, I don't have space to allocate 6B because counting will keep this as a space of 2 and a space of 4." We could coalesce those two free areas together into a single block, and so that is a common gotcha when implementing malloc(). That you have to look at the space beforehand and the space afterwards to see if you can coalesce them.
Right, um.. No need to need to remember that until you actually write your own allocator Okay, so let's just think about some of the comparisons of these then So what we'll do first here: what's one of the advantages of first fit? It's fast! As soon as it finds some space, hey we're done! We don't need to do any more Okay, what's one of the advantages, say of best fit? Or any disadvantages? Yes? Okay, so, think it's least amount of fragmentation Because it's ideal! Okay, so that is uh, do we know that for sure? It appears to be from this example, right? But is it true? In all possible uses? What about disadvantages? It's slower than what? first fit Because we have to check all spaces Okay, let's do worst fit and I'll come back to this one Right, what about worst fit? Yes, it's slower than first fit again because now we have to go through Any advantages to it? Any other disadvantages to it? Let's think about what we're doing for a moment. So worst fit is always going to find the largest space and use that So that means in a longer-running program, if you've got a giant space, it's going to quickly be eaten up So with worst fit, what you find is that you end up with lots of kind of medium-sized spaces Yes? Uh yeah, we can always go back to the system and say, Hey, system, I need some more memory" But what we're trying to do is see what our fragmentation looks like given the space we've got Okay? so, because we keep attacking the largest space, means that we don't have one large area should a giant allocation request come in Alright, now we've got these medium-sized holes, these medium-sized spaces, scattered all over our memory space So we cannot satisfy very large requests Yes? But we keep attacking that large block, right? It's um I'm trying to think of a good analogy, but uhh You always can say, Oh look, I've got this really really big block at the end, I'll keep using that" Now what we haven't talked about is think about the fact that our memory gets freed up as well, okay? So, this large block keeps getting attacked, and we end up with smaller, medium-sized blocks scattered through our memory if we run this process for long enough We're always attacking the largest space, we're always kind of nibbling bits off it So best fit seems to be, Hey, we're not going to get much fragmentation, we're always trying to find the perfect jigsaw puzzle" The problem with, yeah? Yeah, yeah there are some interesting caching issues, yes Okay, okay, okay, so the question's about, hold on, we've got virtual space, with virtual memory you can actually do some interesting mapping to real memory" Yes, that is true However, that mapping happens at four kilobyte chunks Um, so, we can't completely get away from our fragmentation issue So, yes, underneath this for the real memory, we can avoid some fragmentation Given that malloc actually has some space, you know it's got a low address and a high address, our question is how can we efficiently use this memory? Right, so, I want to address this least fragmentation thing It appears to be ideal. It can be, if you set up your simulation correctly, but when you, uh, run it under more realistic conditions, what tends to happen is you end up with lots and lots of tiny, tiny, tiny little holes. Or tiny pieces of spaces. So you could imagine that you've got, say, a request comes in four 15 kilobytes and you happen to have a 16 kilobyte space free, so you'll use that Now you end up with this tiny 1 kilobyte unused space So, in practice, best fit tends to give you these tiny, tiny spaces which are difficult to reuse So, quite often, some variant of first fit actually turns out to be a pretty good choice What first fit tends to do is the size of the holes tends to vary as you walk further down your list of free spaces So, this is actually often a pretty good choice Okay, so that was placement strategies Let's talk about a few other things with memory So we talked about where it's stored in memory It's stored just above the code and the global variables And we can call sbrk to say, oh we need some more space" So what then are the challenges of actually writing a good malloc? How are we going to keep track of which parts of our memory have been allocated and which parts are free? What would you use? If I said to you right now, Okay, start writing a malloc", how would you keep track of Say again? An array of what? Okay A disjoint set of regions in memory, okay Okay, so here's what I'm going to ask you to start with is just a simple linked list We can start with just a linked list of what's been allocated And what's been freed
So if we go back to our picture that we were drawing To say 'Oh, look, this has been allocated, this has been freed, this has been allocated, this has been freed.' What we need is a way to say, 'Okay these are just entries inside a linked list.' And I can walk along these looking for blocks which are, say, large enough.  And then when I find a block (let's say I'm going to use this one), I need to update my data structure so that I've now got an entry to say 'Hey, this part has now been allocated, and' 'I've got some remaining space.' And we go back.  So we can choose to take a block out and turn it into some space and some remaining free space.' Which of course if that's zero, you don't need to have this entry. When you call free someone's going to give you a pointer to one of these used areas.   And we have to go through our linked list then to update our counting - to say, 'Okay let's turn this now into some free area.' Remember how I gave a little advert about coalescing blocks?  Well, our work may not be done because you can imagine that, over here, I've got a free block, and on this side I've got a free block. So I now need to update my counting on my linked list to say 'You know what this is now just one giant block if I've got it on both sides, a huge block of free space that can be reused.' We could do this really, really inefficiently by having a linked list and then when someone says, 'Oooooh!  Free a pointer.' I'll just walk through my linked list until I find my entry that corresponds to that pointer.  Oh my gosh, that'd be really slow.  Okay, I'll tell you what, I'll use a hash to speed it up.  I'll have a quick hash so that I can find my pointer and go back to my pointing structure and update my linked list structure correctly.' When actually we can do a lot better than that. We can store our linked list structure as part of the memory that we allocate. Here's a clever trick. Let's allocate some memory and we'll allocate a little bit too much. So if the user says, 'Hey, malloc() 100 bytes we're going to malloc() say 120.' And we won't tell them, okay?  As far as the caller is concerned, they're just getting 100 bytes.' But the reason we did this is because we're going to store some secret information back here that's actually our linked list information (our pointer to where to go next). Wheeeee! When we return, don't return the pointer to the beginning of here.  No, make sure you bump up the return value so that the return value from your malloc() actually says, 'Okay, user program: here's a little space, here's the 100 bytes that you wanted.'  So we'll add our twenty bytes or however large you made it. And when the user later says, 'Okay!  I'm done with my pointer.'  When they call free(), we have to play the other trick and go the other way and say, 'Okay now where did that block REALLY start?'  Let's subtract our 20 bytes again. And if we do that, we can find our pointer.  Our linked list structure. So we're hiding the link information inside the allocation.  Pretty sneaky, huh? It gets even sneakier than this. We're going to do two more little things to make it really, really sneaky. First of all, we'll discover that we actually need to be able to go the other way.  If we start with a block over here, I actually want to be able to kind of have a doubly linked list.  I want to be able to go back to the previous block. So not only do I want to store the pointer to the next, I want to store the pointer to the previous.  So I'm going to put that over here. And I'm also going to actually store this information at the end as well.. So that if I come over here, I can always look at the previous block and say, 'Okay, where are you?  Where's your start?' The other thing that we can make use of is rather than storing actual addresses (pointers), we can just store numbers.  We can store the number of bytes and then use pointer arithmetic.  If you know that this is 120 bytes long, and we're looking at the beginning here, then we can just add 120.  We can just store 120 as the size of this thing. And we can jump to the next entry. Or if we look back here to the previous value, then actually we're looking back at the previous block.  And if this makes a note of how big it is, like this one's 200, then we know that we can jump back 200 bytes.
This sounds really easy when I'm presenting it in lecture. Writing malloc is a rite of passage Meaning that you too can have gray hair and fuzzled eyes and look just like me...no What I mean is that it's tricky because now we have to start dealing with pointer arithmatic Now we have to start dealing with multiple pointers A little error like writing pa instead of pb or adding instead of subtracting can bite you big time And worse it won't bite you in an obvious way For example suppose that you didn't actually add enough bites You didn't add 20. You added a smaller number. Then the user program just overwrites your pointer values, KABOOM! Of course it crashes Later when someone calls free and you try to read these values and these values are just garbage Like what happened to my values! Why aren't my values correct? The only thing that can bite you is... sizeof So remember if you've got a struct for example That you've set up to hold these values Or an array The sizeof an object or struct is very different from the sizeof a pointer to something Or sizeof a pointer to an array is different from the sizeof an array So one little character here can really really bite you So my advice is to get started early when we put this out and to program slower than you've ever programmed before Make each line a work of art that you would trust your life to It still won't work, but at least you've tried really really hard Yes Question sizeof doesn't work like that sizeof is a compiler thing that runs at compile time so it uses the type ok so sizeof says oh look I'm looking at a pointer" Pointers on my machine are 4 bytes or 8 bytes Ok it does not do anything at run time Alright how are we doing for time Ok We will finish with something really really easy. calloc and realloc calloc and realloc easy after you've done malloc These are easy. You can implement them in terms of malloc and free So realloc says guess what...I need some more space" Here's a pointer that I previously got from my malloc call or calloc call Basically a heap pointer, a pointer to some memory. And here's how much memory I need now on the... I've decided that my array needs to be larger Realloc will do that for you But be careful, here's how realloc is supposed to work It says look, I'll try to find some bigger space. If you're asking for more space, then if necessary I will copy everything across and return a pointer back to you If it fails however, it returns NULL So be careful when using realloc. Always check it's return value. Because it may have decided to shuffle things around for you. I couldn't extend this. I have something else using the memory just next to you. So I had to allocate a new block. But you can implement realloc directly just using malloc and free Calloc Calloc is very similar to malloc What calloc does is it zeroes memory So it's a bit slower than malloc Also you give it 2 parameters You say this is my element size and this is the number of elements And so the amount of memory it's going to allocate is size times number Why somebody thought calloc needed two arguments, I have no idea They should have just made it with just a single argument The first thing it does just multiply these two numbers together, that's it Except it has to do it the hard way because you could get integer overflow But anyway, calloc is essentially malloc plus it zeroes the memory Fastest way to zero memory is to use memset And we are out of time. Yes! And with that it's 11:50. Have a wonderful week. I will be going down to the lab now. After I've answered questions incase people want to help setup the android ndk
morning cs 241. how are you this morning great. okay. so here's what we're going to do today. we are going to talk about memory allocation we're going to look at some code that some ta's wrote last semester and then we're going to jump into a new topic called threads and this is where we can actually get more than one CPU to work on our process at a time let's start with this. let's have a look at this code that the TA's wrote they actually wrote a version of malloc() and free() i want to show you that it is possible to write some code that works and we'll see how it goes first we'll define a struct and we use typedef because we're lazy and we don't want to have to keep writing struct everytime we refer to this memory object and so in the future we can just say metadata_entry_t, that's just a shorthand typedef is just saying here's an alias and this is what we're going to have inside our little struct. we have a ptr that we'll be using for the user memory we want to know how many bytes to use we want to know are we talking about memory that's currently in use by the program or is it free. is it available for a future malloc() and finally here is what we're using a linked list so we can walk through these things so this is going to be our metadata, our information about what memory our malloc() has actually created or freed and so this will be the beginning of our linkedlist ok, so now let's have a look at the malloc() implementation we want to know how many bytes do they want. so we're going to look through our linkedlist and look for the appropriate block that we can reuse let's walk through our list and we can obviously we only care about entries which are free. we don't want to use a block that is currently in use that's currently been allocated for some purpose but i've missed out some code here so it's going to be your job to figure out what code is here also what placement strategy is this using. remember we talked about different strategies in the last lecture which one is this using and how do we change the code to implement a different placement strategy so you choose a different one and then figure out how to alter it and then there's more code down here. so what's this second half of the code do so that's going to be our challenge for the next 5 minutes: what's the missing code change the strategy that this is using and what does the rest of the code do. why is it doing what it's doing? and you may also want to have a look at the free() and i'll walk around and answer any quesitons  on this or this week's assignment silence
silence so here's how this works we're calling malloc() and we're going to look through all the previous allocations that we've ever made and we're going to see if any of those allocations we've made are free so we want to check if they're free and we want to make sure that the block of memory is of sufficient sie so let's check into our entry that size is at least equal to the requested size if it is, then maybe we can use that use that block. now we could at this point say hey great i've found a block but instead we're going to change our chosen pointer if the following is true either we haven't chosen anything yet or the size of the allocation we're looking at is even smaller then the previous block we've found in other words what kind of placement strategy are we using best fit! yes, this is best fit if i was using a tinder analogy, this would be like a best match you go through all the matches okay yeah of course sometimes you don't want to take that long and we could do a first fit: oh, yeah, that'll do so at that point we could say break out of this loop as soon as chosen is non-null so we could change our code somehow so for example if i were to put break in here then i can break out of the loop or i could have changed the conditions of the while loop to say while chosen is non null but yeah this is best fit and we go around and look at those allocations until we've actually exhausted all of them so it could be that we've found some space some previously allocated space that is not being used and in which case life is easy so if chosen is free then all we need to do is update that entry to say actually it's no longer free its being used and we can immediately return and we'll tell the user code to use the memory found at that pointer so that was the easy case let's take a break for a moment and now let's look at how free works because later on when the C code is finished with the memory, it's going to have to do the same trick again once with the meta data, so here we are going to that linked list eventually we find the entry that the user was using and we can mark it as available this works but its not very efficient. you can see that as we have more allocations in our linked list this code is going to get slower and slower our free is order n so this is not a very good implementation. which is why you get it for free maybe we can do better than this. rather than having a separate linked list maybe we can actually come up with a better solution. but anyway, now let's go back to our malloc now let's actually see what this code does. if we weren't successful in finding in any memory instead we call this sbrk() thing we say okay if chosen equals sbrk then sbrk and we pass in the size of the struct whenever you use sizeof() stop and pause and think come back come back, are you actually pausing in the right thing to sizeof() sizeof() works at compile time. the compiler uses the type that you give it the sizeof a struct is not the same thing as the size of the pointer to a struct and it's a common error to pass in the wrong thing sizeof() an array is not the same thing as an entry of that array
alright so here's what these two lines do they're basically saying hey operating system, I need some extra bytes heres how many talking to your operating system is very slow thats gonna take several microseconds to complete and then we're gonna say here, chosen im going to set this pointer to be sbrk and then call sbrk on size guess what that does. that also says to the operating system i need now size bytes they're actually calling sbrk 4 times to say alright give me some byte not only for the struct but give me some bytes in order for to satisfy the users request and what we're doing with the asterisk each time is raising the rule to mar raising the threshold for where our heap finishes so now we're gotten set up our little struct we'll set it's size we'll set that it's free and we'll set the next pointer to equal to metadata and we change the metadata chosen to the pointer so what we've done here is insert our new entry into the beginning of the linked list so the next time we call free or malloc we're gonna see this newly created entry inside our linked list and then finally we say back to the user here's the memory of size bytes that you needed questions about this code? yes? if chosen is bigger than the amount of space that you need yes so what this code does not do is do anything without spare space it's got a very simple view of the world its view of the world is yeah i've got a block here that was previously allocated, a block here, some memory here and if you want to say to this much memory then it's obviously not going to give you that one and it would give you say this block and you'd say well what about this space back here can we use that should we add another entry because maybe in the moment someone will malloc and attempt to make a smaller space ah too bad okay so we've got some fragmentation inside each of these allocations if we dont have a perfect fit yes? ah right okay so before this line we've got metadata pointing to our first entry yes this is my little struct now which then has a next pointer which points to another one which has a next one which points to another one and so on and so on and so on so what we do is  we set up our new struct so its next pointer  points to the old beginning of the linked list alright so when you see equals just remember your copying bit patterns you're just changing one pointer to look at the same thing as another pointer and then the next line is meaningful we've changed that variable metadata to look to our new brand link any other questions alright then so okay yes get your spectacles on i did this too small today and it was tiny when can a system use COW moooo that's a moot point no COW cow stands for copy on write here's the idea you and I can share a resource providing neither of us actually tries to change it and we can do that very quickly well the day that one of that you and i actualy need to write to that resource, that's when we're asked to duplicated it we'll do it very quickly before the other person notices so you can defer the actual copying process, the duplication process, until a change or modification happens ah this is a common idea for performance because quite often it turns out that we don't actually need to write to something or modify something so if you can detect when something is about to change maybe you're writing an alloc class or youre the operating system we dont actually need to initialize stuff or copy stuff until it actually is required and so a little brain teaser i have to today is how can we improve calloc performace here so COW is just copy on write so its a way to have shared data structures until something mutable happens until a change happens, and that way, we can use our resources efficiently right lets just see what you remember from previous lectures what's realloc it's when you change your mind you say, oh okay remember those bytes i malloc, actually i decided i need more bytes so we can use realloc when i say i'm creating an array and i keep going around a loop and i decide to say remember that array i made turns out it's not large enough okay so realloc works but there's a big caveat as you've just seen how malloc actually places things it could be that we can't keep the user data inside the same memory address anymore so when you call realloc be prepared to update your pointers with the return result of realloc so if i've got an array that i previously created say from realloc or malloc or calloc then don't just say you know what im gonna make it larger i'm gonna make it say 100x 100 entries larger infact, let me just change this code a little bit let's say that  you called calloc and i've got like a size of thing something and i've got like 50 entries here and then you say you know what actually 50 wasn't enough im going to double my space i've just managed to write two errors in 2 lines actually both of those were in the second line
so here's two gotchas the first is that my variable, array i didnt build it to update and so it could be that during testing everything is fine but later one it turns out that im trying to change the size of realloc and actually had to move my array to different memory and i didnt update it so make sure you use a return value this second error is awful and im going to tell you know its because life is short and please please never make this error unless youre trying to confuse someone else this is a fantastic gotcha does that code really allocate enough things for 100 entries no it allocates 100 bytes what we forgot to do was multiply it by the sizeof() our entries so don't just plug in N here or number of items remember that calloc realloc and malloc work with bytes and we didnt allocate enough bytes which means later on when we start putting things in our array we're going to go past the end of the array and exciting things can happen called segfaults and data corruption so start and pause whenever you see realloc are you actually passing the right number of bytes and when you see sizeof() are you calculating the size of the right type okay thankfully now no one in this room is ever going to mkae that error again we'll just let university of whatever make those errors okay so what do remember about calloc? what does calloc do okay it takes two arguments and it multiplies them together to determine the number of bytes what else? how is it different from malloc? it clears the memory yes calloc now only gives you back a pointer to some memory it zeros out all that memory as well for you so we go back to java arrays we said hey i need a new integer array a great way to implement that would be to use calloc so of course then calloc is much slower we actually have to write to all those memory locations and you remember talking to memory is really slow especially when you need to talk to lots of it so the reason that we dont necessarily always call calloc is because sometimes we know that our program is going to write into every memory location we don't even need to waste time zeroing it out first so it zeros the bytes so you can write a loop to do this but ill give you a little hint if youre ever writing a calloc and you want it to be performant then remember when you do the operating system and say hey i need some new bytes i guarantee you those bytes will be zero because the kernel the operating system does not want to give you some memory that is being used by a different process maybe its got a password in it maybe its got a secret key in it maybe its got stuff that you shouldnt have access to so for security you will get bytes which are zero so if you know that you're getting new bytes you can reliably you dont actually have to zero those out but only if you know that youre getting them fresh from the operating system youre not just using memory thats already part of your process boundary tags we haven't talked about much but we have talked about indirectly the last lecture i gave you an idea about whenever we did an allocation we could actually store the size of our allocated area at the beginning and the end of each part so rather than having a separate struct like we saw at the beginning of this lecture we could actually hide inside here how many bytes this is so this say is 16 bytes put 16 here this is 20 so if we do these tags at the beginning and end then when we come to do something like a free i know that because these are like train couches becuase theyre next door to each other if i just go backwards enough bytes i can actually read how big the previous allocation was and that allows me to manipulate these values and to maintain a list what's been allocated as part of this train as part of these tags which are next to each other alright so when actually return from malloc we wouldn't return the beginning of the carriage if you like, no we look a few bytes in and say okay here's that area for you to play with you can put whatever data you want inside this bit here because you asked for 8 bytes in the middle but becuase the users code was broken it kept going say someone didn't actually request enough bytes so as a result of that the user code just destroyed our metainformation inside here in fact it could've kept going as well things might seem to work until the day the code calls free becuase now you're free implementation assumes that it can read these values correctly but as we've just seen the values here are gone they've been replaced by whatever the user code happened to write in there or the rest of the program actually did so now you linked list manipulation and your calculations ha ha ha might be updating arbitrary pieces of memory and you're adding whatever the values were in here heres an example where a buffer overflow could make your perfectly reasonable code do bad things now it could make it say write arbitrary values into arbitrary different locations which is why buffer overflows are so dangerous of course most likely whats going to happen is when you call free your program crashes so when your program crashes during free its probably because something bad happened earlier to the heap so how can we stop that? what can we do? lets say youve inherited a program where it just crashes strangely on free how could you try to figure out what's going on?
OK. So, programmers took inspiration from miners. When you go down in the mine you take a canary, yes? The nice thing about canaries is they die before you, if there's poison gasses. Or at least then they stop singing as all is well. So here's what we can do. We can actually put some values into our heap barrier. And then we just check that those values are still correct. like there special hexidecimal values, like deadbeef, deadcode, or a value that is a quick hash of the values we want to store. So we can at least verify that things haven't been overwritten. So debug versions of malloc and free will do this. They'll take some extra space to write begging and endpoints. And then before they do anything, they'll check those values to see if they've been overwritten. So we can't stop the override, but we can at least detect it afterwards. Any questions? By the way this idea of putting the size inside as part of the allocated area, this was developed by, I think, Donald Knuth, many years ago. We've been living inside the user process. Now let's step back a moment and talk about virtual memory. What do we mean by virtual memory? We've virtualized memory. Ok, what do we mean by that? We mean that the addresses that our processes uses can have very little connection with the actual addresses that the RAM sees. That, in essence, there's a mapping. So ya, we can keep talking about the process address space. It goes from zero up to some high number, let's say 7fffffff. And we can think of it in terms of little blocks. And in fact, our virtual memory likes to work with pages called, and there typically about 4096 bytes, or 4k So, anytime you read or write into your virtual memory, we've got to take that address. Some magic happens. And say ok, which piece of RAM, which physical address, should I read or write to? This side will have virtual memory, and and this side we have real addresses. And it's the MMU, the Memory Management Unit, that has to convert one to the other. Now today we're just doing the quick two minute version, because there's a lot more to say about this I just want to give you an idea we can actually step outside the matrix. Once we start playing these tricks, there's some amazing things we can do with this, as system programmers. This is a fundamental piece of any reasonable hardware that runs a modern operating system will have a memory management unit, in order to convert virtual memories into physical addresses. And here's the cool thing is that now these don't need to be contiguous. That this mapping can be all over the place. So this 4K can go to some lower memory and this 4K can go to some other piece of RAM. So this allows us to use our physical memory much more efficiently. We don't have to worry about fragmentation, now, and having holes or having spaces inside our physical memory that we can't use. [So if it's stored on the hard drive...] Ah yes, I wasn't going to mention that but ya. Here's the cool thing is that now we can now say to every process, Hey! you want 4GB? No problem!" You want 4GB? No problem! You want 16GB? No problem!" Ok my machine only has 1GB but don't tell them. Because what we can do is, ya, we can actually secretly store some of the information they want on the hard drive. It's basically like this, imagine only the bits of the world your currently looking at exist. Any time you turn around and look behind you, I'm going to put you on pause and quickly recreate everything that you intended to look at. When I finish doing that, I'll release you again. So that's what the virtual memory, that's what the operating system does for you. You think you got 4GB of space. I just promised you that. Promises are easy because I know you can't actually look at it all at the same time. I'm going to intercept any time you try to read or write memory to make sure that what you're trying to read or write actually appears to be there inside RAM. But it's all conjuring. It's all fake. And it's up to the operating system to do this for your process and any other process that's currently running. Right, that's enough of virtual memory today. But it's a wonderful system. It's one of the best parts of an operating system today, I believe. Instead, let's talk about something which is just as powerful and is going to separate your programs from mere novice programmers. And that is being able to use threads effectively. This is the beginnings of the major part of this course here, is to understand how to work with synchronization and work with multiple threads.  This is the coolest bit so here we go. Let's put on some basic ideas here. How many heaps does a process have? That was easy. One. Inside your process memory a heap is used for all those malloc and free calls and there's only one heap.  So it's just a BIG area of space that anytime you want memory from you can just call malloc, or calloc or realloc. But you can just say Hey I need some memory and this is how many bytes I need. It's stored in the heap. How many stacks? When we first introduced our program modal we had just one We said, What's a stack?"  Well, anytime you call a function I need some space for those automatic temporary variables And also a bit of space to say where the CPU should go back to when it finishes calculating anything we need to do inside that function. And if the function is recursive then my stack is going to get lower, bigger and bigger, because I'm going to keep calling myself and I need more space on the stack. And if my function calls other functions, ya agian, my stack is going to get bigger. That's a stack. What if I had two CPUs working inside my process at the same time? Each one needs a stack. Yes? Because each one will be inside a function; that function might be calling things.
So here is the basic idea I'm going to have one per thread [gibberish] So our processes have at least one thread of execution And it would start in main, as far as we are concerned And finish when you either called exit or returned from main And now I'm going to show you how we can have multiple threads going inside each process So let's start on the stack. All the automatic variables, also known as temporary variables, (the reason they are called automatic is because they automatically disappear when we return from a function and our stack gets shorter) You'll find the return address for the CPU, in other words what code you want it to execute when it finished calculating the current function and the last thing we'll see is the previous stack pointer, or the previous SP Because we want our stack to shrink when we return from the current function So what happens if our stack gets too large? It's.... Stack Overflow. Yes! You've probably heard of the website called Stack Overflow. I actually registered as the username Infinite Recursion, I couldn't believe it wasn't already taken So we have a limited amount of memory so in a single threaded model, our stack would meet the heap. Kaboom, and we're out of space Our program crashes. In fact, by the power of Virtual Memory, what we can do is set up little pages of memory that are like quicksand If our program attempts to read them, then it will crash the program deliberately, we send it a Segmentation Fault. Yes?  [Student asking question] Can you sbrk more memory for the [stack]. No, no you cannot. Sbrk represents the top of the heap. [Another student question] No, but where they meet depends how big your heap is and how big your stack is What we're going to do is make multiple threads though, supposing we have multiple CPU's working at the same time So what we'll have to do is make our stack start in different places So there is actually a possibility of one stack hitting another stack if it gets too large Now let's have a look at some code, let's play with some code Here we go. C'mon. Great. We are going to be working with a thread framework called pthreads It's very popular, you can run it on Android machines as well Here's the plan: We are going to make our program do some CPU cycles We agree that our program will never print Hello World, it will just go around this loop forever But what I would like to do is have a second CPU working on my machine And for that, I can call pthread_create There's four arguments, let's have a look at them First, we have a pointer to pthread_t, some attributes which can just be NULL, this scary looking thing and finally an arg Let's talk about each of these First of all, this is a function pointer. It looks pretty scary, void star start routine ahhhhh! Here's how to read this: You see where it says start routine? Just interrupt that as the name of your function and then work backwards. It's going to return a pointer to a void* and it takes an argument void* And then we wrap the name of the function with an extra set of parenthesis. Let's take this and write our function Cool beans Alright, what should we do inside cool beans? Let's sleep for 2 seconds, then we will print out the pointer And a new line. Ok, so now let's call pthread_create We can have a pthread id. So we pass in the address of that stack variable, we aren't doing attributes today Now we can just pass in the function name. If you ever pass in a function name without the parenthesis, it means Tell me the address of this code" And finally we can pass in a void *, so we write (void *) 12345 Let's write something in hex. I need a hex value. How about 0xdeadcode?
okay right lets run this, see what happens and it wont quite work, cus uhhh gcc will say hey I've no idea.. what" uhhh doesn't know what sleep is, and shouldn't know what pthread is either so lets fix this we need uhmm pthread.h and also on our options down here we have to tell the compiler please I really wanna compile with pthread there we go ... what. okay!  right great so it printed out.. dead code.. so what I want to show you is... look we passed in a pointer to something over here and then inside our function called beans, we just printed the pointer value we did not try to follow the pointer value if I tried to print out the string of deadcode my program will probably crash thats probably not a valid memory address to read okay  and now my machine is getting hot why? because there a cpu we're running uhmmm it it it, my program never finished right, the first cpu is still running so what have we just proved we proved that we can do two things at the same time inside one process what do you think happens if I make a hundred threads my machine  might only have say a couple of cpus so how is it going to run those threads if I've only got 2 actual cpus. yeah? so what I do, is it lets one thread run and when it finishes it says next thread I know youve been waiting for a while you can have the cpu next actually its cleverer than that every 10 milliseconds or so a little hardware timer goes off and the operating systems scheduler comes up and it says you have been having chocolate for too long. in other words you've been having the CPU for too long Im going to put you on pause and let this other thread that has been waiting for a while have access to the CPU and so that thread gets to run so the operating system treats memory, the cpu and other resouces as scarce resources and tries to allocate them very efficiently and the different parts of the running system that wants to have access and how we schedule that  is actually an area of research so we have passed in something. you've seen that what we have passed in here arrives as the pointer though here lets make our program return something so  I'll return another void pointer lets call it one two three four how do I get that from another thread? Well, this time I'm going to pthread join so pthread join is a bit like wait it says don't continue until this thread has finished and uhh lets just grab it okay here is the thread I care about so lets just pass in the id number that we have before and uhmm I better have somewhere to store it right so now I just need a void pointer and I need the address of that void pointer and so lets finally print out the value of that okay, so what did we see of it here we still have two threads then the new thread the second thread slept for 2 seconds meanwhile, the main thread the first thread say okay I'm just going to join so it gets paused because its waiting for that second thread to finish and then the second thread finally prints out something prints out what it is given and then returns a vlue which we can then get back fromthe first thread using pthread join theres another way to exit threads and that way is called pthread_exit right so lets exit with something uhhh lets exit with ohh I dont know hello! oh, wrong way did I... ohh, yes okay and we'll cast it as a void ** pointer there we go if you call pthread_exit you're never going to execute, that thread is never going to execute more code after that point. you're telling the system Im done with this but my cpu for this thread does not need to execute any more so this time my thread called pthread_join prints out hello world and hello instead of the other return value soo pthread_join the exit here basically says I'm done and with that we've finished have a wonderful section tomorrow if you have any questions about it come down and ask me now there were three students that failed to put their exam key and by the way your quiz scores are in your subversion if you are one of those students that didn't buble in your exam key come down and we'll sort that out now
Ok, it's 11 o'clock. Good morning class how are you? Alright how's your shpar looking? I imagine some of you are celebrating that shpar is finished. Except of course you know it's not, because what we expect you to do now is actually not just make code that appears to work, but code that you are proud of. Code that is probably commented, code that has nice variables, code that you give someone else and they could maintain it. Some of the worst things about writing sloppy code is someone has to come back to you and say, What was this going on here?" "I have no idea I wrote that yesterday." Now's your chance to put your coding skills to test, not just to make something that works, but to make something that works well. And we'll do a finally code review next week on Thursday. We'll have some other things for you to do before that, but we'll announce that via email.  Here's what we're going to talk about today. We're going to talk about using threads. Threads are cool because we can now make our single process do multiple things. And threads are cool because they allow multiple threads to share the same memory and the rest of the state of your process. So if you've opened a file descriptor in one thread, you can use it inside another thread. The exciting thing happens, though, when you have to wait for one thread to complete something. And for that, we need to worry about synchronization. And that's what sets your programming apart from things you've seen inside CS 225 and 125, earlier courses and other people that might have just picked up some programming. The ability to work with multiple threads correctly so that it always works when not just ten users are on your website, but a thousand users are on your website or you've got multiple CPUs inside your tablet, or your phone, or your watch, then that's where synchronization comes in. But anyway, let's get started. Little question, little memory question for you. My thread calls pthread twice, pthread_create twice, how many stacks does my process have? Ok, let's pick someone at random. Hi! What's your answer? If you said one, guess again. Any advances on one? If you said two, thanks for playing, but almost correct, off by one. It's three! Why? Thank you, yes! We get a thread for free at the beginning. One thread must be calling main, our CPU must be executing code at main All we did by calling pthread_create twice is we got ourselves two additional threads. And remember, each thread needs a stack. Why? Well we're calling functions. We have to put those automatic variables somewhere. And, when we return from a function, we have to remember where we're going to go back to. So again, that goes on the stack. So for each thread there is a stack and we have three threads in our process. So if my code called created twice, that means I could be doing three things at the same time. Ok, so I've been talking about processes for quite a bit, and talking about threads. What are some of the differences between them? Which is bigger? A process, yes. How much bigger? It's HUGE! Our process is a massive object! It's got file descriptors. It's got a big virtual memory space. Threads are tiny. they live inside a process. If you killed a process, that's it for all of your threads. They don't have anywhere to run anymore. So your process represents the sandbox. Everything that your threads can do will live inside a process. So our process has security. It's got virtual memory. It's got an exit status. Threads live inside a process, and they just represent what you want the CPU to do. They represent the code, the position in the code that is currently being executed. So that means if you kill a process, ha ha that's it. All of your threads are done. So if you send, say, an alarm signal to your process, all of your threads will disappear. If the process disappears, all of them have gone. This is an important point. They just live inside. So if we've created all these threads, perhaps we want to stop them. Guess what, you can do that and here's what you'd call. You'd call pthread_cancel. Let's have a look at pthread_cancel. How could I cancel a thread? Easy, just send in that id that we got from pthread_create and you can cancel a thread. I don't want to spend too much time on this because, in practice, no one bothers to use this. Here's why. Imagine you are making a fantastic meal for Friday night your potential boyfriend, girlfriend, dog is coming over, and your cooking like a storm here. And then suddenly, BAM! your activity is cancelled. The kitchen is in complete disarray. It hasn't been cleaned up. What a mess! It's extremely rare that we can just cancel something and not have to clean things up. So what examples might we have. Well let's say you have a thread that's kind of calculating new digits of pi, or discovering prime numbers, or trying to mine bitcoins like you've come up with a new currency called CS241coins or something. You can probably cancel that. It was just a CPU intensive job. But if there's any kind of resources, then maybe we shouldn't just call this cancel and leave everything in disarray. So in practice what we tend to do is actually make a variable to tell our threads, Oh by the way, you should stop at some point." And if you call this pthread_cancel, things don't even stop immediately. Typically they will stop when that particular thread makes a system call, like open or read. We can discover all of the calls just by looking at the man pages. So this will be like the moment that your chef opens the oven door we say,  ok, you're out of here, we've quit you, we've cancelled you, no more work for you." So what a mess. We don't tend to do that. So let's write something that can be cancelled. We want to call pthread_create. What do we pass in? A pointer to our little identifier. We don't need any parameters. What's next? Oh yes, the function. I called it my funct, and an initial value. Let's just pass in NULL to begin with. And this will go on forever.
Alright, so, this little function can say initially we are going to just sleep for one second and then put something like HI!". Ok, right, so its gonna print HI!" So, now, I've got a program that is going to use two CPU's, if I have two CPU's. Uh oh, what happens if I only have one CPU? The scheduler!  The Linux Kernel is going to say okay, you get access to the CPU for say 10 milliseconds or 100 milliseconds and after that amount of time, I'm going to take you off the CPU and let the other thread use it. And if we do this faster enough, like 10 milliseconds or so then those slow humans will never notice, that actually only one thread at a time is on each CPU core And if it turns out that you make a system call like open" or "read" and it takes time for us to read that stuff from the disk Then you don't need the CPU because you are waiting for stuff so I can give the CPU to someone else. So the scheduler has to make those decisions and make them well. Ok, so for example this sleep, you don't need any CPU to sleep.  I can let another thread use that. So, what were we going to do here... Oh yes, let's change this so we can cancel our little HI" function. We'll sleep for 3 seconds here and then change to something like please_stop". And then I will just loop forever. So, what do were want to do here?  We want to say while (!please_stop)" keep going around. And finally, let's have a global variable...there we go. We know in C that our global variables are initialized to zero. Let's run this and see what mistakes we made. (waiting) Ok, alright.  Whoops, we didn't declare the thread id.  So, what's that?  pthread_id" I believe. (waiting) (grumbling)  Oh, I just put a t"  How about that?  Yay!.  Ok, alright.  So we print HI!".  Our main thread sleeps for a bit and then calls "please_stop" And our little thread that is going around the loop says oh, look at that global variable, I better stop". Now I use global variables for a quick demonstration. Obviously we could put that inside a struct. We could pass something to the working thread inside here and we could use that to communicate with the other struct so we could have some control if we agree to share some memory.  Now I can hear my CPU fan going. (fan noises) Do you hear that?  Good. Because the CPU is constantly doing that little while loop in the main thread. So let's do something better than that.  What we would like to do of course is wait for the other thread to finish. One way to do that is to say pthread_join" and say "here is the thread that we want to finished" And we would like to know it's exit value. There we go.  We can find out what it is. Alright, here is my exit value and we can say return something here So what when we call pthread_join" again, this second thread is going to not require anymore CPU time. Because not it is waiting for the other thread to exit.  So that is one way to write this program.  I can also talk about pthread_exit" Let's write a very dangerous program. This is the _killer_monsters_take_over_the_world". You will agree that we probably should not run that function, yes? Well that's okay, because I am going to call pthread_exit before it. And I do not need a return value. pthread_exit()" says "hey, I am the chef and I am done.  I'm leaving the kitchen for good". If you call pthread_exit then, you are saying this is the thread's return value" and no more code will be run by that thread. _killer_monsters_take_over_the_world" will never happen.  This stuff about having exitvalue" and "pthread_join" in this case, that is never going to happen. pthread_exit()" simply means "I am done".  A little bit of knowledge for you, if you call pthread_exit()" inside the main thread, the original thread, like we did just did the rest of the process will actually keep on running. The pthread library actually says you know what?  I am actually not going to quit this process immediately I am going to wait until ALL threads have finished.  Let's prove that.  Let's call pthread_exit()" here.  I'm going to comment this out so it compiles.  Instead I will call ... nah, this is good. So then, what will my program do now?  That's right, it is just going to keep printing HI!". It is not going to take over the world. Instead what we did is we created another thread and our main thread exited.  So, let's go back to this.  Let's answer some of these questions. What is the difference between exit and pthread_exit? What does exit do? It kills the whole process. Yes, it says Hey, this process is done and here's the exit value. By the way, it also does a little few extra things for you. If you've written to the C output buffers, like stdout and stderr or anything else those get flushed and those file streams get closed for you.  So if you call exit, all of your threads are gone. We're done" Your process is done.  And it doesn't matter which pthread calls exit(). You are saying This whole process is done. Wrap up the shop, close all of the kitchens.  We're gone."
pthread_exit that just means no more for this thread that particular chef has walked out of the kitchen and will never come back so before you call pthread_exit make sure your thread has cleaned up any resources that it might have acquired questions? yes? ok so umm when a thread finishes it can finish in two different ways, it can.. call pthread_exit or can return in fact, they are actually equivalent so this is a way to send some information back to the rest of the process and we had an example down here calling pthread_join and saying what did that thread say at the end?" and you don't have to use this mechanism is actually common to make a struct and pass that to pthread_create That's the purpose of pthread_exit and this return here is that you can get the exit value let's say that you wanted more than just a void pointer what we can do here is define some sort of struct umm i won't bother the struct definition i'll say hey, let's have some memory and i'll call it my to do struct" ok so calloc( sizeof(todo)) and i just need one of them and then i would set..oops set things up on this hey like..umm.. you know.. start.. blah blah blah please stop..umm zero exit value in here, etc. so i could use this struct because both my main program and my thread that knows about this struct cause i can.. pass in it so that allows me to assemble a whole body of information that i want to pass to the other thread ok let's get back to our little questions here why would you call pthread_exit in your main method well, this is typically done in kind of simple or small programs where we say most of the work is actually going to happen by all of my other threads and my program can finish after all of those other threads have finished so we would do this if there was no clean up in the main thread and we'll be happy just to wait until all thread are done so this is equivalent of saying hey last person out of the kitchens turn out the lights and the process will finish so I gave you two ways that a thread can be terminated just now, I said it could return from its function so.. we could .. return a value and i gave you that 0x12345 thing so.. if you return from the function that was originally started by the thread i also showed you that you could call pthread_exit but apparently there's four ways What other two ways might a thread exit? and i have mentioned them already in this lecture yes! yes! if someone calls pthread_cancel() on that chef they're done, okay yes so if a thread is in a cancelled state, it may exit and how else might a pthread ... yes?! yeah, the whole process dies so if another thread for example, segfaults that's it for all of your processes segfaults if like blurring up the entire chemistry lab or the entire kitchen the whole thing is gone the whole process is gone we need a valid process in order for our threads to finish let's talk about pthread_join it actually has two purposes.. we can wait  for a thread to finish and get its exit value the other thing it does is..free up resources okay what resources might that be? well every thread has some space in its process memory for its stack and every thread has an exit status, an exit value the library is going to keep them around because who knows, someone will call pthread_join on the thread so we can only release those resources after pthread_join has been called if you're writing a short simple program and you don't about these things then fine but when you want to write longer running programs that don't have resource leaks you should call pthread_join on every process, i mean, every thread yes so pthread_cancel, you're giving a chef another thread the marching order to say hey leave okay. I'm canceling you, i don't want any more of your work I'm canceling..you know that stuff i told you to do? don't do it anymore, okay? so.. pthread_exit says i'm done and by the way, here's my result and i .. so it's an act by the thread that says i don't want to do anymore work yes? yes! oh okay, right the point i was making here is.. that you know that when you return from main, the process is done you know that when you call exit, the process is done okay pthread_exit has a supple part of the specification that says the main threads is finished, but the process continues until all threads are finished corrrrrrect! yes so, if i called pthread_exit() after printing  - eh hi right? now the process is done so it's the last chef out that turns out the lights to the whole process
So, i have thrown pthread_exit at you, pthread_join, pthread_cancel, etc This is an exposure to the words in the vernacular, this stuff is not going to sink until you play with it So, i encode to play a lot with these things and to write little programs and see what happens Okay, if we don't call pthread_join on a thread, we get a resource leak And eventually We wouldn't be able to make anymore threads We can't reuse the same memory address from the original stack We are still hanging on to the exit value so we are using up more memory Okay so the next thing Take a look at this kind of typical kind of code here And the...this..something wrong with it What question is: What? And how could we fix it? How could we make it valid? Now your first instinct might be .. HOLD ON IT TAKES A VOID STAR POINTER That's okay All i'm doing is passing in a pointer To start So that.. My new thread can read a value Presumably, this 42 So, what do you think might be wrong with that? Just take a moment to talk it over with your neighbors or neighbor and see how we might fix it I'll walk around in case you got any questions - [silence] What did your neighbor say? What did YOUR neighbor say? *whisper from student*  - It was out of scope Ok we got a scope problem Yeah, so, first of all there is no security It's okay for one thread to access another thread's stack, it's not like we're going to get a segmentation fault The hardware doesn't know or doesn't care two threads are stomping over each other's stacks But we do have a scoping problem And it's this: we're passing in the address of start And start, as we know, lives on the stack How long is that address going to be valid for? Answer: Not very long, we're about to return from this function So, when will my funct start? Answer: I don't know, it's up to the kernel to eventually decide get around this other thread Maybe we'll put this first thread on pause beforehand and give pro to the new thread Or maybe this new thread will start much later on .. 100 milliseconds time By which point, what will be at this particular address? Could be anything right? It could be our original value, it could be being reused by a completely different function at this point So our problem is with time Our problem is that we gave the address something and that variable is no longer in scope Alright, how can we fix this? Well One trick is to say: I'm going to put this magic word static in here And if I do that, it's no longer an automatic variable It lives just once as a global variable inside my whole process But that is pretty heavy handed Alright, now I only use this start variable and I better keep its value until i'm sure another thread is run How else can we fix it? We could use malloc() And allocate some memory in the heap We would have run into the same problem if we immediately called free In this thread Because we would have created some heap memory Passed a pointer to it and immediately freed it. OH NO WHOOPS I didn't give my new thread any time to actually read that memory So if you do use malloc()  Don't immediately free it, instead.. Let this function Free it after it runs One thread can create heap memory and another thread can actually free it That's perfectly fine, they all live inside the same process And there's one heap I think another way this might be valid is before we turning We could call pthread_join On the thread If we did that, we know that the new thread that is going to run my funct will actually finish before this function returns So we've solved our timing problem We've made sure that we don't finish that this variable doesn't go out of scope Until the other thread has finished We have just encapsulated from a time point of view The running time of this other function and made sure that the running is within the scope of this start thread's function
Yes Yeah Ok right. So what happens if you put static inside a function? Yes, so the variable itself lives forever, but static makes it a secret variable. yes the scope of it, the name start, is only available inside that function but the actual storage of that variable is for the lifetime of the process thats like one of those awful interview questions hey whats on page 37 of the C standard? i dont know. I didn't write it Knowing precisely how static works is an exercise left for the advanced C programmer But by defining static, the life time of the memory is for the duration of the process. other questions? yes? To cast an int to a void pointer, no that's the other way of solving, if you're sure that a void pointer has enough bits to represent the parameter you're trying to pass in You can also just say, look void Let me choose a different value like 71 That means, I gotta type as a pointer to some memory I'm not going to say what kind of pointer yet Im going to pass in this value 71 you can do that providing you write the code to the other end to simply cast it if you attempt to read at memory 71 oops, you'll get a segfault I will not talk about that right now, but yes, that's another way of solving this problem How about this one? So what I want to do here is that I want to send my value of i from 0 to 9 to some new threads So each one can get a value Why does this code not work? So take a moment with your neighbor to review it and I'll start writing it up as a demonstration - [silence] Ok so here's a version of that code The first thing we might comment is what might this code print out? It might jsut print out hello world and nothing else it could be that we return from our main before those other threads ahave  a chance to start up Before those chefs can be employed and waltz into our kitchens, the process itself is exited because we've returned from main alright, how should we stop that? Well we could just call pthread_join on every one of those ids But you and I know we can call pthread_exit() here and leave it up to the system to finish a process when all the other threads have exited. ok right, so let's run this And this is the output we get Im printing out the value that's actually sent to each new thread and also the actual pointer we've got as well the first comment is look at all these numbers! They're all the same And it seems to work. If we only tested this with 6 threads, we think our code is fantastic! look at the all the threads I'm starting But instead I get 0,1,2,3,4,5 and four 10's. Why? yes?  So the for loop finished So, for the early threads, what happened? well we ran our loop, we start a thread. well we ran our loop, we start a thread. well we ran our loop, we start a thread For the remaining threads, it so happened we went around the loop and those threads did not start.  They weren't scheduled on the CPU They're going to be. It's just they didn't start straight away Eventually they do start And theyre all given the same address the address of i it just happens to be a stack variable in my main thread by the time they started, we've already incremented the value it had already been incremented up to 10 and we saw that they really are looking at the same variable because we've printed out the variable that was given to us and that address, 7fe blah, blah, blah is just part of the stack of the main thread So let's to fix it We could make a struct for each of our threads using malloc() Or we can make an array in global but let's do the trick that you suggested lets just cast this to a void pointer because we're C programmers and we know what we're doing. said every C programmer. and what do we get? whoops Absolute garbage, yes
Ok, so this time, yeah, look each address that was given to our program is valid. But we shouldn't try to dereference it.  We should actually just try to say,  look, I know you gave me a pointer to some memory, but I was kidding. i'm not actually interested in  using as a pointer to some memory I just want to cast it back. Change that current bit pattern you got as a pointer to a bit pattern that now represents an int. Do not pass go. Do not attempt to read memory at that location otherwise bad things will happen So, here's another way of actually getting the right results. So there we go. Now we have all of our numbers And something you might notice thats surprising is that it doesn't count up 0 8 7 6 5 4 3 2 1 9 Why? Does someone dare speak that hasn't spoken yet in CS241? Yes, in the back! Yes, thank you. There's no guarantee when that thread is going to stop. and in fact it might be paused half way the scheduler might say  actually, I know I was going to give you the  kitchen I was going to give you the CPU, but actually I've decided to give the CPU to another thread, so  we don't know when they're going to start, we don't know how much time they're going to get because the scheduler is part of the operating system is trying to make best use of all possible resources so we have something running but we don't necessarily know in what order those threads are going to run. yes? if I had 10 CPUs it could be that every thread is given a separate CPU of course it depends on what else is happening on your system, right? it could be that I've SSH'd into your box, it could be that your tablet is also using one of those threads update the screen at the same time. maybe check your email, etc. so it is possible to try to schedule threads on different CPUs, but in practice it doesn't always happen the way that you actually specify it. yes? yes, you can set the priority of different threads. anyway, enough of this, let's have a look at page two  there are various C library functions that you've probably played with already like strtok() when we wrote our shell, or hey I actually wanna know what the error number is as a string" and if you read the man pages of these, you'll say oh they're not thread safe". ok everythings broken. what does it mean that not everythings thread safe? it means here be demons. here's where you can write code that looks fine, pases code reviews, passes simple tests and breaks when you put it into the next hart monitor so let's see an example of this here's some kind of typical code, let's find out if it's thread safe or not and perhaps you could figure out what might happen if this little two message function was called using multiple threads. so what might happen if two threads happened to call this function at the same time? why's it not safe? why could bad things happened? yes? [silence]
So if you don't have enough CPUs to run all the threads, the scheduler says I've got this stuff to do", and puts them in a queue. And we'll  be talking about that when we talk about schedulers. Every thread, every process from the scheduler's point of view is either in a runnable state or running, or finished, or about to start so part of its job is to keep track of that Okay so we've got a little function. Its job is to turn a number into a string, and we wrote some implementation, we've got some memory, and it's not thread safe. Why? Yes, at the back? Yes! So if you make something static there can be only one. This is the highlight of the variables. So we've got a single piece of memory, called result. And all threads if they call this will therefore be writing over the same piece of memory. So if you have two threads that are doing this about the same time then they're going to corrupt each other's result. It's like you and I trying to share a secret piece of paper, and I come back to it and I'm like what's this writing on it? I didn't write it before." We need to make sure that doesn't happen in our program. So we've got a problem here. How can we fix it? I know! Let's just make a temporary variable, an automatic variable, and be done. Yes? It's Friday, the best code is always written on Fridays. It's actually not true. You can actually do data analytics on check-ins and see how many bugs are generated by code on Fridays. Fridays and Monday mornings are the worst. So what mistake have we made now? Okay yes we are returning the pointer to some local memory and after the variable goes out of scope that is not longer valid, that area on the stack is going to be reused for other functions we call So we can't just do that Okay, so how can we fix this? Well one thing we can do is not use any memory inside here at all. Instead we'll change this to take a pointer to some external memory. And if you look at the c-library, you'll actually see this has happened over time. There were early versions of functions which just declared things, say, using static. The nice thing about that is it's cheap. We don't have to wait for malloc() to find us memory.  But the bad news is that it's not thread safe. So later versions of similar functions allow us to pass in a pointer to some memory that can be used.   So I'll come back to twelve in a moment. First of all, there's a quiz on Monday! What? What? Yes, it will be about fork(), exec(), basic synchro stuff and I/O.  Here is a hint about some stuff that might be on the quiz, and you can find references to all these things inside the wikibook. Is it comprehensive? I'm not quite sure what you mean by that. Will there be things on there which are challenging questions? Absolutely, yeah. They will include gotchas so know the difference between sizeof() a type and sizeof() pointer of a type. It will include code that is good and bad, you are expected to notice when it is bad.  I have a habit of writing multiple choice questions which state things like hey which one of the following statements is not true?" So that means you have to recognize false statements which are not true Right, let's just finish of with these then. The advantage of threads over forking processes: Hey, they share memory, so it is easy for us to communicate between threads. Very very easy They're also very cheap. And you too can create a new thread, just call pthread_create()! It's trivial, it's easy! So can I fork a process with multiple threads?  Yes, but don't.  Unless you know what you're doing. Unless you're really sure you know what you're doing. Unless you're crazy and you're really sure you know what you're doing And you want to maintain this code for the rest of your life So here's why: when you do this, the only thread which survives this cloning is--you know how I said Fork, you're gonna clone everything"? I lied! --the one thread that calls fork() continues.  In the copy, in the clone. All of the other threads have disappeared. They no longer run So now all of the other threads in the clone that were doing things have just disappeared. They may have been in the middle of calling malloc(). They may have been in the middle of doing something important. And now the good work that they were doing has disappeared. So that's why in practice it's extremely difficult to write good programs that fork() AFTER they've created more than one running thread. So yes, if you want a world of pain.  Otherwise, try not to. So let's finish with this: condition variables, semaphores, and mutexes.  This is the meat of the couse This is the cool stuff. This is the stuff that is going to make your head explode These are the primitives we are going to learn about so we can communicate with our threads. So we can make sure that our threads pause while another thread finishes its work So that we can make sure that threads don't step on each other's memory structures. So that we can have ten threads write to a single structure and know that the result is valid at the end.  So that we can have threads that don't fill up buffers then spin and use up CPUs, instead intelligently use the CPU And we'll be talking about those next week. Have  a wonderful weekend.  Look out for an email from me about the next assignment and the MP. Thank you very much and I'll be here for questions. For those of you that forgot to write down your exam key on the last exam we can find your exam script right now. I know there was like two of you. One percent of the class failed to write down their exam key. So let's fix that
[background noise] good morning you gin lads and welcome to the bountiful C the wonderful c, the giver of life, the platform that allows us to compile our codes on new hardware you wanna take a program, you wanna put it on your new hardware, don't worry you just need to make a C compiler the wonderful C perhaps you've written it in python, doesn't matter, python itself is written in C perhaps you've written Minecraft ahhh,well don't worry about that, that's written in Java, well Java of course is written in, well c++, but nevermind, it's almost C perhaps you've written a ruby program, well guess what? ruby the interpretter is written in C yes, so C is underneath it all and that is partly why C is such a powerful and potent language it is also a fantastic langauge for working directly with hardware because we can create memory structure that map directly onto bytes and bits of our hardware so C gives you tremendous power because it's so close to assembler but a lot easier to write than assembly code alright, so we've been talking about making our c programs run with say two processes or doing two things at the same time well this is where things start to get interesting for example, let's count our gold  I've got a little function here called countgold() and you can see this is going to effect  so let me run this, i'll make a separate thread to do it alright, how do I do that?  well I need to pass in some sort of identifier and then I've got some options I don't care about what next? and then the function countgold and finally I want to give countgold a parameter of nothing, so I can just pass in null here and of course we want to wait for this to finish this time I'll call pthread_join() because I don't want to just finish at this point, I want myself to print out the value of the sum great, so, let's wait on this and I can, I'll have to put my little pthread_t type in here tid1 and I can actually have an exit value as well so what did it say? that can just be a, whoops, void pointer and I'd better give it the address of that thing so let's compile this and see what we get arlight, argh, sum is zero now why was that? that's a good question, why was that?  we should've waited on this so let's first of all check that I'm using this correctly so we'll check the value of tid and see what it is and we should have  ok we've got a valid value so why did pthread_join() not  join terminate OK, alright, so at this point OH, yes, hahaha what did I pass to pthread_join()? the address of tid1 not the value of tid1 so, we needed the address up here because we wanted pthread_create to push the id into that variable but pthread_join() we just said here's your address and pthread_join() says thank you very much for that address, I'll take that as your thread identifier no, we wanted the value ok, so normally because that would take us about four or five days to discover good, so this time now it's waiting and finally it prints out the sum is a million fantastic now let's not just have one part that's going to count the gold, we want two so we'll have two threads going  they're both going to run the same function, but you and I know they both have their own threads so they both have their own stacks so each thread has it's own value of i OK, so, we'll, of course if we didn't do any waiting ah, thank you we didn't do any waiting, then our value is just some other value happens to be 56,000 in other words we had two of these other threads running at the same time and our main program just decided to carry on and by the time we actually read the values  those other threads had already incremented it so we'll change this now to actually wait and any time that we copy paste code be very very careful to make sure you change everything you need to change I don't need two exit values, I don't care that both of them are going to write from the same thing so, now my program says OK,wait until the first thread is joined and then our main thread says now wait for the second thread to join and there we go my sum is about one and a half milliion whoops, I did not get two million even though both threads were just adding one to the sum perhaps you can see why we'll surely then we can fix this by saying rather than sum plus equal one, I'll just say sum plus plus
ok, what would our value be now? again, about 1.5 million, certainly not two million our pyrax cannot count OK, so why did it fail? why did my sum not get two million? thank you! yes! two threads are touching the same memory location so even though we wrote sum++, sum++ is not an atomic operation now life would be easy if our threads were like gorillas if they walked up to a memory location mine! they changed it, they added one to it they asked it any other thread and they threw it back ok, but that's not how it works of course, no instead we're copying bit patterns we're copying bit patterns from main memory into the CPU  we're running through our model adding machine and then we're putting the value back into memory during that time another thread may have come along and coppied the original bit pattern from memory and done it's thing inside its CPU and then put it back so hopefully you can see that it's possible that the value could be less than two million if it turns out that are trying to add at the same time in fact it's possible for  the value to be much smaller than that but let's talk instead about how we can actually fix this we've made it deliberately interesting by making sure that each threads are touching the same memory it would be pretty boring if they were working inside their own stack space or we'd give them different memory locations to play with, say if we'd give them sum one and sum two then of course everything would be fine life gets interesting when we actually have two threads competing and working on the same memory so what we'd like to do is say 'oh I've got a problem and here's a piece of my code that I only want one thread to play with at time' in other words, I've got a critical section and inside this little example here this single line is my cirtical section it's the piece, it's the lines of code, where you say 'I only want one process or one thread to read this memory or modify this memory' because if I have two threads working then they may see things or leave things in an inconsistent state now we're programming with a very simple exaple with integers and sums but now think about your other data structures you wrote in say CS 225 where you've got multiple memory structures, you've got pointers to arrays, integers which reperesnet the number of things in an array if you didn't write that thing directly than the STL library did it for you all those things need to be in a consistent state if you wrote linked lists then you'd better make sure that you're sentinal value is actually present and there's a few nanoseconds where that's not true so whilst you'll updating a data structure you don't want anybody else to touch it you don't want anybody else to read it and you certainly don't want anybody else to try and update it at the same time so that's where mutex locks come in  so a mutex is a very valuable thing it's like having a girlfriend or a boyfriend or a dob it's yours and you're not going to let anybody else own it very objective thing it's mine, I'm jealous don't let if you are holding a mutex, you don't want anybody else any other thread to try to lock that mutex if they do they have to wait until you've finished with it now to be procise we are locking and unlocking I just wanted to give you some ideas so that in your next jealous outburst you can remember this lecture alright, so, let's have a look to see how we can do this, what we'd like to do is around this critical section we'd like to lock a mutex and afterwords we'd like to unlock it unlocking doesn't take anytime at all locking usually doesn't take anytime at all unless somebody else has locked the same mutex in which case you're out of luck it's a bit like trying to walk up to a counter, the clerk is currently busy, you'd have to stand there and wait and twiddle your thumbs in fact you might actually use up a bit of CPU time while still twiddiling thumbs, it's often called a spin lock which is how this thing is implemented underneath but we don't need to talk about that but essentially we've got a little piece of code that says ok, i have to wait i have to wait i have to wait i ahve to wait until the mutex lock has been unlocked but they're designed to be efficient for when you want to lock them and unlock them in the very near future so let's actually have a look at the code for that, how do we do that? we'll it's part of the pthread library and we can say I've got a pthread_mutex, here it is, it's a pthread_mutex_t type and I'll just call it my mutex one so now we want to lock it how can I possibly write that code if pthread_mutex_lock() what do I need to give it? the address of the mutex and guess how I unlock it you write pthread_mutex_unlock() OK, so now we think we've got working code let's try it and just for fun I'm going to reduce the number I wrote by an order of magnitute to make it run a bit faster tick tick tick suddenly we noticed even though I made the for loop to help with the speed I think it returned OK, heres, here's to the first surprise, it shouldn't have worked [laughs] it appeared to work, but that's just lulling us into a false sense of security the second surprise is that it took a bit longer so at least I'm sorry I took the loop down by an order of magnitude yet it still took a long time so this is a not free the lock and unlock are not free, it takes a certain amount of time especially if you look at how much overhead we're doing in this example we're just incrementing and getting them out of a loop. so they don't take a small amount of time to run the second thing is that they may not work if you've forgotten to initialize them and this time for a lecture demonstration i was unlucky that it did work what we should do is make sure that our mutex locks are properly initialized alright, so how can I do that? well before using them we should call pthread_mutex_init and let's look at the man page we can pass in a pointer to our mutex as some attribrutes if we'd like as well so I can say 'ok initialize my mutex and here's some additional attributes I could set up for them as well
ok there's another way to initialize them which is to actually set an equal to this magic macro pthread_mutex_initializer ok, so, if I do that then I've got an initialized mutex and now I've got this object not in a c++ cense, but in terms of something conceptually I can think of as an object that I can lock and remember, the lock means that no other thread can lock the mutex so I'm using it as a way to serialize who gets access to my sum variable if your thread comes a long and tries to lock this mutex one then it has to wait until I've finished with that mutex and similariliy if you've locked mutex then I have to wait yes? then we go back to the original problem we have arbitrary values ok, so yeah, we could do that, we could have another little loop down here for example yes and we're back to our same problem that the CPUs are now stepping over each other in trying to read and write to this memory location pthread_mutex doesn't give you any magic, it's a very low level way just to stop two or more threads form continuing it's up to us to do some code analysis and say 'yeah, actually I've got a problem with this code' I forgot to put a pthread lock around that other loop [student question] correct, yes, you can just think of it as a very simple little busy loop the lock thing says 'hey whilst it's mutex is locked by someone else I'm going to wait' that's all it does it doesn't magically say and the code in here is amazing and bug free it doesn't say that other pieces of memory are especially locked, it's just a loop it just happens to be a clever loop to be sure that there can only be one  if two threads called mutex lock at the same time only one of them wins only one of them gets to go to into the bathroom the other one has to wait a bit but eventaully that first thread will presumably unlock the mutex at which point the waiting thread can say 'oh great, it's my turn to lock it' and continue so it's a busy loop, it tries to be efficient in the case that the lock is unlocked because most of the time there isn't a conflict most of the time it's pretty unlikley that two threads are reading the same data structure it's just that one percent of the time or .1 percent of the time we're lucky and our CPU, or two or more CPUs are trying to read the same memory when we don't want them to yes? [student question] yes, in this tiny example we would actually get a better performance if we did that if we just locked the whole thing for the entire time in other words for this silly little tiny example there's absolutely no point running two threads yes trying to have two threads accessing the same memory we might as well of just had a single thread that weant up to two million ok, so the parallelism in this case or the speed of it just isn't worth it the reason I've chosen this example is because it's trivial to show a problem with two threads incrementing the same piece of memory it would not be a problem if sum was the local variable because local variables are stored in the stack and the stack is per thread and so presumably they'd be updateding their own variables what happens if you forget to unlock? ok, imagine this, imagine the person in front of you goes into the bathroom and never comes out what we've discovered ladies and gentlemen is something called dreadlocks - nah - no, actually deadlock nothing to do with dreadlocks or bad hair or goodhair if you like dreadlocks so we've got a problem of deadlock we've got one thread waiting for another thread to unlock a mutex and it never happens right, our poor thread is stuck alright, so let's do that to our poor little program and you can tell me how quickly my program will finish three years later we're still waiting what happened? well I had one thread that locked the mutex and a second thread that said 'ok, i'm going to wait because i need to lock this mutex'  so it never proceeds, it never gets into the for loop meanwhile our main thread is waiting for both threads to finish when does that happen? never so if you think C code and programs have been hard to debug so far you ain't seen nothing yet. baby no because our program stalls, it gets stuck if we were to debug this we'd discover that the main thread is here, it's waiting it's waiting for soemthing that never happens we have to say while why is it waiting? what happened to that other thread? so like sherlock holmes you have to say look this thread ever unlocked a mutex yes? are you taking about the mutex or the sum variable? so in the - we had the code before ok, so the code, the code as written right now allows one thread to work through the whole for loop and the other thread is just spinning there waiting for the mutex to be unlocked before it can lock it so it doesn't do anything now you've got the case where each thread before they can increment the sum had to lock the mutex has to own that mutex
ok, only one of them will win that fight if they happen to try and lock at the same time one of them still wins and the other one has to wait if the other thread comes around and tries to lock it whilst you've got the lock it has to wait and it keeps going around, yeah, so you take the lock, you increment it and give the lock back goes around again, yes yes? [student question] yeah, it's not a very good program I agree correct, in some cases the only reason to do parallesism is simply to add it to your resume it may not actually give you a speed up and this is an example of that. it's just a silly little example we'll get to to more complicated examples soon in the course where we talk about multiple threads spawning to read and one thread wanting to write now, I'm showing you code but I want you to stop for a moment and think about this conceptually we're talking about threads, but this could apply to real life. this could even apply to processes now I'm not going to show you any code with processes but there are certainly times when multiple processes are asking the operating system to do things at the same time 'hey I'd like to write to disk at the same time' sorry, I'm not going to let you do that 'oh I want to open a file descriptor at the same time as someone else' now the operating system has to play these same kinds of tricks to make sure that the data structures are valid whenever a different process tries to read it so the operating system is full of code like this to make sure that we correctly work with our data structures even when different processes are trying to run, or use them or read them or write to them at the same time right, so, the other thing we can do is talk about this pthread_mutex_lock() yes, it's just a little data structure here pthread_mutex_t but behind it there's additional resources this elusive thing I just called a spin lock is behind it and so we're tying up system resources in creating a mutex lock. not much, just a tiny bit so good C programs will free up a mutex when they've finished using it OK, so, down here we can call pthread_mutex_destroy() and pass in our mutex that doesn't do anything to the C variable, but it does say to the pthread library 'hey any resources you've connected to my little C variable can be released and reused'. a question? [student question] aha, that's a great question if one thread locks a mutex, can another thread unlock it? no this is where the bathroom analaogy is great. if you lock the bathroom door you don't want anyone else unlocking it no, the idea of a pthread mutex is that you lock it and then a few nanoseconds later you've finished updating your data structure and then you're going to unlock it it's an error for another thread to actually try to unlock it also with a simple mutex like this unless we give it additional options it's an error to lock it twice if you try to do that the most likely thing to hapen is that the pthread library will say 'that mutex is locked, I'm just going to sit here until it's unlocked' but there's a problem becasue you locked it so it's never going to be unlocked, so now you've got code that's hit a deadlock again that this poor little thread is waiting for itself but it can't continue because it can't execute anymore code because it's waiting for the lock yes, so don't try to lock it twice you can give more arguments to pthread mutex locks to say add some more debugging and checking and it will complain to you if you do things like that but in practice we don't do that because a) it slows our mutex locks down and b) we should just write correct code anyway right, good luck with that yes? [student question] aha, ok, let's suppose the mutex is locked and you try to call destroy the answer is, don't do that it can lead to undefined behavior  the exciting thing about undefined behavior is that it's undefined! it can do anything! it could start world war three, it could change your facebook status to single ok that was a joke um, it could update your tinder profile, whatever it could - so, so - don't do this  these primatives are designed to be extremely high performance so as a result there's no safeguards so look back with nostalgia at Java where Java would say 'excuse me you've gone past the end of the array' I'm going to politely shut down your process and throw an exception this doens't exist anymore, you are ice climbing here and you'd better make sure that every line of code you write is correct so write code slowly, especially code that deals with locks especially code that deals with malloc and calloc and free and realize the lifetime of functions now can be very diferent so for example here's a student error I saw once where we had some memory  ok, so calloc sizeof an int, lets have enough memory for say a hundred of them. we'll pass this in as a parameter and then we'll free our memory not a good idea alright, because if my count gold function is now using that memory the code I've just written assumes that I can free it straight away well hold one, we don't know when countgold is going to end so just because we don't write anymore code in our main function that uses this memory doens't mean we can immediately free it no I've probably got another thread that's going to use that memory so now we have to think of the lifetime of our threads as well and how long their going to run so like I said this is like ice climbing, you do it carefully and think about each line of code and the lifetime of your data structures and whether they - what happens when two threads try to work on them at the same time alright, any questions about mutex locks? ok, so, I'll just reiterate the main points again they're not magic they're just little loops a pthread lock is basically just a little loop until that lock is available so it's up to you to use them as such
yes, if you had two threads using two different pthread locks that doesn't help you at all you're going to protect some memory use the same lock to protect that memory everywhere you access that memory right, are you ready for slide two? k, slide two yes, in todays lecture I'm not just giving you one synchronization primitive, but you get two synchronization primitives yours for just 19.95 yes, so we're going to talk about counting semaphores here's an idea mutexes are a little constrictive, right? first of all I can only have a lock and unlock from the same thread and they don't have any internal state other than whether it just locked or not so sometimes we want something which is a bit more general and this is where a counting semaphore is very useful because it has the idea of a count and everything is happy providing that count is at least one but where we get down to zero or lower it stops it doesn't let you reduce the count  so it behaves like a resource counter the integer that we're going to put inside this counting semaphore and if you try to reduce the count you can't, you have to wait so I have a little example  so what's the code look like in terms of the counting semaphores? well what you'll see is this sem_post and sem_wait and fundamentally what they do is they increment or decrement the count inside the semaphore you never see the count directly and in fact it's quite common to increment and decrement - sorry it's quite common to set the initial value as say zero or one so imagine a pizza box with slices of pizza in it and anyone, any thread can come up and say 'yes, I'd like to eat a slice' unlike the counting gold code I gave you, I guarantee you that each person will get a slice and we'll keep track of the number of slices in each pizza box so you can come up and eat a slice of pizza if you try to eat the slice of pizza and there's no pizza left, you wait here's the nice thing about semaphores that you don't twiddle your thumbs no, your thread is put on suspended animation, you're not going to use up any CPU time so if you want pizza and you ask for pizza and there's no pizza left, I get to freeze ray you and you're not even conscious of the fact that you've paused, that you're stuck now, is this the end of the world for you? no because here's the good news other threads may come along and put pizza back inside the box they can increment the count when they do that I can wake you up and say 'hey guess what? there's pizza now!' and you say 'oh thank you very much!' and take your pizza slice and carry on your way right, so this little analogy is what these sem_wait() and sem_post() calls do so how do we use a counting semaphore? here's the basic idea, we're going to say init and we want to say how many slices of pizza do we want inside of our box our what's the intial value so for example zero might be a common idea or we might say actually I want say three slices of pizza and then we might call wait I'm decrementing those counters, if there happens to be pizza inside the box, if there happens to be a non-zero value inside my counting semaphore these can return immediately OK, so I can call wait three times and they would immediately continue but if you call wait a fourth time your thread gets stuck inside the wait call doesn't need to use any CPU for this because your operating system is now going to take control of that thread and say 'Im sorry, you cannot proceed, there's no pizza left' ok, the good news is that on another thread we can call post post does not block, post will return immediately but post is the plus one effect, it says I want to actually increment the number of pizza slices inside this counting semaphore so when you do that anybody waiting to eat a slice of pizza can now continue, they will decrement the count themselves and continue we're going to use this counting semaphore for some more advanced examples, but one thing I want to show you or one thing you should notice is the way you post now they, they don't need to be inside the same thread. they could be, but they don't have to be right, questions about counting semaphores? yes? [student question] ok, right, so, let's imagine you've got any empty pizza box two threads walk up and say I'd like to split a slice of pizza. we've put them in a state of suspended animation and then you walk up and you call post on this pizza box here's what's going to hapen first of all you get to walk away straight away, you can carry on whatever you were doing one of the two threads that were waiting will win, ok? one of them will get to return from their wait call now of course, what's left inside the pizza? because you posted but another thread immediately waited on that and stole that slice of pizza so the count is still zero, so any other threads that walk up and try to eat pizza, theres nothing left in the box but we've released one of those threads
[nothing] yes? correct, it's not necessarily like a queue it's actually operating system dependant we can give hints to the system as to how fair it should be for example, you might say that the thread that's been waiting the longest should have access to the pizza, that seems pretty fair to me but actually we have different definitions of fairness for example, the surgeon that is waiting to eat the pizza has a higher priority than the non-surgeon so we can actually assign different different priorities to our threads but that's some more advanced stuff that we don't need to worry about for today. for now just assume that you don't control it, the operating system controls who gets to eat the slice of pizza I don't know about you, but I'm going to be pretty hungry after this lecture so, yes? haha, great question! can you use this to implement lock? that's such a great question, I was about to ask it to! can we use a counting a semphore to implement a lock, a mutex lock? in other words, if I hadn't told you about the mutex lock, could you do it with a counting semaphore? that's true, yes, so counting semaphores are more versatile in that sense but in terms of the counting gold example I showed you at the beginning of this lecture could you do it using a counting semaphore? well the answer is yes my next question to you though is what should be the initial value of the counting semaphore? so if we were to go back to our code here and we didn't want to use lock and unlock, but we wanted to replace this with a counting semaphore ok, so, before entering our critical section we should try to take a pizza slice, we want to grab a slice of pizza ok, how do I do that? I'm going to call sem_wait() on my counting semaphore afterwards I can give back the slice of pizza yeah, sem_post() so how does that work now? if I have two threads trying to call sem_wait() at any one time I just need to make sure one of them wins so therefore how many slices should I put in the pizza box at the beginning?  just one! yes, so one thread get's a slice of pizza and can continue if I put in zero slices of pizza when I initialized my program what would happen? deadlock, yeah! no one gets to continue if I put in two slices of pizza or more I have a race condition again now I've let two threads continue when in fact I only ever wanted one thread inside my critical section if I'd put in two slices of pizza then two threads would've been able to proceed past that sem_wait() at the same time and that as we say lead to data corruption ok, so I think I have my sem_wait man page search so, when you initialize a semaphore the last thing you're going to pass in is it's initial value, in other words the number of pizza slices inside your counting semaphore questions? so one of the powers of the counting semaphore is that you can call sem_wait() and sem_post from arbitrary threads and we'll see that when we want to make a simple queue or stack work with multi-threaded code now, the queues and stacks that you've made in past classes did things like 'oh look I've ran out of space, I know iI'll just allocate some more memory and I'll make my list or linked list longer' I'll double the number of spaces we can do better, what we can do is say I will stop thread from putting anything else into my data structure I can pause it because when it calls sem_wait() we know that it's going to be put on ice so it's unable to continue, it's unable to put anything else into my data structure until the space so now I can think of my processing in terms of pipes and I don't have to have an infinite amount of memory if part of my computation is generating results faster than the rest of my computational process
so I can say to a data structure given the next item, if the data structure's empty that call can just block and it can block until there's data to be retrieved so these become very powerful primitives in multi-threaded code and by the way you can use semaphores as well to even work with multiple processes, but let's not worry about that today still I want to show you this little example here where I'm going to use sempahores with signals now a quick comment, semaphores don't work in mac os x so if you happen to have an apple machine in front of you please go intern at Apple and fix this don't worry, we'll work at how to get around that in a different lecture, but you can check to see if it works by looking at the return value of sem_init() so remember typical posix calls return -1 if they fail so it's a good idea to find out early that our semaphore failed instead of just carrying on and assuming it wasn't a problem so I want to show you a common way of using semaphores, and that's this let's have a thread that's going to do some clean up for us and the first thing this thread does is call sem_wait() alright, so I've got a little method here called sing song and the clean up is going to do sing 'yo ho ho ho a pirates life for me!' which you can imagine in say your java virtual machine there's a whole lot of clean up you might want to do before it exits and so this is a perfect example of how we can use a semaphore we're going to call sem_wait() which means this thread blocks, which means this this thread cannot continue because there's nothing in the pizza box right now now, I'm going to set up a signal handler so that when I press ctrl-c I call my little handler here's my handler so when I press ctrl-c I call sem_post() hold on a moment, why couldn't you've just printed 'yo ho ho ho a pirates life to me' directly from my signal handler? and the reason is because printf() might actually allocate some memory and the number of functions you can call from the signal handler is actually quite small sem_post happens to be one of the few functions that you're allowed to call from within a signal handler, printf() is not why? because there could be race condition it could be that malloc is being called from somewhere else in our code and the internal data structrues may not be correct, it may not be ready for another malloc call to run at the same time so that's our trick, right, inside the handler we put an extra slice of pizza inside our counting semaphore we increment the count from zero to one and in doing so and a moment later sem_wait() can return at last that thread can eat! at last it can take a slice of pizza alright, so, let's run this so, you can see I'm using gcc. you need to give the option -pthread to say include the pthread support and because I didn't specify an output file it's just compiled to a.out so let's run this nothing happens of course until I try to press ctrl-c in which case it now prints 'yo ho ho ho a pirates life for me!' we caused the signal handler to run which posted the semaphore which let our other thread go
[pause] okay good morning and welcome to a very cozy edition of CS241 it's eleven o'clock according to siebel 1404 so let's get started here's what we're going to do today we're going to look at something called the critical section problem this is a fundamental idea of how we cope with doing two things at the same time or to be precise, how do we stop two things from happening at the same time we played around last lecture with counting gold remember?  and we saw that if we let two threads access that global variable then our count will be wrong and so our messing around reading or writing that piece of data we solve the problem via putting a mutex lock around it and we said okay right but if we do that then only one thread can continue and change that variable and the other one has to wait so what we did is we identified a critical section of our code where only one thread or one process can manipulate that memory at a time so what we're going to do now is step back from thinking about mutexes and locks and think about it in terms of some pseudocode and also think about what happens might you implement say mutex lock and mutex unlock and that is what we're going to do right so here we go it turns out for example that someone forgot to implement mutex lock and unlock and so, here's my idea of how we could actually implement those two functions okay so remember the game here is that if two threads called lock only one of them should win and the other one has to wait it's the you know any one person in the bathroom at a time type of rule here so how's the code work? right so when you call it you pass in a pointer to this mutex object inside that data structure I've got something called lock which can just be an int so if someone else has already entered, in other words, if they have already set the lock then my code does nothing it just goes around and says okay is it unlocked now is it unlocked now is it unlocked now is it unlocked now? so it's going to busy wait, it's going to just keep testing that variable once it's unlocked, my little thread is going to say okay great now I can set the lock that means if any other thread at this point tries to lock it, they are going to have to wait they are going to be inside that busy loop because I still have the lock and of course eventually when my code finishes I can then just immediately set it back to zero I don't need to have any loops here, I know that I'm the only thread that could of set this lock so the code is simple, just unlock the door and walk out right so that's my first attempt at protecting my critical code, my critical section so that's my first implementation of how lock and unlock might work is it any good though? will it work? perhaps you and your neighbor can figure out why this proposed code is actually not sufficient  what race conditions could you see? what would happen if two threads happen to call it at about the same time? so here's what we have to do, you have to look at that code with two parts of your brain and imagine two different threads were running the same code what could happen that would be bad? [pause] okay so what have we discovered? is this implementation any good? what do you think? no, why not? no okay too scary, alright so here's our problem, our lock needs a lock there's a potential race condition here what would happen if two threads called lock at about the same time both of them would see that the door is unlocked yes? both of them would see that the variable is zero. great they say, I don't need to be inside my while loop anymore and they continue at the same time so now they both set the lock equal to one and they both return, they both continue so both of them, both threads are now able to enter the critical section which is precisely what we didn't want we wanted to make sure that only one thread at a time could escape from our lock does that make sense? because this is the easy one, this lecture is designed to blow your mind and to make new connections that didn't exist this stuff is really hard to think about if you have a human brain
so your homework for this week is to go and upgrade please go and get one of those uiuc brains please um because this stuff is really hard, we're looking at one piece of code but thinking about it for what could happen when two different threads happen at the same time and you're thinking about the sad days, your thinking about what could possibly go wrong we're not thinking about oh my code works great, it's no no let's look at this really really critically yes so our problem would be if two threads came along called lock at the same time and they both read a value of zero for the lock value before either of them had a chance to change it to one not very likely but that's not good enough, we're trying to make code that actually works that doesn't make us lose money or corrupt our data structure at the end there can only be one thread that gets through this alright I talk about threads because that's how we program this stuff but if you read the historic literature, it talks about processes that's because we're thinking about this actually in a more abstract sense not about pthreads and c structures but just how do we actually do this so that it works alright so this is broken, the only way that we could have made this code work is if we had somehow done all of this as kind of one operation but we can't do that in c you can't say okay I'm the gorilla, whilst I look at this lock, don't let anyone else look at it or touch it, alright? how do I do that? easy, make a lock, oh wait that's what I'm trying to do right? so that's not going to work for us okay so that failed, what we failed at was mutual exclusion we only want one thread or process if you're talking historically inside our critical section so let's try a different solution, let's try our first real candidate solution we'll have um. we'll agree on the following now before you panic, the code written out here, the pseudocode is the same as the pseudocode on the right hand side the reason we wrote it twice is because I want you to think about two threads or two processes trying to execute this at the same time and see if we can actually kind of prevent bad things from happening so what we'll do is we'll have some flags we'll say look, I'm going to just wait until your flag is lowered and your thread will do the same so if I see that your flag is up, then I know that you are inside the critical section in which case I'm just going to wait once I decide that your flag is down, I'm going to raise my flag, I can do my stuff and then I'll lower my flag now we can say what happens if I have three or four or five or more threads in this, let's not let's just worry about what happens with just two threads or two processes trying to do that this is hard enough with just two alright so does this work, does this suffer from the same problem? or not? okay you decide and see if you can argue it with your neighbor [silence] okay! so, does it work? yes it does great, end of lecture no of course it doesn't work right? so does it work? no! why not? let's hear from someone over here, yes they both could be waiting forever, uhhhhhhh, I think that might be hard, I think we can assume that their flags are initially down alright so how will they get to have both of them up? come on keep going alright so we have a potential problem right? yes that both people or both threads could see each other and say oh look his flag is down great I can continue, at which point we raise our flag and say alright off I go and they do this at exactly the same time, or about the same time so hey i'm going to wait until your flag is lowered and I'm going to wait until your flag is lowered they check each others flags they are both low so they can both proceed they raise their flags to say okay I'm going in but it's too late, they've both gotten past this little loop! so they both go into the critical section so what we have failed on the mutual exclusion principle game again we did not get mutual exclusion we wanted one person inside our critical section at a time thank you very much and we failed so when we're looking at these solutions, we've got to evaluate them a little bit carefully because it can happen more than once you could imagine you're going to wrap this around some data structure update like hey I want to add something to my linked list or add something to my hash and I don't know where I'm going to do it but I do know I'm going to say insert things into my hash or read my hash multiple times right so, let's be sneaky, let's be guided by what we did before and this time we're going to raise our flag first that way hopefully, we can stop this mutual exclusion problem okay what's wrong with this solution, right so again the code here is the same as this code here you could just imagine that this is person A and person B or thread A and thread B what happens now? what could possibly go wrong? again take a moment to argue this with your neighbor and even if you don't agree with them perhaps you can persuade them that you're right [silence]
okay sounds like we got a little situation over here okay what have we got? you put your flag down. no, you put your flag down! it's a Mexican standoff with flags! It's a Mexican standoff with flags! okay... uh so what do we mean by that? what could possibly go wrong? okay right yes exactly, both of them could raise their flag at the same time not very likely I agree, but it could happen right? both of them could raise their flags first before continuing and then they check each others' flags  oh look over there that other thread has their flag raised, i better wait and they both do that both threads or both people now just are stuck forever waiting for the other thread to lower their flag this would be an oops moment right? so clearly this is not going to work for us this would not be a good implementation for mutex lock and unlock we can get stuck what have we got? so this will become deadlocked we can't make any progress right so let's try this one. alright that um this time we're going to have not some flags because they don't seem to be working for us let's have the british solution we'll say no after you, okay? so we're going to say something like look we'll have this shared variable so turned is shared between us so we can take turns and i'm just going to wait until turn is set to my id and then do the critical section stuff and similarly you're going to do the same, you're going to check the shared variable that you share between us so there's not two turn variables there's just one in global memory somewhere and see if it's set to my id and I'm going to wait until it is okay and when it is I can do my critical section stuff and then i'm going to say okay it's your turn right what do you think of that solution is it any good yeah we're just considering this for just two threads right we'll worry about generalizing this to more than two later [pause] okay so could this lead to say data corruption? could we have two threads inside the critical section at the same time no, right it's impossible to continue unless you have the golden chalice  unless the turn variable has been given to you so hurray we have mutual exclusion again it's satisfied! alright but our critical section now is only going to have one thread at a time inside the critical part of the code two threads are not going to try and update our goal value or change the data structure at the same time or try to read it whilst another one is writing it. fantastic! we're done. but what's wrong with our solution? yes? okay it's not going to work if we add more threads to it uh but it is something that will run with just two threads uh if they try and update at the same time, let's have a look, so we'll let the first one go through and then a second one comes through but you're along the right lines, it's like what will happen if this thread actually wants to continue it can't! it has to wait for the first thread to actually do something yes, they become rate locked it's as if you and I have to use the bathroom at exactly the same rate, no it's your turn... oh i have to wait I have to wait to use the bathroom... no one's in it yes? but I still have to wait for you to use it there is something broken with this picture, yes? so what we have is a problem of uh, let's see I think... uhhh I have to look at the definitions, just a moment oh yes, progress there's no progress if no one's inside the critical section, I should be able to enter it so in fact there's three desirable properties that we need here and we've touched on two of them so what we'd like in our solutions is mutual exclusion, that one's pretty obvious yeah? we only want one thread or one process to be able to continue into the critical section the next one is progress so if there, I'll write it in terms of threads, if there are no threads inside the critical section we should be able to enter immediately or with the bathoom analogy, if there's no one in there I should be able to just use it I don't want to have to wait for you to give me a chain of keys each time, right? the resource is not being used, I should be able to use it the last one is something called bounded wait and I'm going to give a non mathematical definition of bounded wait, there's more technical definitions that you might use in later courses that I should be able to get into the thread... the thread can enter the critical section in a finite amount of time
okay so that's a little of loose definition other definitions talk about the number of other waiting processes or number of waiting threads that I don't want a little four year old running between my legs running into the bathroom and getting there before me that's going to be really annoying right? they should stand in line as well. There should be some kind of principle of fairness behind this that it shouldn't be the case that I'm just stuck there waiting for an infinite number of other processes to finish and they always get in front of me, they manage to somehow jump the queue, that's just no fair so we have this idea of bounded wait. yes? why does candidate three not have progress? because suppose you want to update it faster than the other thread wants to enter this critical section so we're stuck there waiting for the turn, waiting for the golden chalice to be given to you now, maybe the other thread may eventually call their code and update the critical section, do something inside the critical section but until they do so, you're just stuck there waiting so you could imagine I've got a thread that's writing into a an associative map  you've got a thread that's reading from it why should your reads have to wait for a write to come in? if no one's modifying the data structure, you should be able to immediately get in there and use it so this is the fact that you might want to say come in here twice as fast as this other thread is going to run, yes? yes, it's not efficient, but worse you don't know when that other thread is going to make that call so imagine you had one thread that it wants to walk through a linkedlist structure and another thread that might be changing that linkedlist structure you don't want to modify it whilst one is walking through the links okay? you want to get in there eventually, you don't mind waiting but it shouldn't be an infinite amount of time right, it's not fair if another thread continually just jumps in front of you and you never get a chance to use the resource for example right, so I've littered this lecture with trying to make concrete examples of why we care about the critical section in terms of accessing data structures but these are the three formal thing that we care about for solving the critical section problem. So if you care about reading the literature about this.. these are the properties in which we judge our success or not of our proposed algorithms so let's take a look at another one here we go so a reminder that we're not going to be executing this code all the time but the threads are going to execute this code more than once so we do other stuff and then repeat sometime in the future so now it's your turn take a look at this code and decide how could it possibly go wrong? This is tricky [silence]
okay let me tell you how hard this example is for giggles, when I wrote this little problem I challenged a faculty member assistant programming senior professor five minutes to find the problem with this and after three minutes neither of us had actually noticed the error yet so I'm pretty sure there's a problem with this but it took us more than 3 minutes to see it I'll give you a hint though, it does not satisfy mutual exclusion the question is how could that happen then? [silence] okay, so, before we talk about this code in specifics, I find that it's absolutely fascinating the fact that we can write something that just has a couple of booleans, just flags, simple flags [something] and a simple switch variable and a little boolean that says your turn or my turn and we've built something that couldn't be much more complicated and it completely fails to be handled by our poor little brain we have a really really hard analyzing this really really simple code for spotting it for synchronization problems and concurrency bugs so, anyways, let's see if we can kind of walk through this and do it carefully let's suppose for example right now that only one thread kept on using the resource, use this critical section here can we have progress? right so if we only have one raise my flag! wooohooo, if your flag is raised, it's not, great! I don't need to wait, I can continue to my critical section and I'm going to set turn to you okay, do I have a turn variable? yes here's my turn, wooo! right and lower my flag okay right a millisecond later, I want to do some more stuff for this critical section so what do I do? raise my flag! is your flag raised? no [something over there] right great so I don't need to wait, I can enter my critical section, I'm going to again set the turn to you and lower my flag so that seems to work, I'm able to enter the critical section if no one else is using it so progress is good right mutual exclusion let's see if we can argue that it works and then we'll argue that it doesn't right so raise my flag and is your flag raised? then if it's not I'm going to continue to the critical section meanwhile another thread comes along. alright so [noise] there's my flag, right. another thread comes along and says oh um I see your flag is raised then I'm going to just wait until it's my turn eventually that other code finishes and passes the golden chalice, this turn, to me! so now I can continue but they are only going to pass the turn variable to me when it finished, so the code works! right? oh what happy little brains we have because we're so happy excited to see that our code works um, no, it doesn't work the way to analyze this is to say okay I've got this turn variable so I actually have to do this analysis twice I have to say suppose the turn variable was set to the first thread before this stuff started or suppose the turn variable was set to the other thread before this mess continued and if you do that, then it is possible to break mutual exclusion here's how then first of all we'll set turn equal to two so there was some prior instance when we'd run through this code and turn ended up being 2
right that this is the solution then let's um, look to see what order things happen okay so I'm going to raise my flag and then I'm going to see if your flag is raised it's not, great! I can go into the critical section then the other thread comes along and says okay raise my flag if your flag raised? yes it is okay wait until it is my turn oh look at that, it is my turn so, enter the critical section three four five six, whoops so, by trying to introduce this turn flag to ensure progress we broke it, we broke mutual exclusion we have a situation where because of the prior value of turn, our code allows one way for mutual exclusion to be broken don't feel too bad about spotting this, there have been peer reviewed published papers in major conferences, in major journals that failed to solve the critical section problem yet claimed they did so in trying to solve this, in trying to come up with algorithms that actually solve this it actually advanced the state of the art in terms of how do we analyze concurrency and how do we analyze programs that do two things at the same time right so this is broken, it failed to satisfy mutual exclusion alright then, here you go, what do you think of candidate 5? see how far you can get in five minutes for this one [silence]
[silence] what's up? which one are you talking about? yes? mhmm. uh why is not your turn? no there's just one variable, ok. correct. okay just to read this code, there's only one turn variable  so when it says turn to win it's still the same turn variable okay so what I asked you to do is actually impossible this is a solution to the critical section problem this was the first published solution by dekker so let's see if we can understand some of the logic behind this as to how it tries to work ok so first of all, before we do anything else, we raise our flag, we are kind of signaling intent okay, I want to be inside the critical section so think about this flag as an intent, I want to go so then we have this while flag is raised right didn't we have this at the beginning of the lecture? yes we did and we saw how we could run into a problem of deadlock where both of them were waiting for the other thread to lower their flag but of course it never happened because thread one was waiting for thread two and thread two was waiting for thread one so what we do is to have a little bit more of a complicated logic which is to have a standoff and one of us will win and we take it in turns to see who wins in this potential deadlock so that's the purpose of this, so if it's your turn to win, then I'm just going to lower my flag and wait while it's your turn in other words, you've won! you've won this competition. I'm going to let you go so at some point though, you're finished and you've set the turn back to me, you'll give me the golden chalice or the trump card if you like what do I do now? well I don't continue immediately.  instead, I play another game with you. i say okay I'm going to raise my flag,  I've got this intent again to go into the critical section. but I'm not going to go straight in  I'm going to first see if your flag is raised so it's a bit like playing trumps except that we're going to take it in turns to see who wins if we do that, then we've solved the critical section problem namely that we have mutual exclusion only one thread or one process at a time can be inside the critical section we've got bounded wait, what do we mean by that? well a rough definition is that I only have to wait for a bounded amount of time a more precise definition is that I only have to wait for one other thread or process to enter the critical section and then its my go and we've got progress so if the other thread or process is not inside the critical section, I get to play immediately, I get to use the critical section, I get to execute that code it took many many years to come up with this solution and it took even more years, several decades before another solution was published, here it is between those times, there were many incorrect solutions published and so here is the last solution I'm going to show you today the original article from peterson  this might look like it was from the 1960s, in fact it was from 1981 that's how long it took to find a simple solution to the critical section problem that's how poor our brains are at how to cope with multiple threads or multiple processes it's incredibly hard to reason about this stuff right, I'm not going to talk about this but I will say the following first of all every systems programmer knows of peterson and dekker in terms of the critical section problem it's the kind of thing that should roll off your tongue in an interview secondly, yes I may choose to add a multiple choice quiz question based on these two solutions for example, does this code... is this code dekker's solution? or is this code a version of peterson's solution thirdly, I may choose to make other code which fails and I'm going to ask you in an exam quiz to work out whether it fails mutual exclusion, progress or bounded wait and with that, that's the end of today's lecture, if you have questions for me please come down and see me! thank you very much
[Om Monk Chant with Transcendental and Tibet Bells] so, what do we got. overhead. right so, here's our requirements that we'd like know that first of all, we only want one process or thread to be inside our critical section at a time what do we call that? mutual exclusion in other words, if you've taken cs241, I don't want to see you taking any other courses yes, your time is mine! said cs241 right, what about this then? if waiting, then another process or thread (if you're talking about threads) can only enter the critical section a finite number of times what do we call that? this is a better definition of bounded wait if you're waiting to use the resource, if you're waiting to be inside the critical section it would be unfair if another thread just kept on jumping in front of you in front of the queue so we want a solution where eventually we get to go in alright and then if no other process is in the critical section then the process or thread can immediately enter the critical section our code should be efficient. it shouldn't have to pause. if there's no one inside the bathroom, I expect to use it straight away alright, so, what's that called? progress! yes. so those are our three desired properties that we're going to evaluate alright. now there's um, one more thing that I think that I should mention is that we're talking about pseudocode right now. but today, if you were to look inside say, mutex lock, and you were to drill down to find out exactly how it worked, you might discover that it uses something called the exchange instruction so many processors today will implement either test&set or the exchange instruction what do you think the exchange instruction does? okay, it exchanges something, yes, very good, but what might it exchange? how about a value inside a register and the contents of memory so it swaps them but here's the critical part: is that it does this atomically. it does this in the guerilla fashion. it walks up and it exchanges your hats actually no, I'll take your cellphone, that's more valuable, right? for the microphone oh yeah and in doing so, no other CPU is allowed to interrupt that process it completes as one logical step. here you go, you can have your phone back so that way, we can actually use it to implement our mutex lock because only one thread will win we can make sure that only one thread gets to put a certain value inside it so, it's an atomic instruction, why is it useful? well, to implement locks! we don't have to worry about officially catered code down here and it works even if I got say more than two threads trying to compete to lock something okay, alright, next thing we're going to talk about is condition variables I'm going to introduce them now, we'll let that simmer in your brain and then the second half of the lecture we'll come back to them so like I said, this is the cool bit condition variables sound like they hold some sort of clever value they don't uh, their name actually is very good at confusing beginners the way to think about condition variables is that you can make your thread meditate what an exciting lecture isn't it? okay, right! so we can put a thread to sleep... and then....it will stay until another thread decides to wake it up. now, you don't need to actually scrumple up a piece of paper and throw it at the other thread the system will do that for you you can just make a call, you can say hey, signal!" and, at some point, you know that the meditating thread will be woken up by the system so it's a communication pattern. it's a way for one thread to wake up another so we can use this and we can use this so that our thread can wait until something is true, but we need to write that, so that's the idea of variable comes in. we are actually going to write a condition. a truth that we want to be true but, until that truth happens, until that test happens, no magic is going to happen. we're just going to write a little loop (a little white loop) until that truth has happened we're just going to put our thread into a meditative state alright, that's the idea they're not very complicated. they're not fantastic and clever, they don't know what the condition is going to be. we're just going to write a little while loop that says ok, while there is no good coffee at bervandes, meditate" it'll be a long time
alright, but at some point, we'll write another thread that says ok, guess what? I've delivered great coffee to bervandes, and you saw it, and you wake up your meditating monk, aka your thread" at this point, the monk wake ups. okay, I better see if there's good coffee at bervandes now alright, now, there's a little gotcha here, which is that sometimes monks wake up by acident this is called a spurious wait in other words, we'd like our monks to meditate forever until we do the little tip symbol, yes? ding! wake up unfortunately, it's not a perfect system. they may wake up by accident. but that's okay, because we will write a little loop to say, okay! before you attempt to purchase any coffee, actually go and see if it's any good" and if it isn't, guess what I'm going to ask you to do. go back to sleep. continue meditating" alright. now, there's a little bit more to this course. for starters, I've suggested that you can signal a waiting monk. you can throw something at them turns out that actually normally you can use wake one monk you can get the largest gong you can buy ebay and bash it like hell wake up all of them because maybe you want to wake up a lot of monks so that's a design decision. we'll see how we can do that in a little bit alright so that's the beginning of condition variables we'll let that simmer into your brain we'll come back to that in the second half because right now, hahaha. I've got some more critical section problems for you to look at I've written four potential solutions to the critical section and remember, what are we trying to do here? well, I've got some code here (my critical section stuff) that's only going to work if I've got one thread or one process at a time inside that code so I want to make sure that if I happen to have two threads or two processes attempting to get there, that one of them will lose one of them will have to wait until the first one has finished and remember, all code runs more than once so you can think of the critical section, for example, as using a data structure or updating a data structure. you don't want these two things to happen at the same time. I'm not quite sure how often this code is going to be called. but we do have our three desired properties. we want mutual exclusion so only one thread or process can enter the critical section at a time, bounded wait, and progress so, I've got some problems here, and this is where your neighbor comes in, because I'm going to ask you to actually evaluate these in terms of those properties and see whether they are good solutions to the critical section problem or not and I'm going to come around and answer any questions you might have [long pause]
[long pause] okay so let's have a look at the first one we have a flag and in this case, our flag represents an intent to go into the critical section because inside this while loop, we actually may lower our flag. we actually may say yeah, well, I give up. it's your turn" so if I see your flag is raised, then if the turn variable is set to you, then I'm just gonna say okay, actually I'll let you go ahead" so I'll lower my flag. I know then, therefore, that the other thread gets to win! they see my flag has gone down so they can go into the critical section but they're not going to raise my flag so before going into the critical section, my flag will always be raised alright, now I go around again so, let's go around again now, if it turns out that I've actually had to wait like I just did, then this time, it's my turn to win. so I'm not going to back down the second time. I am just going to now keep waiting until your flag goes down and because the turn variable is set to me, then I win this round I win this second time so I know that I can continue at some point at some point your flag will go down either because you've finished this other critical section or you've deferred to me so in fact, what we're looking at here is dekker's solution. so this was the first solution to the critical section problem and we're looking at, of course, the version which works for two threads but I hope you can see that the flag represents kind of an intent to be inside the critical section right then! so what about version two? yeah, we're raising a flag and this time, it's a kind of no no no, after you" so now we have a little loop that we keep going around. if your flag is raised or its your turn, I'm just going to wait what do people think about this? candidate solution? no progress? no mutual exclusion? no bounded wait? no progress did someone say? alright so let's have a look. so, if I set the turn to you, and then I'm going to wait if its your turn well that's, that's like walking to the resource and just standing there because no, I want someone else to go in front of me. I'm scared" I should be able to use the resource if its right there and no one else is using it. I want to have that piece of cake. I want to be able to enter the critical section so we've already identified that it fails at least in terms of progress there's no progress here it gets stuck waiting for the other thread to come along and kick the turn variable back to the first thread or first process so, we've found a problem here: no progress alright, um, what about the third one? I'm gonna raise my flag, this time I'm being selfish, hey! it's my turn! this is the toddler version of the critical section solution I see the cake. I want to eat it. it's mine. I saw it first alright so, I'm claiming set turned to me, and now I'm just going to wait while your flag is raised or it's your turn what happens here? so you could imagine, that we do one, two and three, alright, so if there was no other thread, then great! we're going into the critical section alright, now we've cured the problem of no progress here. so let's see if we can make it a bit more interesting. suppose another thread comes along and raises the flag now we have to decide who's going to set the turn variable last ok so, for now, let's try like this we'll set turn to me, and then the other thread says set turn to me so what happens now? the first thread says oh look! your flag is raised! I better wait!" and what does the other thread do? oh look! your flag is raised! I'd better wait!" it's like a four way stop sign in Wisconsin oh! I see you've arrived! I'll wait for you!" that was not a Wisconsin accent, but you get the idea we start talking about cheese perhaps. but we got a problem that now both threads have claimed its their turn but we've reached a problem where they're both looking at each others flags and so we get stuck so we actually have deadlock. we've again showed the problem of we try to fix progress but we failed there is no progress here I'm going to make a little change to this program I'm going to say what would happen if this was an AND?"
and, if we do that, we actually have Peterson's solution so now Peterson's solution says I'm only going to look at your flag if the turn variable is pointing at you" otherwise, I'm just going to be the bully and walk in now, I'm not going to spend twenty minutes to prove that this works because we'd actually have to look carefully at the possible different sequences of how this could work well I'm going to kind of just do a little bit of hand waving which is - I think you can agree that by the time we get to the wait loop, one of them has set the turn variable so the turn variable is either pointing at process 1 or process 2. one of them has finished doing that most recently so, one thread will wait. and the other, will continue. so we've solved the progress problem right, so dekker and peterson are two solutions to this and every systems programmer should be able to kind of recognize how these solutions work sorry, at least be able to recognize these solutions you'll notice what peterson did, what peterson noticed was this. was setting the turn to me before the wait that was his insight to say oh look! if I change the turn variable to me, BEFOREhand, I can actually write a really really simple solution" and like I said, that wasn't actually discovered until 1981 okay, what about the last one? does this work? what about algorithm 4? or solution 4? no progress again! yes, we can have a case where both sides are seeing each others flag being each others flag is raised and so we get stuck alright so, we've worked out two possible solutions. dekker's solution and peterson's solution here. through that minor change here how about enable us to actually implement a mutex lock and unlock? what part of the code would you put inside mutex lock and which part would you put inside unlock? alright. it's actually not that hard, right? let's use dekker's solution. we'll say this is the pseudocode I'm going to put inside the lock and this is the part that we'll put inside unlock and we better write some documentation to say that our code actually only works for two threads and if you want to use this for more than two threads, you better pay me more to think real hard about how to generalize this okay so, not bad for a morning's work! look, it's only 11:25 and we've already figured out some code to write mutex lock and mutex unlock. unfortunately, we come back a moment later and people say, wait, you know what? okay, it failed! what do you say? this is impossible! I learned this in class! this is a correct solution. I even proved that it's correct it doesn't work it does not work on modern hadware here's why the C code that we write even the assembly code that we write, does not always correspond to exactly what happens in the hardware we try to make our hardware run as fast as possible. so, here's some things to abide to first of all, we can have a cache problem that what CPU thinks is in memory is being provided by the cache on the chip, on the CPU so if we've got two distant CPUs, they may not update the memory and notify each other that the value has changed so all this stuff about testing a turn variable and looking your flag, I might actually be looking at stale values that have not yet propogated from one CPU cache to another CPU cache a second problem is that actually our CPU can execute instructions out of order now before you panic and say oh! whats gonna happen to my code?" don't panic too much. actually all the stuff we're going to do with pthread_mutex_lock ensures that the all the instructions up to that point are fully executed and completed so, I'm not going to talk anymore about how this can bite you. other than don't panic because guess what, we've got the exchange instruction that we can use at the lowest level to make sure that we really do have a complete round trip to main memory as opposed to dealing with stale values in the cache okay, right, any other questions about these? when we have an exam, when we have a quiz about this stuff, I will be writing these kinds of problems and asking you to figure out if its a valid solution or not. or if it is a valid solution, whether its dekkers solution or peterson's any other questions? good! we have round two! here we go, condition variables! alright, we're gonna write some code that actually uses a condition variable okay so, along the way I'll write some pseudocode I'll turn into real code and I'll talk about some gotchas so for example, one common gotcha is that we forget to actually initialize this stuff if you forget to initialize it, then yes you still got some memory reserved but it may not be connected to any actual real system resource that does some of the work for you so calling your mutex lock unlock may just silently fail because you never bothered to initialize it correctly so that's just a common gotcha so, if your friend leaves their workstation or their laptop open for a moment, just quietly walk over and delete their initialization code. they'll never know and they'll be stuck for hours alright, so how do I have these things, how do I create these things in my code? guess what? the pthread library gives you one, here it is. I'm gonna have this little variable called cv and you might notice in this code I've got a mutex lock as well it turns out that whenever you need a condition variable, you are going to need a mutex lock as well it's like the little side kick that comes along to the party you can't uninvite them. I'm sorry they just won't come together as a pair you're gonna see a mutex lock and a condition variable together why? because a mutex lock makes our lives much simpler the mutex lock allows us to reason that one thread at a time is doing things inside a critical section
and remember, that makes our life much easier. when we can say, oh look! i've got multiple threads happening somewhere in my program, but in the stuff that's really complicated, when I'm changing data structures or reading data structures which might be changed, I just want one thread accessing this stuff so that's what my lock is for alright, so here's my incredibly complicated data structure, it's called an array, here it is and I've got the count that counts the number of things inside my array and as they are global variables, we know they are going to be initialized to zero okay, so, here's what I can do to my data. I've got something to add something into my array, to push some data in, and I've got a method to delete something! which all it does it just reduce the count and hopefully we'll assume that no one tries to delete more items than there are ok, I'm also going to have a getLast() method so getLast() we could, if we're inside cs225, say, I'll tell you what, I'll just return a bad value if nothing is actually in there already but no, what we're going to do is make getLast() wait we're going to make sure that it doesn't continue until there really is at least one value inside our datastructure alright so, here's the game we're playing there's one thread that's going to be calling push data and delete and it might do it several times. I've got another thread that might call getLast() several time right, so we're going to develop this code slowly but here we go. so, here's the plan. any time we want to deal with condition variables, we're going to write something incredibly incredibly simple. just a busy wait. just a simple while loop that keeps testing something right so, this is the code that I'm scared about. right. I'm going to try and get something inside my array but what would happen, for example, if the count is oops this should be count - 1 here we go what would happen for example if count was zero? it means my array doesn't have anything in it so, I need to say the following look, while count is zero, don't carry on." so while count is zero, just go around and, who cares about burning up my battery on my cellphone. alright. it's easy code to write this is the kind of code you might write if you didn't come to cs241 you know just [something] count is zero, doesn't matter, just keep going around" eventually, at some point, count will change and that's fine of course, that code might execute a billion times and used up several milliamps of current or milliamperes of power and um, but it's the best we can do, right. I'm going to show you how we can do better so how can we fix this code? well first of all, we can see there's a race condition, right, that I don't want these methods to run at the same time so I'm now going to put my locks in alright so, here's what I wanted to do. I'm going to call my pthread and pthread's a lot to write so I'm just going to write p pthread_mutex is a lot to write so I'm just going to write m lock and, pass in the address of my little lock structure and at the end, call unlock and, suddenly our code is easier to read. we don't need to worry about say, two threads calling pushdata at the same time even if the problem says that never happens my code now says because of that lock, only one thread can ever be inside that little piece of code" and similarly, here, if I lock on the same lock I'm conpletely confident that even if you tried to call pushdata and delete at the same time from two different threads, the code would still work one thread would have to wait one thread wins the lock and can continue and change the value of count. the other thread has to wait until the mutex is unlocked and then it can lock the mutex and carry on alright so, the lock call may take a bit of time if someone else if currently in the bathroom, you're going to have to just twiddle your thumbs and wait until that lock has been unlocked we're good, okay, we're fine so far right? this is not complicated so far. this is easy stuff, yes? yes? I know it's a monday and the weekend was great but come on, this is not too bad alright so, now, haha, right, now let's see what we should do over here um, before checking this count, I should make sure that no one else is touching it alright? that no one else might be, say, changing its value halfway through so, um, before doing anything with these shared variables, let's put a lock call in at the beginning. there we go. we see how our code is becoming littered with these lock() and unlock() calls, yes? alright, so we write this code, what happens? if we tried to test it at this point? this is the, what, freddy mercury who wants to live forever code? alright so my. I'm fine if I'm just calling pushdata and delete things can bad though, the moment I call getLast() because, getLast() locked the mutex, so what would happen now, to any other code that calls pushdata and delete? they get stuck! yeah, they get stuck inside their lock call waiting for that lock to get unlocked which as we can see from the code is never going to happen. wahahaha. alright, so we've got a problem we can even imagine as well that this count, if this was zero, then we can get stuck inside this loop, and because we don't unlock it, pushdata will never happen so, here's how we're going to fix our code now we're going to unlock the mutex, meditate, me-di-tate, with our condition variable after we finish meditating, lock the mutex again
so if our count is zero, go into a restful, peaceful state, but you say how can I wake my monk up if its meditating?" okay, when should I wake it up? do I need to wake it up in the delete()? no! because there's no way it could've fallen asleep then. it's going to fall asleep if the count was zero so, when should I wake it up? after I've incremented the count there's no point kicking the monk before that point, yes? because if I do, the monk will wake up, come out, eventually it'll be able to lock the mutex, it'll check the count again and say oh!" so I'm going to write the code like this. I'm going to after here, after we're kind of ready, kick the monk of course, if you're not feeling so violent, you can have one of those little bells. ding! and signal the monk to wake up alright so, we kick the monk! they wake up out of their meditation! they attempt to lock the mutex, but they can't because guess what our other thread has currently got it locked, so they're stuck in the lock call but in a moment's time, we will unlock the mutex. when we do that, the monk on this side is able to lock the mutex and continue. the go around, back to their while loop. hey look at that! count is no longer zero! great! I can continue! quick, get the array! get the last entry of the array! fantastic and return it alright, is my code complete? no, I've forgotten to do one last thing which is at the end, unlock() the mutex notice I put this after reading the array why? because I want my life to be simple. if I'm going to look at the array, if I'm going to look at the count, I want to make sure that I'm the only thread that can do so how do I do that? by owning the lock any other thread that attempts to say push more data in" or "delete stuff" has to wait because they have to get the lock first. yes? you could do the kick after the unlock() almost, but there's actually a subtle race condition that I don't want to talk about today. so for now, just put it inside okay? alright, now, some comments on here. so this is how I want you to think of a condition variable. look, there's always three steps we better unlock stuff, because if we don't then I'm going to be meditating forever the rest of my code can't continue. it can't do its stuff to the array structure, it will never kick the monk because it will never get the lock so we must unlock it then we meditate and then, because we want to check our variables, we better relock the mutex alright? now I have some wonderful news for you all three of these things that we do here, happen inside cond_wait() actually, it's just one call so the most important thing in this lecture is to remember that cond_wait() actually does three things. before meditating, it's going to unlock the mutex that you give it why? so that other things can actually access the data structure and do things and the POSIX call is not called kick the monk" or "ring a little symbol" it's just signal or cond_signal, to be precise and you pass in a pointer to the condition variable so here's what happens. when you call cond_signal, you're saying to the operating system please, at some point in the future, find a monk that's meditating and walk up and do the little symbol. ding!" wake up the monk if you call cond_signal, the operating system's only going to do that to one monk if it can find it. if there's no monk's meditating, it won't bother it is also possible to bash the gong and wake up all monks which are meditating but we don't need to. well, we don't need that today. we know that from the problem specification, there's only going to be one thread inside getLast() later on, we'll see examples which do that
okay, right, so, now, this is where you come in remember how I said, OSX doesn't implement semaphores? well guess what, it's your lucky day! you are at Apple and in the afternoon, they accidentally left you access to the source code so you decided to actually implement sem_wait(), sem_post() ecetera for Apple so we can actually get these things working alright, and we can use condition variables. condition variables are more general, they're more powerful than semaphores because we get to write any condition that we want inside the little while loop so, how would you write these things? okay, how do we implement our semaphores? okay, so what do we need inside our semaphore? well, we need some sort of count to remember when that count gets to zero, then our sem_wait will wait and presumably, we also need some sort of pthread_mutex_lock there we go. and we'll have a pthread_cond variable there we go so with both things inside our semaphore, now we can figure out how to write sem_wait() and sem_post() so, what's the first thing we should do inside sem_wait? we're going to be accessing our count variable so before we do that, we want to make sure that we have sole access. exclusive access to it. alright. so what should we call first? yes! let's lock our mutex alright, so, pthread_mutex_lock, and passed in a pointer to that structure so we'll do s, get the lock um, we'll make these little pointers just for speed today. right, and at the very end, we are gonna unlock stuff as well so, when did we need to actually meditate? when did we actually need to pause? so if the count is zero, then let's send this monk to sleep. let's send this thread to sleep. so now we can call pthread_cond_wait and you'd pass in a pointer to the condition variable and a pointer to the mutex and remember, that does three things for you. it unlocks the mutex, sleeps on the condition variable, and when eventually where it wakes up from that meditation, it's going to relock the mutex before returning so one way to look at this code is that inside this code, at all times, the mutex lock is actually locked in terms of the code that we writing. in terms of say, checking this count. we know that that mutex lock is always locked it's only if it actually goes to sleep inside this cond_wait will the mutex lock become unlocked alright so, we get around there. and the last thing we need to do in our wait call is to reduce the count so, in our count structure, reduce it what would happen if two threads called sem_wait at the same time? doesn't matter. our lock would ensure that only one of them wins. that only one of them executes at a time so maybe the first thread will successfully call sem_wait() and continue. the second thread, though, calling sem_wait() might see the count value zero and then it's forced to meditate alright, what about our post? our post is not going to do any sleeping. it will increment the count okay, oh! look at that! I've touched part of the structure. I better make sure that what? what should I have done first? get the lock! yes. okay, so pthread_mutex_lock() and pass in a pointer to the lock that everyone's playing with there we go so now I know when I get back from this that I've got exclusive access to this data structure because all the code I'm writing always locks the same lock and now, I can call pthread_cond_signal() on the condition variable and finally, unlock the mutex. so this code would work but we can do a little bit better which is that our post is always asking the operating system to find a sleeping monk and ring the bell and, we could do a little bit better reasoning about this, we can say well hold on, the only time that there could be a sleeping monk is if the count is actually already been reduced to zero so if I've just incremented the count, then I'm going to wake up one monk so if the count has just been incremented to one, now I know that I should try to wake up a monk. if there happens to be no monks waiting, doesn't matter. that's okay, that's not my problem but for the other times, if count says greater than one, then there can't have been any monks waiting. there's only going to be monks waiting if we've reduced the count down to one. alright and in here we write the standard code to initialize our mutex lock and our condition variable okay, and with that, we're out of time! I will see you on wednesday and you will have a quiz on friday! more about that on wednesday a reminder that malloc part 1 is due today come down and, it is isn't it? come down and see me if you have any questions! welcome to condition variables
Apparently my head cold managed to confuse me so therefore I confused you and I gave you an incorrect delta to those examples to show you peterson's solution and what I did was incomplete this is peterson's solution it is in the book, the wiki book the wiki book is very new  I only started creating it last semester it is an experiment to say what would happen if I after every lecture I wrote some notes and rather than just put it in a pdf, actually make it a wiki page so the wiki book is yours to edit and to add to eventually we'll actually turn it into a hard copy and I'll charge eight hundred thousand dollars for each one right no I'm not going to give it to Peterson or any of those other vulture companies I'll eventually have a hard copy and basically sell it at a bit over cost but until we do that it is available on the web you too can edit it, you too can improve it and in fact i'll be talking partly about that on Friday there is a conference where we talk about educational technologies and I've got a talk about that and also about the linux in the browser project which you too can play with and it's all in the cs 241 home page and you too can help develop it if you wish so i have several people doing improvements on that project as part of their senior projects for example I also have another group adding subtitles, captions to lecture videos and are looking at crowdsourcing for that so lots of good stuff right so we've talked about that i'll tell you about some more news in a little bit right now let's turn our attention to today's little challenge here the first challenge is relatively easy but it's still nontrivial what we're going to do today is make a barrier so we talked about okay we can create all these threads and one way to program them would be to say create a whole lot of threads which work on a little problem and join on all of those threads and we wait for them to finish that's a perfectly reasonable and simple way to use threads but we can do better now that we know that we've got these primitives that can stop and wait we can make our threads wait for each other  so before going to a part b of an algorithm let's wait for everybody to finish part a so this is basically like before closing the door of an elevator and going down to the next part we want all of our other threads to finish so that's the idea of a barrier we can implement this using semaphores and we can say that we're going to look at using condition variables so remember what is a condition variable? it's nothing particularly special it just allows our threads to go into a meditative state and not use any cpu until we wake it up but it's called a condition variable because we've put this inside the loop that tests for some condition so let's look at our little story here and see what we can do here there we go right so I've set up a typical little problem here that hey I've got a lot of data here it is a big array it's in global memory so that makes life easy and I've got a calculation I want to do on it fortunately I know about threads so I'm going to split my big array up here into chunks and if I've got two hundred and fifty six blocks why don't I split it up into sixteen chunks for my oops I'm just looking down here if my x so this is now x and this is now y, nevermind so my x values are going to be rather than one thread going from zero to two hundred and fifty five I'm going to get each thread to work independently on a segment of this matrix alright so if we have a look at this  this is what we've got here in my main I'm going to fire off N threads okay so we'll define N to be say sixteen wouldn't it be nice to have a sixteen core processor well you too can right now either just spend a lot of money or wait three years and it'll be easy so it'll be cheap so then we'll start say 16 threads I want to ask each one of them to do a chunk of the work one sixteenth of the total amount of work okay so great we've called pthread_create what's the first argument we pass into pthread_create? yes we are actually going to pass in the address of that the address of where we want pthread_create to store the the thread identifier so how do I write that I could say ampersand okay here's my little array and I want the i one that's probably the most readable way of writing that an equivalent would be to say ids + i is that true? so think about that or test it part of it becomes what's the size of this what happens when you add to it I'm not going to write that today I'm going to go with this right so we've got the address of where we want to store that identifier we don't need to set any special parameters for our pthread_create we're going to pass in this calc function that actually does all the work for us and finally we say (void*) i right so what are we doing here we're taking that little integer and we're turning it into a pointer you can that in C, remember it's just a bit pattern being converted into a similar bit pattern but we're saying that the type of it should be treated as a (void *) pointer why do I that, that's because that's the argument type and that will be okay provided we don't actually try to follow that pointer into memory remember it's just a value 0 1 2 3 4 5 6 7 8 9 10 11 12 13 15 okay so at the end of here I'm going to wait for my threads to finish okay so here I'm just going to call pthread_join and this time pass in the value of my little identifiers and I don't actually care about the exit value otherwise I could have passed in a pointer to a void * to grab that and then I would write some code to print out the result which I don't care about so that's the outside of my algorithm, start all these threads, off you go, sixteen people start doing your work I'm going to give each one of you a unique number and then wait for them to all finish by calling pthread_join now the main part of this puzzle starts okay we're going to write our little calc program we know that our pthread functions take a void* and return a void* so I've got some pointer, I don't actually want to use that variable as a pointer though I just want to cast it back into an integer so no memory lookups were used in this casting  it simply says hey I know you treat me as a pointer, I lied I just want to treat it as an integer and I went through those hoops just to make the compiler happy and I'm confident that a void* pointer can hold the integer between zero and fifteen right so that's going to be my starting point my end point exclusive would just be the starting point plus sixteen so now in my little loop x can go form the start almost to the end and my y is going to go through all of the remaining 8192 entries right and then I do my calculation that's going to take a while now you might say really all sixteen threads are going to run at the same time so they are all going to finish at the same time well that's not quite true it could be that one of these threads starts very very late it could be another thread starts completely earlier  it depends on how the operating system decides to schedule these threads it could be that a cpu is temporarily stolen to do some other work like process an interrupt because you pressed something on the keyboard something arrived on the network something arrived from the disk so you're not guaranteed to have the CPU for 100% of the time so we're not quite sure when all of these threads are going to finish so that's where we come in now we're going to try and write some code in here so that we can make sure that we don't continue the second calculation until all sixteen threads have finished so what are you going to do how are we going to solve this? what do we need? I need some ideas we could potentially do this with a semaphore kind of, what other ways could we do this though? okay yes we need some sort of global count variable just keep track of how many threads are currently running we're not going to try and directly query these threads we'll just have some sort of global variable that all the threads can decrement to say oh yeah I finished okay so up here we'll have an int remain and we can set that equal to sixteen or N if we want to so when I actually finish my work, each thread will decrement remain now notice what I just said when each thread finishes, it is going to decrement remain at this point, alarm bells should go off okay very quiet ones inside your head because I've just said that more than one thread is touching a data structure so there's a potential race condition two threads might decide to decrement remain at the same time whoops we don't want that we want each thread to have exclusive access to this remain when it's actually manipulating that so how do we ensure that happens yes bring out your mutex lock maybe it looks like a giant padlock or anyways nevermind so yeah we'll call pthread_mutex_lock on our mutex okay so this takes a pointer to that data structure at this point alarm bells go off and say oh hey did I actually remember to initialize the mutex and the answer is yes yeah you did if you actually managed to write the correct function these are pthread_mutex_init is one way to initialize your mutex lock right so if we do a lock, we know that any other thread that comes in here has to wait it could be then that those other threads that have not yet finished in which case the thread that is running this code  we want it to go to sleep okay well let's suppose I didn't know about condition variables then I might say something like while remain is greater than zero do nothing wohahahahaha we laugh at that code wohaahaha why? because we do know about condition variables, but why else? yeah the first thread that gets in there is just going to spin around and round and round and round it goes the second thread when it finishes will attempt to lock the mutex are you prepared to wait? yes i'm prepared to wait right then the second thread that finishes will get stuck inside pthread_mutex_lock waiting to lock that mutex, but we can see from this code that that mutex lock is never unlocked the second, third, fourth and fifth and the remaining fifteen threads will never get past pthread_mutex_lock because that mutex lock is never unlocked wohahahah alright so how can we start fixing this code well here's what we are going to do rather than just having a busy loop where we continuously burn up CPU time we are going to call pthread_condition_wait and for that you pass in your condition variable and pass in a pointer to your mutex lock and every good systems programmer knows that is when your thread meditates it goes to sleep but before it goes to sleep what happens? what do you get inside here? for free, what's it do for you? hint, we have to pass in the pointer to the mutex why? because it's going to unlock that mutex for you and then go to sleep alright so one of our threads arrived here early and said look remain is still non zero, I'm just going to sit here and chillax" yeah i'm not going to do anything, I'm just going to go into my meditative state the very last thread, the sixteenth thread that comes in says oh look remain is finally zero, I don't need to sleep, I can continue!" so I'll unlock and off we go and the sixteenth thread to arrive will then do the second calculation right so that's not a very good barrier right? what do we do? we wait until the sixteenth sheep finally arrives that was enough weight to tip the balance and the sixteenth sheep could continue and all the others are left there waiting, sleeping, yes? we'd like a way to wake up those meditating threads how do we do that? yes broadcast, we want to not just wake up one sleeping thread with a little bell, ding right, if you call pthread_condition_signal the system will choose one arbitrary sleeping thread and wake it up we don't want to do that, we want to wake up everybody so this is like running over to FARPAR and shouting free ice cream right? everybody comes over actually any free food at FARPAR will work but so how can we do this? well here's what we'll do inside our code, we need to call broadcast now I could do it even before the while loop here I could say okay pthread_condition_broadcast" and here's the way we're going to wake up, anybody who is sleeping on this particular conditional variable now will this work? yes, here's what happens you wake up everybody in FARPAR and they check and discover that actually there is no ice cream so they just go back to sleep okay so that's a silly analogy, but what happens in the code is that we wake up everybody inside the condition wait and see look we wrote it inside a while loop so everybody wakes up, eventually they get to run on the CPU, and when they do they'll say oh look remain is actually still greater than zero" so this code will keep waking up every time a thread gets to this point, it would run it so we could do a bit better than that we actually don't want to always wake people, we actually only want to call this when we know that if remain is now zero, actually bother to wake people up alright so if I'm the last person in the gate, wake everybody up there's no point in waking other people up beforehand because they will simply check and discover that remain is actually still non zero and then just go back to sleep so that would work, it's just not that efficient this is more efficient, don't wake people up until remain is zero so that is a barrier, yes at the back? well the last thread will see the value of zero so you'll never actually go into this while loop yes I could have written it afterwards, it's still a good idea to do the broadcast inside the lock and unlock there's a subtle race condition we can get if we don't right and the other thing to remember is that condition wait actually does three things after being woken up from its deep sleep, before it returns, it waits to acquire the mutex lock again so that means you've woken people up but they won't actually start to execute this code they won't be checking the remain value until someone exits until someone unlocks the mutex so in this case the sixteenth thread will come in, see that remain is now zero, wake everyone up but now they've woken up but can't actually continue on this code yet because we're still holding the mutex lock so eventually we unlock and then another thread in here will say great! finally I've woken up and finally I've managed to lock the mutex thread and I can continue and what's it do? it just unlocks the mutex and continues and so on and so on for the remaining threads so this is really really powerful this is a very very powerful paradigm now because now you can make your threads do a whole lot of work, pause for each other, wait for each other and then continue to do more work, etc now you can write pretty good performant code in a way that you couldn't before okay any other questions? I'll give you a hint, I like to do things like show you code and say on an exam or quiz and say well okay does this actually work? is it efficient or not? or when might it break?" so you could imagine for example if we only did signal here instead of broadcast, we'd only be waking up one thread and the other fourteen of them would still be sleeping aha right so when we come to test this, A will be compiled so let's fix what you said pthread_cond_t there we go and then when we come to test it, it doesn't work what did we forget to do? initialize it, yes! remember with these things, we've actually got two steps you've got to A. make some memory somewhere of enough size and B. actually call init on it so inside here we need to do pthread_cond_init and if we were writing robust code, that's a null as well, we would check the return values of these
right, let's try this you should be able to write this code yourself and understand how it works now we're going to talk about the Reader-Writer problem the Reader-Writer problem crops up in all sort of places maybe in a web server, maybe in a database server and anytime you've got a data structure where you want to read it and update at the same time, you're probably going to run into the Reader-Writer problem so the problem is this I might have multiple threads that want to read from it and multiple threads that want to write to it if I've got a writer that is updating my data structure everybody else needs to wait I can't have two writers trying to change my data structure at the same time it's like two surgeons trying to do the cardiac stuff at the same time. it's not going to work it's going to end badly so we want to make sure that anytime we update data structure everybody else has to wait so if there's multiple writers waiting hey get in line, just one at a time please" however, most of the time we don't actually need to update the data structure most of the time we want to allow our readers to read the data structure we want it to be efficient, in other words more than one reader can read the data structure at a time sounds easy, yes? the reader writer question is a popular question in internship interviews by the way let's have a look at some proposed solutions and see what happens and by the way, another thing you can expect in interviews is hey, what's the producer consumer problem?" or how's it different?" OK, so how is it different? first of all, the reader-writer problem is harder! the producer-consumer is just hey, I want to throw some stuff into this data structure and I want to pull some stuff out of the same data structure and if the data structure is full then you need to wait and if the data structure is empty then you can't pull anything from it and you need to wait and we can implement that with semaphores or conditional variables as well but we'll see that later the reader-writer problem I've got multiple readers running at the same time N readers, that's OK but I only expect one writer at a time anytime I've got a writer everyone else has to stand back, the readers aren't allowed to access the data structure either great, I've defined the problem. let's see if this code works here's some example code, perhaps you and your neighbor can figure out if it's any good or why it's no good [students working, long pause] OK, so let's talk about one kind of common gotcha here is I've been giving you examples where I've made p_threads, mutex locks and conditional variables just as global variables you don't have to do it that way, you could actually put them inside heap memory for example, if we called malloc, we might say now give me the size of a p_thread mutex pointer" is that OK? no! I've just asked for the size of a pointer, that's going to be say 4 bytes on 32-bit system and 8 bytes on a 64-bit system I don't want that. I actually wanted the size of the data structure and unfortunately no one is going to tell you that you got it wrong it's just going to crash at some strange point in the future of the program so watch out for your asterisks  a pointer is not the same as the structure and good that we've initialized these things, presumably we have to make some more memory for the write lock as well how does this work? well anytime a thread wants to read, it first grabs the read lock and does reading stuff and when it's finished it unlocks how does the write work? anytime it wants to write it grabs the write lock, and it grabs the read lock! so it can only get through this stuff, it can only get to actually doing any writing, when it has both of these things so that means that no other writer can be writing at the same time, right? because I've got the lock and if I have the lock you that means you don't have it! You must be stuck inside the write lock so only one of us can actually do the writing this works great, yes? no, of course it doesn't, it's the first version! how is it broken? yes, our first problem is that only one person can read at a time. we wanted multiple readers to be able to use our data structure this is insufficient it fails in terms of allowing multiple readers it does a few good things though. it ensures that if a writer is writing then no one else can do anything so that seems pretty good let's have a go at version two and in this version we are going to have a couple of integers, which if they are on the stack I'd better set equal to zero and we'll keep track of how many people are really writing should read be locking write? it's not necessary the question is should the read method actually call write lock as well?" it's not necessary because the write also grabs the read lock so the writer cannot continue whilst anyone actually has the read lock good question, thanks we'll keep track of this somehow whether reading or writing is actually happening what do you think of candidate two? is this any good? [long pause] so you could be doing reading while writing OK, let's have a look at the logic that inspired this and then we'll see why it's broken so the logic behind this is trying to say, while someone is actually doing some writing, I'm not going to touch this. I'm going to wait so then we can carry on and I'm going to raise my little flag to say we're doing some reading" and then I set reading to false what's the logic that I did behind the writing is to say  while anyone is reading or writing, just do a busy loop. we'll burn up some CPU nevermind that, CPUs are cheap and then when we get past here we'll raise my flag I've got writing to do. I'll do my writing stuff. I've raised the flag so anybody else will be stuck inside their busy loops because I've set the flag to true then the readers will be waiting and any writers will also be waiting inside their while loop the code is fine! what smells a bit? it's not fine! we've got race conditions, just like we saw with the critical section problem with these flags we might be setting the flags a bit late and what would happen if two readers came in? the first reader to finish reading would set the reading flag back down to false it would look like no one is reading you could imagine two writers coming in both writing threads would see that reading and writing are zero or false and so we'll continue. oops! we've got a race condition so we're not doing very well here we're not checking our variables in a careful enough way and we're allowing readers to happen a the same time as writers I could imagine a reader and writer coming in at the same time and they both get past their while loops because neither of the flags are set yet because they are set later so if the two while loops happen at the same time, whoops! we've allowed both a reader and a write access to the data structure so this is no good, but don't worry, we've got a solution for you!
Let's see. I've heard the uiuc students are incredibly bright. Yes, they know how to party, but I've heard that you're really really bright so let's see if you can actually solve this problem yes you're going to need some sort of flags or counters to keep track and rather than set them to one or zero we should add and subtract as people come in and want to read and I'll give you a clue: you're going to need some mutex locks at least one lock and some condition variables we can start with one condition. let's do one condition variable you can add more if you want see if you can get something to kind of work with those alright, let's have a go at grading the solution here I'm not gonna do the complete solution today I'm just trying to do this in stages we've seen two broken ones, I'm now going to try and write something which is a little less broken towards a complete solution we're going to be touching these variables so I'm going to use locks to make sure that when we access the values, it's actually read/written by one process at a time so now in reader, what we'll do is we'll see if we've got any writers trying to do anything then I want to wait but rather than having a busy loop, I'm going to meditate here we go, condition wait and I'll go to sleep so, if I come out of that, I'll check to see if there's any writers and if there are, then I'll go back to sleep again alright, before doing anything, I'm going to increment my little counter here. the number of readers has now gone up by one and then I can actually access the data structures so I'll do my reading here then I'll declare that hey! I finished! hey, there's no more readers" and I can unlock the mutex yes, I can see that we've only going to actually allow one reader at a time, but trust me, for now this is a good stepping stone to a more complete solution what about the writers? well, they need to wait while there's any readers  (so any readers greaters than zero) or any writer greater than zero we want our writer to sleep great, I know a fantastic way to do that. let's call my cond_wait and pass in the pointer to the condition variable and a pointer to the mutex so we can only get out of this little loop once there's no other readers and no other writers before doing the writing, I'm going to increment my write count, then I'll do the writing afterwards, I'll decrement my write count and I'll unlock the mutex I've got my readers and writers sleeping. if they are unable to continue, they'll sleep. we never wake them up. we....probably want to wake them up occasionally, yes? we could try to be clever when we should bash the gong when should we wake everybody up but I'm not going to do that right now I'm just going to put the code in down here that says well look, if I finish writing, maybe there's another writer waiting" so hey, let me bash the gong here so pthread_cond_broadcast wake everybody up! alright, so, anybody that's sleeping, hey! wake up and check your condition, check your invariant, check the loop that you're inside do I need to do the same inside the read call as well? so if there's a writer that is waiting, we should call p_cond_signal. could it be that I've got new readers in here? cuz they might get the signal instead you can say okay! that's fine!" or you might say "actually that's impossible" and never happen. even if it's impossible, they still end up signaling someone, so I could either call signal or broadcast here so that's my next attempt. what do you think of it? it's better than the busy wait we saw a moment ago, but, what? thank you! right now, we've still got the problem of only one thread can actually do the reading because we lock the mutex. okay, we're going to have to fix that. other problems with it? okay, so you're worried about mutual exclusion. actually, the beautiful thing is that our while loop will be checked each time and because we've got locks here, we can reason abotu this much more simply. because we locked this, we know that only one thread at a time can ever be executing inside this critical section, inside this code that we've written hold on, I see what you're saying. but we're only incrementing the reader afterwards yeah, it's easy to see that initially, but remember we're going to wake these writers up but they don't actually check the values of r and w until we unlock the mutex okay so they're ready to go, they're about to run, but they don't get to return from this condition wait until we say so so they can only see a decremented version of the reader right so, we're heading towards a good solution but we've got more work to do one problem you might think about is, what would happen if I had a lot of readers? the poor writer is stuck! it never gets to change the data structure. readers barge in there and our read count never goes to zero so remember this magic saying called bounded wait"? which is about, don't let the small kids just run in front of you? if you've been waiting, there should be a finite number of other processes to allow to continue before you get a fair chance we haven't succeeded in that yet either but anyways, this is towards a good solution so now, I need to change topic because first of all, you have a quiz on friday! woohoo! it's about memory allocation you can expect these kinds of questions! alright, does code data heap and stacks inside your memory? you know how to use pthread, and pthread_exit, and pthread_join and what the differences between pthread_exit and pthread_join you know what free(NULL) does. answer: nothing pthread_create succeeds, what does it return, zero, you get the id by giving it a pointer instead can you use a function that's not thread safe in a multithreaded program? what the answer? yes you can, but you've got to make sure only one thread at a time accesses it gosh, when do you knew about pthread_mutex_lock so yes you can, but you have to be careful pthread join man, okay, so enough about pthread_join boundary tags, oh yes! here's a memory allocator that we did not talk about in lecture but rather than making allocations the size that the user requests, we can have chunks which are 2^n sizes so if I have a pool of a 1024 bytes, we can split that into two allocations of 512, for example or I can split this 512 into two allocations of 256 so if I keep my chunks at sizes 2^n then I can very quickly and efficiently find an allocation of the correct size so, for example, if I wanted 65 byte allocations, I would end up using allocations of 128 bytes and so, if I had 1024 bytes to play with, I could make eight of those allocations so you can see that this kind of allocator, which by the way is called the buddy allocator, suffers strongly from fragmentation I'm going to give you a block of 128 bytes, but you're only going to use 65 bytes of it so it can end up having a great bit of a unnecessary space, but the good news is that it's very very fast to find a free block of sufficient size implicit and explicit free lists? you've seen this now in the MP contest that we can have a separate list of free blocks so it's much much quicker to find a free block rather than scanning through a linked list of all free and allocated blocks, why not have a second linked list which only contains the free entries? so that's an explicit free list and if we do that, we can put it inside the unused space okay so you know about first fit and worst fit and how they work and you know what malloc() and calloc() do if they can't return the request. alright good, I have a moment left good news and bad news. I've got some sad news for you in a sense. monday and wednesday, I'm going to be in california so, robin is going to be taking this lecture slot. and she's going to be talking about some 241 content you're in safe hands. she's taught this course before I'm talking about andriod mook and representing illinois at the coursera partners conference this course, which ran in december 2013, we the largest ever course by illinois at 143,000 people signed up. we've since had 200,000 people sign up
... Good morning! If some of you don't know who  I am, I'm Robin Kravets. I'm a professor in the CS department. I have taught CS241 many times in the past although Lawrence Angrave has taken over and I don't get to torture you guys anymore. So it's not as much fun anymore. But he is out having fun in warm sunny California for the next two classes which means you are stuck with me. For better or worse Anyway, he gave me all the information to teach you guys. I didn't even have to give you the quiz that was done already. So we are going to focus today on some of the synchronization problems that he started on.  And get through hopefully deadlock on Wednesday.  So he left you talking about the reader-writer problems, producer-consumer problems, and one of the things that was assumed was that to make these entities talk to each other that there is some shared space between them. And I don't think there was any restrictions put on how he told you what this space would be. So in the best of all worlds we might just have an infinite buffer where we have somebody put some data in on one side and somebody taking it out on the other side and I could infinitely put in as much data as I want and take out as much data as was put in But in reality we know that infinity is never infinity. We can't implement infinity in a system So what we want to talk about today is understand what kind  of data structures and what kind of resources we can use to implement these shared data applications. So where one application is writing into a buffer and another application is reading from a buffer. ... So if we're dealing with entities where we have a producer and a consumer  And they are putting data into some buffer and the consumer is taking data out of there. What kind of limitations do we have if we're going to implement in this way? What's the first thing? Well at some point once I've filled up the queue I can only take things out as fast as the consumer is consuming them Vice versa I can only consume as fast as they're produced. But this is not an infinite buffer So what happens is the producer puts something in and puts a couple of things in and now the consumer is going to take them out And we put some more things in Now I want to put something else in. What do I do? I've hit the end of my buffer We can rotate around and wrap So let's let the producer now say let's go all the way back there and I can put my next thing in here
you can think of this buffer as something that we call a ring buffer where it's not you've kind of taken the two ends of the buffer that we're using and connected them on the other side so now i need to be able to put things in and take them out and i could just chase my own tail forever and never worry about running off the end so conceptually theres a number of things that i have to have to make this work so if i'm the producer what do i need to know what does the producer need to know the producer is putting things in it needs to be able to hit that so the producer what i filled up my ring ok so lets say im starting from nothing and the producer wants to put something in what's the first thing it needs to know where to put it! okay so let's have a pointer in here that says okay in im going to put it in there i just started some place random if i was smart my underlying data structure might have started right there yeah i wouldve wrapped the two ends okay so now that the producer has put something in what does the producer have to do it can't n isn't write anymore right you have to increment in to now point here that's where my next one would be so that's my producer what did my consumer need to know ill tell you it's out a pointer to what the first one that i want to take out so in this case it's here i'll make the consumer blue and as the consumer puts things in here, it's gonna slowly increment in to be there and as the consumer takes things out it will delete them out of the queue, out of the ring buffer althoguh i guess it really doens't matter and that's the next one to take out so there are two things i have to be careful about whats the first thing that you said before that i have to make sure that i dont what? i want to make sure that i don't overwrite data that hasn't been read yet my writers write, my producer is producing this is a big ring buffer i should've a smaller one okay i'm putting things in do i have to stop yet? no i can stop here but can i keep going? no i have to make sure i dont whoops that's in i have to make sure i dont overflow my buffers and now for the output for the consumer the consumer is going to start taking things out let's say it gets here it can still take that out but now it takes that last one out and now my out is here can it take anything out anymore? no if i allowed, if my program allowed the consumer to take something out at this point i would call that underflow overflow means that the producer produces too much and overwrites good data underflow means that my consumer is trying to take out something that's not there so those are two things we wnat to make sure don't happen we we're implementing a ring buffer so theres no underflow, and there's no overflow now i know you guys have done semaphores and you guys have done condition variables we're going to implement a solution for a ring buffer and of course we have a number of properties that we want to be able to have true for this solution and to start with we dont want any particular busy waiting so we want to make sure that our semaphores and condition variables are set up correctly and we dont have to have any kind of deadlock i know you guys haven't talked specifically about what deadlock means, but at a minimum it's going to mean that someone can't move forward so we want to be able to look at both of these things we want to implement a solution that can do that our first solution im going to give you my basic solution and from there i've been told you guys like to sit down and come up with your own solutions so i'm going to give you a basic first start so certainly whats the first thing that we need in our globals and initilazliation variables what are we trying to manage our buffer! right? so we need a buffer so i'm going to have a  and im gonna say im just going to have a 16 alright and then i need our two variables. what were the two variables i said we needed? in and out so since they are just pointers into my data structure they can just be integers im going to have an integer in and and integer out where should they both start they start at the same place? they start at diferent places? they start at 0? what should we do 0 we're going to initialize both in and out to be 0 so i'm going to give you a basic in queue and i want you to tell me if this works so i'm going to say for my enqueue im goign to put something in im going to put my value in whatever the in value is and increment in and my dequeue is im going to say that i have some result im going to save out my result becasue i want to use it later
uhhh and that's going to equal my data sub out i gotta increment my out too plus plus ++ and then i can return result so there's my solution very basic solution you guys take one or two minutes talk to your neighbors figure out what's wrong with this and how you would fix it are you ready? ok what's the first thing wrong with this? or what's something wrong with this? i'm not checking what? i'm not checking the equality of in and out why do in and out have to be equal? oh i don't want to be equal whats going to happen if i do that? yeah i'm going to try to remove data that's not there if they are equal what else aren't i doing? if not if  so if in equals 16 or more  it's not that i'm overflowing,  what am i doing? i'm overwriting what no what happens if in == 16? so what's going to happen if in == 16? not the answer how big is my buffer? yeah, well 16 0 to 15 if i write data[16] i am going to smash somebody's memory so not good so the solution was to what mod what else could i do? ok so i could mod, wait wait let me write that down i'm going to mod it so what if i do i'm going to change this to say uh data[(in++) % 16]  is that going to work? ok don't worry about the overwriting for a second is this going to help with my wrapping? is this a good solution to fixing my wrapping? there's one minor problem which is not so minor about this it'll work yeah it's going to work for a while and after a while what's going to happen? my integer's going to overflow actually my integer is not going to overflow it's just going to go negative and mod , if i understand correctly, can preserve the negative value so you're now going to get a data sub minus something accessing bad data  or just crashing i don't even know what the system's going to do if you put a negative value in your array so not the  it's the right idea you could actually be must simpler and just say ok that works too when i'm done so don't do this you could also if you really wanted to say n = n mod 16 that'll work too but that's not even that necesasry you only  have to change it if it is 16 and i have to do the same for what?  for out so not going to write that but i have to do the same for out so we've already hit on a bunch of problems that has to do with this. and the problem is all the overwriting and that uh we're not being careful about wha'ts going on and really the challenge here is there's no synchronization  i'm not synchrnoizing my readers and writers reader writer producer consumer enqueue dequeue all of the same idea basically what if i call enqueue twice at the same time is there any safety there?  no what if i call enqeueu and dequeue at the same time is there any safety there? no so let's assume that  we use this code for the actual functionality for the enqueue and dequeue and let's add some synchronization to it so that we can protect the data from overflow from underflow and from the synchronization problem of two nodes trying to put something in the qeueue at the same time and overwriting each other so we have to be careful we have to make sure that  only one node ony one enqueue can write into the ring buffer at the same time i'm teaching networking this semester so if i say node just ignore me
gets in your brain Ok Solution No2 Get that up there Okay!! I'm gonna tell you what we've got here. we've added semphores and locks I have two sempahores, S1 and S2 S1 represents my spaces in my ring buffer and S2 represents the number of items the i've put in my ring buffer if you think about it If i have space, i can put things in it if i have items in my queue i can take things out. so, that's good. I can go initialize them and move on. so now, you guys have done semaphores, right? what happens to a semaphore when you do sem_wait?  What does it do to the value of the sempahore oh did you guys talk about counting semphores? YEAH!!! if you noticed that we initialized one of these to 16 and one of these to 0 these are counting semphores not just mutexes counting semaphores if i initalized it to 16, what can i do i can call sem_wait  how many times? 15  and I can call sem_post  if i'm starting sem_pos 16 times. so what it's doing is it's giving me this ability to call sem_wait, m_queue 16 times or dequeue 16 items in and of itself that's not enough to make sure I don't break my system, but that's gonna be my counters to help me decide how many items i have, and how many spaces i have So my sem_wait on this one is gonna try to decrement  and sem_post, increment sem_wait increment Sorry backwards decrements sem_post increments so take a minute and look at this, and I can tell you this doesn't work maybe you can tell me why. Talk to you neighbors say that one more time Yes So i have initialized it to 0 but my max is 16 s2, i've initialized it to 0 with a max of 0 Let me double check the actual interface of Sem_wait while you're looking at this Sorry, i take that back. Ignore the first zero so, S1 is the semaphore, the zero is just whether or not it's shared across processes S1 is initalized to 16 and S2 to 0 Obviously I should not be writing code to make airplanes fly because they're going to fall out of the sky [something]. What's wrong? Yeah? so we're calling sem_wait and sem_post on the same sempahore my values are gonna change i'm gonna decrement and increment it right away and, how is that gonna implement my, how is that going to affect, write my dequeue yeah? so i'm going to call sem_wait on s1, which initialized to 16, that's good I have 16 spaces I'm gonna put something in. I'm gonno do sem_post and that's gonna increment it, and im gonna be forever be able to put things in
yeah, I've got this really wrong. alright, so my dequeue, is calling S2. what was S2 intialized to ? 0 which is Okay, there's nothing in there but i'm never changing it so I'm never going to put anything in there so i'm waiting forever my dequeue is never getting into anything and my enqueue is gonan run on forever so if we look at our requirements one of the things we asked for is that have we stopped overflow from happening is there overflow in this example? potential for overflow? what was the definition of overflow overwriting good data with something i'm trying to put in do we have overflow here? Yes, because the writer is going around writing writing and writing do you have underflow? Not really Why not? yes because dequeue can never really take out anything so you can really have underflow if you can't take anything out so this didn't work what else did I want to say about this do we have a race condition? is there any race conditions in here? no  why not? we've got our locks. So we can only have one enqueue in there at the same time and our dequeue is never going anywhere so it doesn't really matter actually it's gonna acquire the lock and it's gonna wait, and it's gonna block everybody from doing anything once anyone trying to call enqueue, the whole system is gonna come to a standstill so, we do have a deadlock. it's not a race condition but we've got deadlock and we'll talk more about deadlock on wednesday ok so, lets' move on we still have s1 and s2 still initialized to 16 and 0 so this is still spaces and this is still items what are the problems that you might noticed before from our prior one no matter what the enqueue did, it only affected S1 and no matter what the dequeue did, it only affected S2 so there was no coordination between the Enqueue and the Dequeue so i need to be able to tell the reader the dequeue that there's something to take out so for my next solution, i've mixed it up a bit so now i do a sem_wait on s2 and a sem_post on s1 and a sem_wait on S1 and a sem_post on s2 did that work Okay did i fix my problem? No oh ok, what did i do this time only dequeue could work this time why can't enqueue work S2 is always 0 so i'm starting on calling S2. I try to decrement it, and I've got a problem I did fix one of my other problems though did you notice what I switched? i switched the order of the sem_wait and the lock i' dont actually acquire the semaphore until the semaphore is released and that is very important because if I acquire the lock and I wait for the semaphore to be released but somebody is not gonna released the semaphore unless they've got the lock. i've created a bad problem called deadlock that fixed that a little bit Okay so the problem here was This one starts at zero, right? so whenever I call sem_wait on it it's just gonna block what about this guy Do i have overflow? Do I have undeflow? Why? Here what does S1 start at? it starts at 16 my first call to dequeue is gonna do a sem_wait on S1 and its' gonna say  Oh! Cool, it was 16 now, it's 15 here, so there' nothing really in there" so i've given you some steps on how you would do this, i want you guys to implement your own i can tell you that you can do it with those variables figure out what you want the variables to be initialized to  and how to implement your enqueue and dequeue so it's only a couple of lines of code don't make it too complex Yeah?
but the way you build your code will stop that from happening are you getting close? okay I'm hearing the mumbling die down you guys ready anybody have a solution for me what's the sequence for enqueue okay I'm going to do the same way on s1 why s1 cause I have sixteen spaces and i want to wait if there are no spaces available so what do I initialize s1 to sixteen then what do i do lock what happens if i switch these two the order of those two okay I'm going have I'm breaking my synchronization I'll ask that again when we're done so then I do my enqueue how do I finish up? sorry? what should I do next? sorry? post  and then what?  unlock okay? what happens if uh is that the right order for those two? so he says he thinks the lock should be first why should the lock be first? you can let somebody else come in really you want your lock critical section  lock as tight as possible and then do other things outside that to manage your synchronization because you it's not going to be that bad for this small example but if you don't unlock until you do some other things you're locking somebody else out okay so if you release the lock before the post somebody else could come in and could be waiting right here remember because I got multiple readers can come past the wait up to sixteen if it's empty and then they all wait on the lock because only one is allowed in the critical section at the same time and then they're out once I step out of this the next one can acquire the lock and change something before the post happens so for the small pieces of code it's not really and issue but, for larger things you want to be careful okay so what's my dequeue so it's not a correctness issue it's a performance issue so what do i write for my dequeue wait on s2 what's my additional value of s2 zero because I have nothing in there and then I do what lock and then i do my dequeue then what do i do? unlock same reason and post which one? s1 why does this work? I mean if you talk about this if you look at it right? the first thing is I'm coming in I'm saying are there any spaces if there's spaces I can put something in and now I'm telling the dequeue that I finished putting something in and now there's some items so same thing here I'm checking to see if there's any items and when I done I'm letting the enqueue know that there is more space if it was waiting for space so the key here is that the communication between the two is this crossover between s1 and s2 our initial answer remember had just s1 on one side and s2 on the otherside there was no communication between the two to let them know that there was things changing and then our other answer just had them backwards again if I unlock and then post alright first is somebody could be waiting on that lock the post just means somebody's waiting to know if there's more items the unlock says there's somebody waiting to get into the critical section but let's say there are five items in here right we'll say there's five items and I've called dequeue a bunch of times right so I've called dequeue the first time the first one goes through it says wait and it decrements it to four s2 is items right so it decrements it to 4 and it gets the lock and it could then post or unlock if the first thing it does is unlock the next one that was coming along here the next one came along and it blocked  it can't go anywhere it's not waiting for this post it's just waiting for the unlock so it's really just an ordering thing if there was more complexity to this system this mismatch could cause problems. it's just a performance issue it's not a correctness problem
okay so I only have about five more minutes left I don't think I'm going to be able to  any more questions left about this sorry any more questions about the ring buffer okay the back half of the page is return to the reader-writer problem okay so you guys remember what the reader-writer problem is? so there's a couple of rules when you're doing a reader-writer problem 1. how many readers can you have at the same time? as many as you want how many writers can you have at the same time one can you have readers and writers at the same time? no so our first rule is exclusion one writer multiple readers that also means that whatever solution I design I want to be able to allow multiple readers to simultaneously read but only one writer to write at the same time so was there anything else? yes and we want to make sure that whatever solution we come up with doesn't starve either the readers or the writers so you guys saw condition variables right? so just to refresh your memory inside a condition variable inside the system it's doing an unlock on a mutex it's blocking on a signal so it's waiting for something and then when it's done it locks it and then it returns so whenever you call a condition variable you call it with both that condition variable and a lock what state does that lock have to be in? locked because in the system the first thing that happens is the system unlocks it for you but all that is done atomically-ish don't worry about that word it's all done in one step so you don't have to worry about race conditions inside the condition variable okay so here's my first solution to the reader-writer problem I'm going to lock a mutex and then I'm going to say  I have some variables here I have writing  that means somebody's writing and I have reading and that tells me how many the number of readers inside what value can writing be? zero one  reading can be whatever doesn't matter ok so, first thing I'm going to do is lock my variable and call and while somebody is writing I'm going to call my condition wait if somebody if there's a writer in there I'm going to wait for the writer to signal that they're done and then I can go on once that's done I increment reading I do my reading, I decrement reading, I signal that I'm done and I lock similarly, on the writer side  they lock if there's anybody reading or writing remember writers are exclusive they can't have anybody in there I wait increment writing, decrement writing call the condition variable if anybody, this we're a little bit short for time so is anybody off the top of their head see a problem with this there's only one reader at a time what's causing that? the lock, right, so the lock goes from here to here once I try to read and I acquire the lock nobody else can come in does anybody know how I can fix that? there's an easier way to do that? any other suggestions? well I have to lock but you're closer it does have to do with the lock what if we unlock the lock unlock before the reading and then relock right? because this unlock will let the other readers pass the writers will get here and stop because I've already incremented my reading so the writers aren't going to be able to get into the critical section, but the other readers will there's another problem am I done? give me one more problem here there's two more problem, we'll finish them on wednesday say that again? if there's a stream of readers if readers keep coming and keep coming and there's never no readers we're going to starve our writers one more problem I lied look at the writers for a second there's a problem here what does that do? what does a condition signal do? it wakes up what? no it wakes up  wakes up one reader what do i need to change that to? condition broadcast okay I want you guys to think about the better solution for a reader-writer we'll go over that at the beginning of class on Wednesday and we'll talk about deadlock
Now let's get started. Your stuck with me for one more day and not only that, I have a cold, so I apologize for any sniffling or coughing I might do in your ears. I think we can get through this okay, I'll just make you guys talk more.  We didn't quite finish up talking about the reader-writer problem so I put it on you guys to come up with a better solution But just to go back a little bit, we left off with this improved solution. It wasn't quite as perfect as written on the page. We have the lock and we do while our writing and then we do some reading and then we tell them that there's a reader And then when it's done we do some reader, then when it's done we tell the reader's gone.  And then we signal that someone else can take the turn And then we unlock the lock And then pretty much the same thing on the writer side There were three problems with this Two of them were problematic and one of them was functional - completely functional. What are some simple fixes we can make? What was the first problem? Yeah so what is happening here; who's getting woken up here? Only one reader. Only one reader. So we want to make sure we wake up all the readers so we do a cond_broadcast What are the other problems? What part if it is causing that?  So the lock/unlock being here, right. Okay, I lock, so no one else can get into that critical section until I unlock. Which means we only allow one reader at a time. How do we fix this? Do I have to do the same thing for the writer? Why not? We only want one writer anyway, okay. This works, there's nothing functional wrong with this. This is good, now we get our multiple readers, multiple writers But it still has one more problem. Anyone remember what it is? Yeah? Yes, so the writer--what's stopping the writer from getting in? This right here. We only have one writer, so I don't need to worry about this Okay. And it means that unless the writer has gotten into the critical section, every reader that comes along--once one reader comes along and gets in, the writer gets blocked And now readers come in, readers leave, readers come in, readers leave. If that reader count never goes down to 0 we're going to starve the writer. In the real world this could be a really bad thing because I could be making a change, and delaying that update that the writer is trying to make. And the readers are working on old data. So this is not a good thing to starve our writers. And the goal for the last part of the class was to write a better solution I asked you guys to think about this while you were away from class. I can give you two minutes to think about it and pull it back in again then we can go over the solution Talk to your neighbors. Think about what you would do to fix this and make it work [silence while the class works]
so did anyone come up with a way to not deadlock our writers without telling me the code what would your approach be to not let the writers deadlock? so one way would be to broadcast to the writers first then the readers im not sure that would entirely fix the problem because even if i broadcast the writers wait let's go back to this code for a second even if i broadcast here to the writers the writer will wake up but there's still readers inside and it'll still block so it's a good try  so it's the right approach you have to do somehting that gives preference to the writers that's how we're gonna fix this. say that one more time so one thing you can do is put a number of make sure no one reads forever so the solution i have is not gonna break the problem of someone reading forever if somebody reads forever i'm never gonna let a writer in so ummm  that is a limitation of the solution i'm gonna show you even if you just let even if you say that your reader can be in there for 10 seconds let's do it that way instead of giving it a time limit you can still have every second a reader comes along so probably we should put a limit on the solution i'm gonna show you to make sure that the reader's not gonna stay in forever it would be really good if we could have them enter in the order in which they receive did anybody come up with a solution kinda like that? yeah, that's pretty close to what I'm gonna do so basically what i'm gonna show you is a way to say ok i have a waiting flag if a writers coming in and writer's waiting i'm gonna send a waiting flag and if there's a writer waiting i'm not gonna let anymore readers in and whatever reader are in i'm gonna drop through and those readers once they're done  the writers next and i'll show you how that works you know what i have the code here not gonna write the whole thing down we can look over it ok so here's my reader and my writer so i've added  here i now have two two counters that have to do with readers instead of just 1 this one says that i have a want to enter the critical section. so this one says writer's waiting" and this one says writers writing what value can this one have what value can the writers waiting hve okay what value can this one have the writers writing just one how about this one here no i can have lots of writers writing it just tells me that there are writers waiting okay and as long as there's waiting this one says as long as there's writers waiting instead of writers writing i'm gonna block my reader and this part right here says that as long as there's a writer writing i'm not gonna drop out of my condtion wait while loop okay so what's gonna happen is 1 writer's gonna come along it's going to  say that somebody's reading say we have 1 reader  in there let's let the reader go first reader comes in  i need my variables set here so we have writers  writing and reading and they all start off as 0 so i have a reader that comes along it's gonna come along here and check to see if there's writers it's gonna say no no writers so  uhh it's gonna fall through the condition variable i don't have to wait and then it's gonna increment writing, reading i'm sorry it's gonna stay in reading here for a second let's leave it there for a minute to make sure that the writers are gonna be able to get through so now i have a writer its gonna incrament it's gonna acquire the lock so it can change the writers value ok so now i have one writer waiting but now i need to check somebody's reading am i gonna fall out of this loop? yes or no can i pass this line? alright i'm gonna do while reading or writing am i reading or writing? yes so i do my condition wait so now my first writer is blocked here and what happens when it calls the condition variable? it releases the lock so and now i have another writer come along same thing happens i'm gonna increment my writers to 2 and my second one  is gonna block right there is that clear? yeah? nothing's happened yet right we haven't been signaled yet so now let's go back to this reader so this reader's done it gets the lock it decrements reading now to 0 and it signals everyobdy that will wake up it's doing a signal broadcast it will wake up both of the writers both of the writers will acquire the lock 1 at a time right they're not gonna do it at the same time the first one that acquires the lock will say  is reading 0? yes is writing 0? yes so that one can fall throgh and it can now set writing to 1 and there's somebody writing ok so now if you look at another reader coming along it's gonna say is there are there writers waiting? yes ok now wait what did i just trade off this is not a perfect solution either yeah? there's no better way for the readers so i now put the priority on the writers instead of on the readers there are solutons for having counters and allowing them to go in step by step i don't think lawrence was having you going through the priority solutions so this is the one he wanted me to go through with you
no there's no order right there's no ordering i this because everytime you do a condition broadcast there's no queue it just picks one it's possible that the operating system implemented as a queue and it took the frst one that asked for it but theres no guarantee of that you don't know how the operating sytem implemented a condiion signal why am i unlokcing the mutex when i do a write  there's actually a reason for it what happens when i unlock we said we didn't need it before but actually we do why do we need it? right. so we want anybody who's coming in reader or writer we want them to be sitting on the condition variables here and here the only way for them to get to the condition variable is if the lock is unlocked while theres a writer writing that doesn't mean another writers' going to get in it just means another writer will get to the condition variable that clear? can let it gel. anybody have anymore questions? because i want to move on to the topic we are suppoesd to be talking about today which is deadlock ok so i'm going to do something that i know lawrence never does but i'm going to use some slides dr seuss' birthday was on monday so i thought we would honor him with the ultimate deadlock actually if you take algorithms sometimes people talk about cat in the hat which is recursion dr seuess seemed to have an affinity for algorithms one of the things that we didn't necessarily see this specific problem of deadlock when we looked at the readers and writers problem but we did see in the circular buffer but we did see things getting stuck and the canonical example of deadlock is these are the north going and south going zacks they both walk up to each other and they go I'm not moving. I want your spot" and the other one wats my spot and neither one is willing to make any adjustments and they're stuck this is the canonical deadlock what's happening is i'm waiting for him to move and he's waiting for me to move and with that we create something that is actually very easily to notice that there is deadlock in the system so we see deadlock everyday anybody living you know who's ever lived in a city you've seen deadlock on the streets any time and it could be caused by lots of different things it could be caused by some idiot driving into the middle of the streeet and stopping there and deciding what to do and all the other traffice come along and starts going yeah um we're stuck and it doesn't even have to be you konw an indecisvie problem it could just be that there's lots of traffic and a car pulls into the intersection and can't make it all l the way across and you're going to have the same problem this is what we call gridlock gridlock is deadlock nobody can move everybody is waiting for some other spot that doesn't exist even if the cars that were blocking it in the first place are gone it still can't go anywhere what we're going to see is that the main problem here is that the first car is waiting for the left car to move the left car is waiting for the bottom car to move and the bottom car is waiting for the right car to move and so and so forth and again the same problem that we had with the north going and southgoing with the zacks is that we can't get anywhere so essentially deadlock is a situation where  we have processes if you want to get away from the cars and the dr seuss characters we have processes that are waiting for an event that will never occur and it turns out that this doesn't even have to be multiple processes typically it is multple processes and if they can't make any progress then the system is deadlocked turns out that a single source can deadlock itself it's waiting for some resource how do you think it could deadlock itself? anybody? i have one process and it's moving along it's it's waiting for something if i have a condition variable that i set to something and then in that same thread or same process i then went to go or  unlock even you don't need to be as complex as a condition variable i set a lock to locked and then i'm moving along and then in that same control thread i say unlock i'm stuck if nobody else is going to touch that so i can deadlock myself by not using locks and unlocks correctly so there's also something called livelock can i have a volunteer come up here for a second just a simple. i'm not going to hurt anybody i promise. just stand right here for a second, come on people in the front i'm going to give you an example ok first we're going to be the zacks stand there ok we can't go anywhere ok but now he's going to be really nice and say ok i'm going to move to the side so you can move to the side ok try again one more time ok you can go back to your seat that's called livelock did we  get anywhere? no but we're standing there you ever done that in the hallway where you just go back in forth in front of somebody? that's exaclty what livelock is we were moving we were potentially making progress potentially doing something but we were not making any progress and we never got past where we wanted to be so in terms of processes we're going to see that processes can sometimes try to avoid deadlock  by essentially he was trying to avoid deadlock by saying ok i'm going to be good and say you can have the spot" so they're releasiing a resource but then i say no i want another one so whatever algorthms you design to try to avoid deadlock could create this livelock situation
there's lots of different things you can do to deal with deadlock you can try to prevent it. this is probably the most expensive thing that you can do you have to understand exactly how your system exists. you have to understand all the states in your system you have to be able to look at it, run from algorithms on it and say that nothing in the system, no program, no application can cause deadlock to be able to do that, you have to be very,very pessimistic because even if we're dealing with the zacks aren't very nice, if two of them never met, it's never gonna be a problem. so only if they actually meet that they cause deadlock a number of systems might try to do something like detection and recovery so detected that there was deadlock and now we're gonna come up some algorithms to recover from it avoidance is kinda somewhere in between. we're gonna look at our system and come up with systems that don't come up with dealdock a little bit more expensive than detection not quite as expensive as total prevention and then if you really have trouble you can have your system operator sit there and fix things that's your worst case - you don't want to do that does anybody know what unix/linux does for deadlock prevention or detection or avoidance or whatever anybody know? wanna take a guess? how does linux deal with deadlock? how many people think it does deadlock prevention? detection and recovery? avoidance? manual intervention? you wanna know what it does? nothing this is called the ostrich approach, you stick your head in the sand and ignore deadlock ever happening. that is pretty much what they decide they leave it up to the application writers to make sure they don't deadlock so, the nice thing about this is that none of the expensive components of prevention or recovery or detection need to be implemented they just say everything's faster and if it's rare is it really worth the overhead? the assumption is that it's rare and we're not going to use it or if it's really important for a particular application that that application take care of it that being said you can't ignore it because it's part of this class and i'm gonna talk to you about how to figure out what's going on with deadlock to be able to do so i wanna be able to model  i want be able to model my processes and my resource that they wanna use in a graph and this is called a resource allocation graph and my resource allocation graph has two components it has  it has processes which are these circles  and it has resources which are the squares and what i'm gonna do is i'm going to take an arrow from a resource to a process that means that p1 is using r1 and i'm going to take an arrow from a process to a resource saying that p1 requested r2 so this would be process 1 is using standard out process 1 has acquired a lock the second half, the right half would be some other process acquired a lock already and p2 is asking for it but doesn't get it until the other process has given it up so, why do we go through the bother of this? well it turns out that if we look at resource allocation graphs they have this great property that tell us how to deal with deadlock or how to detect deadlock, or how to detect deadlock let's say we have this situation now where r1 acquires, sorry, p1 acquires r1 so process 1 has acquires some resource and p2 has acquired a different resource but now p2 is gonna request that first resource that p1 has and p1 is gonna request the resource that p2 had what's gonna happen? so, if they're gonna hold on to these resources and they can't make any progress until they get the second resource, we've now created something called circular wait they're both waiting for something the zack's were each waiting for the other to move the cars at the intersection were each waiting for the other to move this is called circular wait and this type of cycle in a resource allocation graph tells us that there's dedlock so, on your handouts from today, you guys have some examples that we're going to go through so let me switch over to our examples can you guys see that okay or do you want me to put it on the center screen too? so, i'll help you through the first one the first one, here's my boxes and lawrence was calling them candyboxes and they hold candy and there's one piece of candy in the box and whoever gets it get's to take it and i guess when they're done they put it back. kinda gross so if you heard him say candyboxes he meant the resource squares and the resource allocation boses now how many processes do i have i have process 1 and process 2 so i'm gonna write p1 and p2 and the way i read this is process 1 requests resource a and resource b so process 1 requests it and there's no arrows coming out of the resource that means that no one's using it right now and p1 can acquire it so i draw an arrow to p1 because that means that p1 has acquired a and b now, process 2 comes along so this is time for each of these, down is time now p1 says i'm gonna request  oh i guess there's a 3rd one here p2 requests process c sorry process 2 requests resource c, which way does the arrow go? to p2 towards p2 and, what about b? which way does the arrow go? towards the resource or towards the process? towards the resource because a already has it is there a deadlock here? no why not? there's no cycle i don't have my circular wait, okay
Let's do the next one You guys do the next one, you've got 30 secs to do it, it's very easy I'm going to write the processes and you're going to tell me where to put the arrows I'll write all of these while you're looking at it, you can go through as many as you want I'm going to set this up Okay so for the next one P1 requests A, B and C Which way do I put my arrows? towards P1 all of them? nobody has those resources and P2 requests B and C which way do I put my arrow? to the box? For which one? for both of them? Yup cause A has both of them Is there a deadlock here? Why not? There's still no cycle Let's do the next one, A requests A and B We know those go that way because A is the first thing to request it P2 requests B and C which way does the B arrow go? To the resource or to the process? To the resource And for C? To the process How about for P3? To the resource or to the process? To the resource and for C and B for P4? Both? So they both go to the resource ok Have I created a deadlock? Is there a deadlock there? Still no deadlock, this is kind of boring, no I'm just joking Ok you wanna make a bet that there's a deadlock here? How many people know that there's a deadlock here? Then help me, so P1 requests A and B P2 requests B C and D which way does the B arrow go? Towards the resource and the other two go... towards the process We know there's something here so this has to go towards the process P4 wants D and P3 wants B But now P1 requests C which way does it go? To the resource and you're going to go back around the bottom here Is there a deadlock here? Whats happening? P1 has requested C and then P2 is using C but P2 has requested B and p1 is using B Got it? So you'll notice this is what is called a bipartite graph You only ever have arrows going from the top to bottom or from the bottom to the top they never go back and forth between each other okay last one and then we'll go back to talking about deadlock ok i'm going to start it off uhhhhhh because I don't know what I'm doing do I? there we go P2 wants B And C and D Okay this is almost the same as the last one P3 requests B ok what's new here? P1 released B P1 said ok I don't need this one anymore, it's not there and once it's been released, the next process waiting for it can get it let's say it's P2 so now P2 what happens to the arrow for P2? It switches direction so let's see if we can make it switch directions. So now when P1 comes along and requests C Is there a deadlock? No So the key here is to remember that as processes are doing things, they are releasing and using resources and the whole stepwise of understanding how they're releasing and using them needs to be looked at to be able to detect deadlock okay any questions about the resource allocation graphs? okay cool. I'm going to go back to my slides
So, it turns out that this, uh, circular wait is not sufficient for, uh, determining whether there's deadlock. It is necessary. If there's no circular wait, there's no deadlock. But if there's circular wait, it doesn't mean there's deadlock I mean, if there's a circle in the graph, it doesn't mean there's deadlock. So there are four conditions. They are Kaufmann's conditions. The first one is mutual exclusion. It means that only one process can use a resource at a time. so a process can claim exclusive control of the resource they require. So if we're only dealing with writers, writers require exclusive access to that critical section. If we're only looking at readers, there's no exclusive access. They can all look at the same time. So we have to have exclusive access. A lock implies exclusive access. only one process can have the lock at the same time There is also something called hold-and-wait. Hold-and-wait says that the prcoess that the process holding the resources allocated to them is waiting for additional resources.  If we go back to our last two examples here,  In this case, the first one, P1 is holding B And waiting for C In this case, P1 gave up B And then was waiting for C, and so in this case doesn't have any hold and wait. it's not holding something and waiting for something else So, in a sense a hold and wait a process has a resource it has an arrow coming in, and it's waiting for another resource so it has an arrow coming out The third thing is that there are no preemptive conditions this means nothing can be taken out. I can't say well I'm going to remove the fact that - instead of A releasing B2, I'm going to force A to release B2. I'm going to preempt it and say someone else can have it Once you have it, it's never given away So the north and south goings  There is no pre-emption. they weren't going to give up anything to be able to make progress And the last one is a circular chain of processes exists.  So, there is actually a law on the books that said in Kansas, when two trains approach each other at a crossing, both shall come to a full stop and neither shall start up again until the other has gone Yeah, not so good Total deadlock. They both can't make any progress. How would you fix this? This is a train, I'm not using a stack. Ok I'm not sure I understand your solution. Ok, so give the north going train the priority and the south always has to give up. The north always goes So that would break it. What does that break? so we had four conditions for deadlock, would do you think that would break? Yeah, there's no pre-emption here, and in doing so you've gotten rid of the cycles too. Any other ways of fixing it? Let's see...did I have any others? Priority, uh... You could make one back up. But all of them have to be able to break one of the conditions. So let's go with one more simple example. Two students need a pen and paper. I want to know what conditions these do or don't satisfy. I need to know if there's deadlock here. Two students share pen and paper. Is there deadlock there? It breaks mutual exclusion. Both students agree to grab pen before paper. Which one does that break? I always grab pen before paper. This is no circular wait. Because I'm always waiting for the pen and then I'm waiting for the paper. If they randomly did it, one could get that paper first and the pen first and the other could get the pen first and then the paper first. then we would have the cycle and they both get one or none Hold and wait Last one, students I have the pen and you give up the paper There's your preemption This leads us to the dining philosophers problem How many people have heard of this problem before? This is the canonical computer science problem. We have N philosophers and N forks BUT you need two forks to eat You can do this with chopsticks too But you only pick up one at a time
They must be hungry or they're dead Okay here's a solution for ya alright  The philosophers spend time thinking, and then get hungry  They pick up the left and right fork and then they eat when they're done they put down the left fork and they put down the right fork  Any guesses about what might happen here? What's wrong with this? Everybody grabs the left fork first, whats gonna happen? They'll starve  This doesn't work Because what's going to happen is oh left fork, left fork, left fork and one more left fork And now when I try to pick up the right fork, there's no right fork there and they can't do anything, they're blocked  Or deadlocked  Which properties does our solution have? Does it have mutual exclusion? It better have all of them - it's deadlocked. What's causing the mutual exclusion?  Can't share forks - which is good for winter time which is good in the winter time because otherwise we'd all get sick  What's hold and wait? I have one fork and waiting for another fork  No preemption - No stabbing the philisopher next to you to steal their fork  Circular wait is this potential of causing a cycle, each waits for the next neighbor to put down their chopstick  So lets just look at this in context of the resource allocation graph  So if the philosophers are the processes That means the forks are the resources and if we model this using our resource allocation graph we can say everyon tries to pick up their left fork  They all get cause there's nobody's using them so there's an arrow from process to the resource and they all get it, those are the request edges and everyone succeeds oh sorry those are requests, now everyone succeeds so everybody's got it from the resource to the process  Now everyone tries to pick up the right fork  There's request edges  And there's our cycle right there, cycle equals deadlock  I had a lot more examples of how to solve deadlock, how to solve the dining philosophers problem, but I think you'll be doing more of that later The only thing he told me to do is introduce the dining philosophers problem and say why it's bad to pick up chopstick 1 and eat. So  any questions about the dining philosophers problem? Any questions about deadlock? What is preemption? So that means you can't take the resource away from somebody  Once the philosopher has the fork you can't force him to give it up  Preemption means you can take it away. No preemption means you can't take it away And actually preemption is a solution to recovering from deadlock Because one way to solve this would be to say okay Aristotle you need to give up your fork and once he does Socrates can pick it up  Sorry Descartes can pick it up and now he eats, puts it down  And the cycle backs around And we've now solved our problem  So you can use these types of graphs to help us solve the problem of deadlock as well as detect  deadlock But the thing to be careful about is it's not easy to determine, in this one it's really easy you can say oh look there's the cycle  I break it and it fixes everything, real systems have more complex cycles and more complex graphs  Ok - It's been a pleasure, thank you And as far as I know unless he gets stuck in california, Lawrence will be back on Friday
programs that we have you'd be paid 15 dollars an hour for your time and make roughly over a thousand dollars upon completion last year we did the same study but we've tweaked it and modified it a fair amount a lot of people really enjoyed this study, they found it was a really great way start exercising, they met a lot of people and being paid 15 dollars an hour to do anything is pretty great so if you're interested, you can visit our website, insight.beckman.illinois.edu chris out there has handed out fliers to a bunch of you so if you want to write down any of the information from your neighbor you can do that as well cause we happened to run out of fliers and you need to be here during the summer in order to participate in this study so I don't really have a lot of time to speak so does anybody have any questions? any? alright, thank you for your time great, so alright so back okay woo cool great here's one of the things I was talking about in orange county and by the way yes I did bring some warm weather back with me, it's coming this week actually next week, we'll have a much warmer weather but anyways this is one of the things I was talking about was how do you run a course where your introduce android programming to absolute beginners and in doing so get the word out that illinois is actually a pretty good place to study computer science and this is what we did, there were fun lectures, there were students in my lectures, some of them not even CS students but I had a singer song writer we went to spurlock and saw bardeen's first transistor and then being an engineer of course, he wanted to make not one but two transistors so that's a music box there right in the middle and that was fantastic right to actually be able to amplify sound using a small device brought the convention down when bardeen first demonstrated this and by the way he actually did a drinking song he played a music note on this and this is during the dry period so that's how he got his propaganda out that the transistor was a good thing and then here's me underneath singing the fifty words of java as a song parody right so we talked about the fact that look programming is hard and had students say things like yeah I built an app and it didn't work I built another app and it didn't work either and this idea that look programming is a lot about problem solving yes you have to have the technical knowledge but it's a lot about being like a detective and looking at a crime scene and trying to figure out why did it not work and then up there in the thinking bubble is another engineering student with his hair going everywhere because he's actually trying to decode at thirty thousand feet as the plane plumets because its simulating zero G it's simulating being out of space, it's on a gravity dice so that was a lot of fun a couple of years ago right so anyways, so that's what I was doing and as you saw from the notes, professor rutenbar and also someone from the provost office was there as well chuck tucker right so let's now head on over to CS241 content but before that has anyone got any quick questions about this? no? okay right so let's do today so I hear you talked about [something] yes? last week with Robin? yeah we're going to continue thinking about deadlock today but I'm also going to give you some hints about the next MP which is to make a fast merge sort, a multithreaded merge sort so first of all let's review a little problem here and see what we can remember about the coffman conditions I've got three gardeners walking into a garden shed to start their work they are after some resources right and so they are going to pick up their tools for the day in other words they are about to request some resources obviously we have a potential for a deadlock, we might have two gardeners try to pick up the same shovel or something okay fortunately we know about coffman conditions alright so how can we assure that we are avoid deadlock I want you to through the mists of time remember yes there are four coffman conditions now here's the challenge, can you actually write down at least one of them or better, can between you and your neighbor actually write all four without looking them up make a list, make a list of four items, see if you can remember what they are what are the conditions for deadlock? if your neighbors not sure, ask another neighbor [silence] right, the best way to learn to remember things is to try to remember things if you want to program your brain to say hey this stuff is important and I want to be able to remember this stuff, the best way to do that is to actually keep remembering it, to actually tell your brain oh yeah yeah i'm actually trying to access this information if you keep doing this, it's going to go into your long term storage yes cramming for tests gives you a short term cram, it puts stuff into your short term memory it's good enough for about 6 hours to 24 hours but it does not go into your long term memory it gets wiped pretty quickly so if you really actually want to learn this stuff then don't just cram for tests but actually exercise your brain it's really the practice, just to start with a piece of paper and say hey what do I know about subject X? write it all down throw that piece of paper away, do it again on a different day you're telling your brain this stuff is important to me I need to access stuff um so, right what have we got? okay first of all let's see give me a hands up if you managed to get at least one okay hands up if you've got two hands up if you've got three hands up if you've got four alright hands up if you haven't... ah nvm, nice let's keep going here's one we should know right? mutual exclusion exclusive access we need non sharable resources in other words, if my gardeners are all friendly and they say oh no no let's all use this shovel together then there won't be any deadlock but instead of course they're like no I'm grabbing this shovel and get your own so first of all we need exclusive access
access so you could say non sharable or exclusive access to a resource okay what else did you remember? hold and wait right so what does hold and wait mean? if I'm going to be involved in deadlock it means I've already got a whole lot of one resource and I'm not going to let go of it whilst I'm requesting an waiting for another resource so I'm part of the problem right? I've got something I've got a pencil and I'm going to wait until I've also got the paper I'm not going to let go of this thing alright so this is the toddler approach to sharing it's mine! I've got one thing now I want the other thing so in note form, I might remember it's like okay I've got at least one thing and I want more! well that sounds pretty similar to something else what's the condition? what's another similar condition to this no preemption what do we mean by no pre emption? yeah, that no one's voluntarily, that the only way that something is released is by a voluntary action so we can't have another gardener bashing the other one on the head just to get their tools right or tripping them up we let each process voluntarily release resources we can't kind of walk in and say oh I'm sorry I've made a management decision, you know that trough you have? I'm taking it away from you so there's a note form, we're only doing voluntary releases only voluntary release resources okay! and finally what's our fourth one? circular wait my friend wants to go out with B, B wants to go out with C, C is waiting to go out with D, D is waiting to go out with A we've got a cycle in the resource allocation graph or in the wait-for graph that we have a set of processes where the first process will wait for the second process, the second process will wait for the third process and so on and so on and so on until we get back to the first process again so we have circular wait okay now are they necessary? are they sufficient? yes they are necessary and sufficient you have all four of these, you have deadlock the good news is that if we can break any one of these then we can avoid deadlock and that is the standard approach to when you are worried about deadlock situations you backtrack, you write down these four things and say okay let's see we can break one of these conditions so I've got my four gardeners or three gardeners walking to a shed I've already mentioned we can break exclusive access by allowing them to share the resources how could we break circular wait? how would you break circular wait? oh really? come on give me an idea, yes okay so if we inside the shed numbered all the tools and said pick the lowest tool first that you need then maybe we can set it up so that there's no circular wait if we controlled all the gardeners actions and were very careful so that there was no possibility that they would fight over shoes, over shoes? tools! we could avoid deadlock again, we could make sure that hey you're only going to do this type of gardening today and you have to wait until this person's finished etc so we might manage the processes so that we never have a circular wait okay, no preemption like I said we could have one gardener that's the head gardener and say haha if I see deadlock, you put down that trough right now, right? we could force processes to give up resources in practice that's pretty hard to do because maybe the process is actually midway through say writing to a GPU buffer so that's pretty hard and then hold and wait maybe we can use something we know about synchronization to try to avoid hold and wait, we could say make grabbing all the resources an atomic situation alright so that's our gardeners  we'll come back to this later when we talk about dining philosophers again now I'm going to get started giving some hints about the next MP remember good ol mergesort? mergesort where you recurse twice and you say okay get the lower half sorted, get the upper half sorted and then I'm going to make a merge function which combined those two halves and then my part is done right so if I've got a big problem what do I end up doing? I end up making lots and lots of recursive calls until I'm working on smaller problems let's say these are 256 entries and I'm going to merge these two together and I'm going to merge these two together right those two merge actions could actually happen simultaneously, concurrently yes? at the same time great sounds like a job for threads so we'll have a thread doing this merge and another thread doing this merge at the same time and eventually say if these were 256 entries each, now we've got one big block of 512 when these are done I can merge those together so knowing what you know about pthread_create suppose I said to you ah okay it's a race we'll have everyone over here try to beat everyone over here to write a parallel multithreaded merge sort code how would you start? what calls would you call and when? so let's say you've got two minutes now to verbally discuss it with your neighbor and plan, sketch out how you're going to implement this you've got two minutes before I let you touch a keyboard, what would you talk about? what's your plan of how to accelerate this using threads ready? go
[silence] okay so let's sketch out some ideas, remember the basic form of when you call merge sort is we pass in some sort of like low and high we calculate a mid point and then the first thing we do is  say okay do merge sort say from low to mid and merge sort from mid to high and then finally, do the merge to take those two halves, copy all the values in order in some sort of scratch space and then copy that back into the main array so maybe what we could do is say well look let's in these two calls here  let's do these independently right? so our first idea might be that instead of calling these directly I will call pthread_create  and obviously I want to know what it's doing and I'll pass in some sort of task information so on the heap I'll make a little struct that says okay go from this value up to this value I'll create a little struct and I'll pass in a pointer to that struct and my little function that runs can take that task, read the contents, and when it's finished it will free it so I'm creating the memory, but the other thread will call it and similarly on this one, we'll call pthread_create and we'll call this task two and then I better wait before doing any merge, I've got to wait for these two threads to finish okay so then I'm going to call pthread_join on t_id one and pthread_join on t_id two so that might be my first attempt so some things to comment on this is first of all, we've got a running thread, why not use it? so what are we doing? we're saying hey create two threads and then just sit around and block until these two other threads have finished well that seems a little bit kind of inefficient we should have actually used the calling thread as well so we might for example try to speed this up a little bit by saying you know what just execute the second task myself directly but even this is going to create a lot of threads way more threads than actual CPU cores that I have and you could imagine that say I'm dealing with several megabytes of data and I'm splitting into these little two hundred and fifty six integers then that's many many threads so maybe we should be a little bit more clever in how we do this and get even better performance and that's where the idea of a thread pool comes in here's what we'll do, we'll make a preset number of threads and then we'll treat them to work, we'll actually separate them from the actual tasks that we want each one to do instead we'll put our tasks into a queue hey guess what, this is starting a bit like producer consumer our threads will go to the queue and say hey what's next what's next give me some work if there's no work for them to currently do that request will block until another thread puts some work into the queue right? so we've actually got conceptually now a whole load of threads going back to the queue saying okay I'm free give me some more work give me a little task structure and that might even have a pointer to a function and some other additional notes and integers etc and pointers to floats, whatever to actually perform the work so we think of our little thread as a little worker that just keeps going back to this and say okay I'm ready to consume the next task, okay? so our second idea then is to do thread pool that uses the ideas we've learned from the producer consumer and its consumer is consuming tasks now we have to be a little bit careful in this because suppose we've just finished creating let's say this block right? our task was to do the merge and to create this block another thing might be to say okay not I've finished this I should put in a new task into the producer I should submit a new job and that is to do this big merge but we have to be careful, we have to make sure that the other half of the data is actually ready is actually finished now, I'm not going to elaborate all of the ways you could do this because we're going to do a little competition and see who can actually write the fastest merge sort but I'll give you one idea and that's this: don't start on all of the five hundred and twelve jobs until you've finished all of the smaller jobs
and note the key word here is finished it might be there's no two hundred and fifty six jobs left inside the queue but that doesn't mean that they're finished there still could be another thread actually working on it, actually generating this data still so you need in your program a concept that no no, these jobs really have finished at this level I've finally got all of those small bits created into larger chunks and so I'm ready to start working on the larger jobs now a little bit of thought will tell you that you could probably even improve upon that idea as well but then it's starts getting a little bit more complicated as to improving the efficiency of this, but this is a good start and I encourage you to do this iteratively and to use subversion so that when you got a working version either copy it or put it aside so that when you blow it up etc, you can at least go back to a best working version alright so that's our thoughts about mergesort and in working on this you're going to learn about thread pools and thinking about producers, consumers, and you'll also think about barriers you're stopping work from happening until something is finished so just like the malloc mp, this again is a rite of passage but it's an asynchronous rite of passage where malloc was about pointers this is about concurrency and parallelism  right so you'll be learning about barriers, thread pools and producer consumers in the next MP questions? no questions are you ready for unofficial? you can see I'm wearing green myself alright so that was a context switch we flip from one subject to another subject except in systems programming a context switch means something a bit more specific than just simply switching the conversation what we're talking about is the idea that our CPU needs to be arrested, needs to stop working on one particular process and it needs to change contexts so it can start work on another process we can have of course many more processes which are active than actual CPUs in our system but a CPU could only work on one thing at a time it's got a whole load of registers and one of those of course it the program counter as to hey what instructions should it work on next? and we've got this idea of virtual memory, that for a particular process, address blah blah blah blah corresponds to this piece of RAM where we've got this particular state in so that's all about one process so when we do a context switch, we've got to stop all this, we've got to suspend the current process and somehow store the active state of the CPU so if you take an operating systems class, you'll discover that this stuff is stored inside the process control block and all this is happening deep inside the operating system, inside the kernel, the very heart of the operating system that manages processes, that manages the actual deep resources of the system for each process so obviously we have to store the program counter and obviously you have to store all the data registers so that when we want to reinvigorate this process and bring it back to life we can preset the CPU and then click the pause button again and start it off and off it goes and the little process never knew that it was put on ice and we reuse the CPU for another process so we store the active state of the CPU right when do you think this happens? every tuesday? come on give me a guess, yes! okay what if I have more processes than I have number of cores and I want to switch my shamrock to a diff yeah yes? what about virtual memory? yes if you want to store things to disk, yeah so it happens when we want to switch one process to another  and that can happen if our first process blocks so for example, let's say you call open or you call read and your waiting for some bytes to arrive from the user typing something or from the bytes that arrive over the network or the bytes to arrive from the disk your process cannot continue let's say that you call pthread_join or you call waitpid() your process cannot execute anymore statements right? it's waiting for an event where's that happening? it's when your process is deep inside an operating system call waiting for an event to arrive now operating systems are not going to return immediately there's nothing more for your process to do right now so that'll be a good time to do a context switch alright your process is no longer able to run so it happened when a process blocks it can also happen, in some operating systems, when a little timer goes off I'm sorry you've had too much time with the ice cream, the ice cream being the CPU I'm going to give it to someone else now so this brings us to scheduling but if we were to look at this further you'd say okay, when a process has exhausted its time quanta so if I'm going to let you have the CPUs for 100 milliseconds and we notice that you've had it now for 100 milliseconds I'm sorry I'm going to give the CPU to someone else so it happened when the process blocks and when the process exhausts its time quantas is two examples for when we might see a context switch when we might give the CPU to a different process so what does it actually mean to give it a different process? okay we've talked about the CPU but of course another critical part of the process is the amazing thing called virtual memory and I want to spend a little bit of time today talking about virtual memory
what we'll do we'll make a very simple piece of virtual memory and we'll let the hardware people actually make it real right? we're going to do it just today, the kind of five minute version and we'll let someone else worry about the actual hardware details here's the game we're going to play memory, real memory of course is expensive we'd love to have more of it but we're always constrained by the cost of memory the only really really great thing about memory is that it doesn't take up too much power we would like to be able to have processes that can actually use more memory than we physically brought we would like to have more than one processes believing that they've got all the memory in the world and that's where virtual memory comes in we're going to say make the addresses that the processes use only indirectly correspond to the actual ram or actual physical memory that we have on the machine so we need to do some sort of lookup anytime your process actually does a read or write we actually at the end of the day need to connect that to some RAM we actually need to connect it to a physical address so here is my physical address and what I'm going to do is divide it up into chunks and these chunks are called pages and I'm going to work with pages which are about 4000 bytes, 4096 bytes so when are we going to use this memory? ah all the time of course right? so if you've got an instruction like a CPU instruction that says okay increment register A just reading the instruction has to be in memory somewhere if you've got an instruction that says load from address 47000 not only do we need the opcodes to be in memory, we need 47000 to correspond to some memory so I'm using my virtual memory addresses all the time not just for the data but for the code as well anytime you write a line of C code, this virtual memory lookup is happening for every single one of those we need to be able to somehow translate our virtual memory address into a place in memory so here's the big trick take your virtual memory address, get a really sharp knife and cut it conceptually into two pieces preheat the oven to two hundred degrees... no forget that bit, right we've got the lowest twelve bits which we are just simply going to ignore for now because what we'll do with those is that we'll just simply use them as an offset in other words, once I've decided which piece of memory, which memory frame or physical frame which page I'm going to use here Of those 4096 bytes, I need to tell you which of those I'm going to use and that's where my 12 lowest bit comes into play because guess what 2^12 is 4096 so I can use those lowest twelve bits as just an offset into any one of these particular things the remaining bits and because I'm working in a little 32 bit system, I now need to map to memory okay so first of all, how many of these 2^20, how many bit combinations is that? how big is 2^20 okay well let's, i'll give you a clue, it's 2^10 times 2^10 how big is 2^10? 2^10 is 1024 so we're talking 1024 squared in other words a million a binary million a megabyte I've got a million entries, a million possible numbers up here we're gonna give these numbers a name we're going to call this the page number and we better give these pieces of memory a name we're gonna call them frame so, I need to convert one to the other right so page frame a miracle occurs we map it to a particular frame here's a really easy way to do it let's just have a table in memory of a million entriese right so we take our twenty bits somewhere in memory in a well defined location we need a table big enough for 2^20 entries and these just hold the frame number so if your looking say at this one then it turns out that you're going to use this particular frame of memory if you're looking at this piece of memory, it turns out that you need this one if you're looking at this piece of memory, it turns out that you need this one if you're looking at this piece of memory, haha, no it turns out that you can't look at that piece of memory if you try to look at that piece of memory, BOOM, we're gonna blow your process up do you remember things like seg faults? this is it! this is at that moment when we try to look at a particular page number and we say ah hah guess what, that's not actually mapped to any real memory ah ah ah, you can't do that! so we can now protect portions of our memory, we don't actually have to map all those addresses so when we say to our process hey pick a memory location, pick any memory location, do you feel lucky punk? alright if our programs are well written then we'll stick on the valid page numbers if their not then our operating system, our kernel will notice that it's trying to read an impossible entry inside here right okay so this is called a page table and we have one of these for each process alright let's see if you're awake  I know it's up silly question it's a friday. um, let's um let's figure out this, what would happen if we could actually write to our own page table? how machiavellian do you feel today? what could you do if you could change your own page table
okay i've got one person here if you've got an idea explain it to your neighbor [silence] okay let me give you a clue  what about some of these other frames that I didn't bother to draw arrows to guess what, somewhere else, there is another process that has its own page table that says okay I've got some memory here please I've got some memory here so if you could change your own page table this is like escaping the matrix right? you've got out now you can arbitrarily read any piece of memory in your system wahahahahahahha in fact arbitrarily change any piece of memory in your system you say, actually, okay, I'm actually going to map this area say to this one in here and that's pretty useful because this is where this other process is storing all the secret passwords etc so you can break the security model of the operating system so each page table actually, each process has its own page table last thing I want to say about this is we can do some really clever tricks now we've got this mechanism here's what I'm going to do you see this entry down here? I'll just shade it in it's essentially a valid entry but right now it doesn't point anywhere why? because I decided that the memory that was being used there actually isn't being used by this process it hasn't touched it for at least 10 seconds and I've got other processes in the system that are starved for memory they would love to have more memory so I'm going to reallocate one of these pieces of RAM and say well actually you can be used by some other process so right now, it's as if all the atoms behind you in the back of siebel are unnecessary you haven't looked at them for ages right? you haven't collapsed their wave function, they are not part of this room at all but if you were to turn your head and actually try to look at that location we'll make it reappear and that's what we can do with virtual memory if at some stage in the future, our process decides to use some addresses down here then oops we run into a problem the kernel at that point is notified and we quickly say oop I tell you what I'll connect this up to somewhere say here I'll put in the right data in here and then we'll let our process go and we'll do that as fast as we can and the process will never know wahahahaha because it tries this memory access, we stopped it at that moment and we only let it continue after we got all of the data ready to go so we can play these tricks all the time and part of a operating system is to figure out the best use of this memory and then update the page tables accordingly last thing I want you think about is that we can set attributes on these page tables like this entry is read only and if we did that, that means we can safely share it with other processes knowing that none of them can change it so for example, we only need to have the C library and other libraries your process might use in actual physical memory once and then everybody else can share the same block of memory because none of them can change it so we can can set attributes on these pages right so that's our simple page table and I hope now you can see it's a mechanism so we can escape from virtual memory into real memory how do we do it? we took a really sharp knife, we took our memory address and we cleaved it into the offset and a page number and then we use a page table  to look up where to go in memory and you might ask where do you put this page table and the answer is in memory but of course we can't actually look [something] so this has to be a physical part of memory somewhere and we can't use the same mechanism to look itself up so how big is my page table in this case? well I said it had 2^20 entries and each one needs to be about 32 bits so it's going to be four megabytes in size why? because there are 2^20 entries and each one was 4 bytes so that we had enough bits to talk about every possible piece of RAM in my system right that's enough about virtual memory today are you ready for page 2? page 2! okay first of all yes it's true there is a quiz on monday okay what can you expect on this? what should we be able to do we should be able to implement a barrier using condition variables, semaphores that kind of thing you should understand the three steps of condition wait the fact that it unlocks the mutex before waiting and then relocks before returning  mutual exclusion, we should be able to make a ring buffer using semaphores or condition variables so what you did in section yesterday would be useful and we should be able to spot basic synchronization errors in semaphores mutexes and in condition variables you now know about the reader writer problem and you can see the notes on github about what we call the writers preference solution where if a writer comes along we delay any new readers which wish to read the writer still needs to wait for existing readers but we put new readers into a pen like new sheep arriving they cannot continue until the reader gets its chance to do the writing and then finally don't forget our dear old dining philosophers and coffman conditions so, let's talk about that the dining philosophers problem is a classic computer science problem, robin introduced it already and uh, don't be surprised if it comes up in interviews what is it? what's it mean? what's it about? it's not about philosophers, it's not a drinking song it's about concurrency, it's about deadlock and it exploring different solutions to deadlock
it's kind of a fun thing to try and implement so we can discuss so called candidate solutions and we can quickly bring out our coffman conditions and say okay does it satisfy all coffman conditions? is deadlock possible? or does it break them in some way? so what if we did this? we'll pick up a left chopstick after we've done that we pick up the right after we've succeeded at that, great we can eat and release is deadlock possible? right well clearly we have exclusive access, we're not sharing the chopsticks yes we can have circular wait, what else? hold and wait yes we've got hold and wait because we are grabbing one resource and we're not letting go until after we picked up the second resource so we have hold and wait as well so what have I missed? mutual exclusion, circular wait, hold and wait and preemption, no one is telling these philosophers to put them down so yes we have deadlock the host is not saying okay put that down alright what if we try to do this the other way? we picked up the right one and picked up the left ahh we can still have deadlock as well same condition applies this time of course we would have if each one is picking up the right then we could... we can see we've got we can form a circle of all the philosophers waiting for the other chopstick, they all manage to pick up the right chopstick at the same time and they never get to pick up the left chopstick because it's being held by another philosopher so they all get stuck holding one chopstick so yes again we have deadlock what about if we had eat what I tell you could we use this to avoid deadlock? yes, if we're in control, if we have a birds eye view of the table we can ensure that there's never ever circular wait we could avoid deadlock so this is okay but now it requires some sort of absolute look at the table and a complete understanding of the state so this is potentially okay provided I understand deadlock, provided my solution above this can avoid... we can avoid deadlock okay what about this one? pick up left chopstick, try to pick up right chopstick, if that doesn't work then release both and restart deadlock? it's not deadlock it's not deadlock because there's no hold and wait, we've fixed... hold and wait but... this is a kind of classic approach to try and solve these kinds of problems that oh we didn't get both resources we'll just back out a bit and retry these kinds of implementations usually suffer from livelock usually what you'll end up with is one poor philosopher that doesn't get to eat as much as the others possibly none at all because it never gets a chance to pick up both it's continuously picking up one chopstick and putting it down, picking it up and putting it down so you're wasting a lot of CPU time attempting to get both but it's in fact very hard to get both so yes you can avoid deadlock but then you have to worry about livelock and with that have a wonderful weekend we'll let you know shortly when the next MP is out  and as always I have time now if you have any questions for me thank you very much, have a fun and safe unofficial
So good morning ladies and gentlemen and welcome to another exciting episode of CS 241 ...the Dining Philosopher's Code Edition! Alright, are you ready for some synchronization? Okay, so, here we go. What we're gonna do today is we're gonna talk about dining philosopher's, we're gonna look at what makes a good dining philosopher's solution, we're gonna look at what makes a bad dining philosopher's solution, even if you find it on the internet, it's probably wrong. We will also ...make a fat wallet, and we'll see about that in a little bit. Also, if you're looking for your exam script because you forgot to put your netid or something else on it, I've got them all in the corner over there, so you're welcome to come down anytime during lecture or after lecture to help find your exam script in that pile. Okay, and, so let's get started. Right, so. Dining philosopher's... Hello! Welcome to lecture, what's dining philosopher's about? Okay, thank you, yes! It's a resource problem! It's about we've got some philosopher's sitting at a table and sometimes they want to be inside a critical section or do something and they gotta try and grab their fork, or, if you prefer, chopstick... Doesn't really matter to the actual conceptual problem, right? We can deal with abstraction here... And our problem is that we might run into deadlock because they want to grab two at the same time, and we've talked about deadlock. What are the four necessary and sufficient conditions for deadlock? Give me one... You don't know. Okay, good answer! Alright, give me another one: Circular wait! Thank you, yes! What is circular wait? Okay, yes, it's from they're spinning around really fast here... no, no, yes, thank you! Yes, correct. It's when we have a set of processes where there's a cycle in the dependency graph, where one has to wait for the next one wait for the next... Okay, give me another one! No preemption! What do you mean by that? Thank you! Yes, correct. Okay, so what do you mean by no preemption? Yes! Correct, okay great! Correct, you can, we're not gonna interrupt a process once it's got a lock Okay, right, it's not like you've heard now. Like, yeah okay Okay Right, so we've done two. Any others? Mutual exclusion! What do you mean by that? Okay, yeah, we're both talking at the same time, yes! Right, so, mutual exclusion: that once a resource has a lock, no one else can use that lock at the same time. Okay, so obviously with our gardener tools example, if the gardeners choose to be nice and actually share tools at the same time, there's no problem! It's only when they say, no, I want exclusive access to this!" Because there we have a possibility. Right, have we forgotten anything? Hold and wait, yes! I need to be holding onto at least one resource, and wanted to get another one, in order to get a circular dependency. If I only had one resource, that's not a problem. It's only when I try to grab two. Right, so, you see dining philosopher's conceptually, this was used as basically as a academic discussion problem for many, many papers because it's simple to describe, it encapsulates a lot of the problems of asynchronous systems, systems trying to do things at the same time. And we can look at different solutions and say why they suck. And analyze what the problem with them is. And do all philosophers get to eat the same amount? Could it be, for example, the last philosopher does eat, there's no possibility for deadlock, but maybe when we actually run an experiment we discover that they're less likely to be able to get both forks. So, there's actually quite a lot of literature about dining philosopher's. And, it would be embarrassing to be a computer scientist and not know about this. And not know about dining philosopher's. Hence, we teach you at UIUC. So let's actually today look at some code, and that's what I've got in front of you right now. Because I don't know about you, but being a recovering physicist, you know, I like to experiment with stuff and play with stuff. Okay, overhead, let's start off with this... Actually build things, and kind of kick them until they don't work. You know, standard kind of experimental physics stuff, right? We like to, just, play with things and see what happens. So, I thought okay, let's build dining philosopher's and then see what happens, and you can download this stuff from the web. And so here's how we might start: Right, I need to conceptualize each philosopher and so I'm going to give them a name, there will be a thread associated with each philosopher, and whether they've failed or not to pick up their two forks, or whether they've managed to lock both mutexes. Okay, so, here's our struct. Why do we do typedef? Because I don't wanna have to write struct philosopher" all the time, so, so, here's how we read this, we say here look, this is the actual type, I'm defining inside here, and here's the alias, Philosopher." Then I have a global flag running"; so at some point, I want to stop my program. And if we spin down to the bottom of this code, here's the plan: right, we're gonna sleep for 40 seconds in our main thread, then we change running" to zero, and if everything has worked okay, then at some point, our philosophers won't have deadlocked, and they will escape their loop and we'll be able to finish. So, then we can call pthread_join" on all of them, and exit. Oops, I'm sorry, exit down here with return 0". If we couldn't join on them, for whatever reason, if they failed somehow, then we'll know about it at this loop here, so we can find out whether our solution is good or not. Okay, let's check that those mutex locks really were initialized... Okay, so, here let's go back and have a look at the top of the code... where is it... Okay, so we've got our nameList", we've got all of our forks, so, we're actually gonna define our forks as automatic variables inside our main method that means we cannot use this static initializer, we better call pthread_mutex_init" here because the mutexes are actually on the stack now. Okay, so now let's pass in the address of each fork there's no special options we need to set today, and oh look how robust this code is: it even checks the return value to see if it failed. Right, so if we get past here, we know for sure that all those mutex locks have been initialized. Now it's time to set up each philosopher. So, each philosopher just has a pointer to a left and right fork. And fortunately, we know about modular arithmetic, so that the very last philosopher, the index 4, will get the 0th fork again because we go 'round, right, so now each philosopher has a left fork and a right fork. And the last thing we can do with a philosopher is stop them! We've got a Philosophunction" called "Phil", which we're gonna run and we give it a pointer to our struct. So, when you work on the MP, you'll be reusing mutex locks as well, so hopefully this lecture is useful to you, and, oh yeah, that's something else we'll talk about in a little bit. Right, so that's our main loop; pretty simple, right? Just initialize everything, sleep 40 seconds, and then, just like any dinner party, you have to clean up at the end. That's not the interesting bit. Here's the interesting bit: page two!
Okay First interesting comment This actually claims to be a solution to the dining philosopher's. If you put dining philosopher's solution, this is one of the pages you find But, let's see if you, today are more intelligent, no more can do more system programming than the interweb Because today we're gonna find out if this code is correct or not Right so let's see how it works Remember, this is gonna be run for each philosopher so the first thing we'll do is we'll take that pointer that was passed and we'll cast it so now we've got a pointer for each thread each thread has its own pointer to that little struct that we've set up, okay? And let's see what we do then... okay, so Our philosopher has two states, right They're either sleeping or eating. Well, that's not quite true because we also have this middle state where we're trying to eat Right but most of the time philosophers get paid to sleep a.k.a. think, right? so Between 1 and 8 seconds, our philosopher's not doing much, just sleeping but occasionally, they wake themselves up with a fantastic thought I am! To be or not to be!" Or something like that. And they say oh, I'm kind of hungry now!" Right, this philosophy is kind of, uh... ha, makes me hungry. Right, so what do we do We get our two forks We announce that we're hungry and then we try to pick up, we try to lock our two mutexes now, here's some cleverness in this code here, here's a function we haven't seen before: we're gonna do something called trylock" what trylock does is it trys to grab the resource, but rather than getting stuck, rather than blocking if that mutex is already locked, it just immediately returns. it immediately comes back to you and says I'm sorry, that resource is actually currently locked". So, you can play again later if you want, but you didn't actually get to lock the resource So either two things happens: either you lock the resource and continue or it returns a non zero value and you continue right, so this code tries to avoid deadlock because you and I know something terrible could happen, right? something terrible... if every philosopher picked up their left fork first at exactly the same time, we've got a problem every philosopher will be holding onto their left fork trying to grab the right fork and they wouldn't because there's another philosopher saying get your grubby mitts off that, that's mine!" Yes, so that's what we're trying to avoid; we use this trylock" to prevent that. So what do I do if it failed? If it failed... We let go of our left fork. Brilliant, right? We got no hold and wait anymore. Alright, so, look at this: No hold and wait... We could actually annotate this code with some stuff that shows that we actually know a bit of computer science, or at least, more than the people at rosetta's Rosetta Code. Okay, so look, no hold and wait. And then we do something funky here: And we go around again. This, unfortunately, ladies and gentlemen, is where I stop talking, and your brain starts working. At this moment in time, I'm gonna ask you with either your imaginary friend or a neighbor of your choice, to figure out if this code is any good. If it is good, why? If it is not good, why? Okay, so I'm gonna give you a few minutes to look at this code and analyze it and be prepared to say something about it.
I have a story once about a  A friend that got 200 applicants for one job, so The programmers, the software developers were saying ha! how do you deal with like this big stack of resumes?" So the boss picked up exactly half the pile, put them in the trash, and said I don't like dealing with unlucky people." (laughter) Alright, so let's have a look at this code: Right, so Here's the plan, right: we know about circular wait, so What we're trying to do is, if we fail, we'll swap our ideas of left and rights and next time around the loop, we won't actually be picking up the fork on the left, we'll actually be picking up the fork on our right. And then we'll try to pick up the other one. And if that fails again, Well, we swap our ideas of left and right again And so we end up picking up on the left first, and then on the right. So, does this code work? If you're in your Google interview, and someone says okay, look at this code! Does it work?" What would you say? Excuse me, I need to run back to CS 241!" Can I make a phone a friend?" Right, what do people think? I'm sorry Okay, it tries to break circular wait By not having a... by saying, okay, I'll pick up the other side first" Alright True, this last kind of probably the thinking behind it this But... Does the code actually run? Will it deadlock ever, or are you confident this code will never deadlock? Remember, our understanding of this is not just about dining philosophers; it's about being able to write multithreaded code in general and spot problems. Yes? Yeah. So you, are you saying there is deadlock or not deadlock? So you're saying there's potential for livelock where one philosopher never gets to eat or two are constantly interchanging? Okay, I'll come back to that, I'll the point in a moment. Yes? Uh huh? Yep. So, when you say pthread_mutex_lock" line at the same time, which lock line are you talking about? This one? Okay. Right. So Let's talk about the live lock" thing, right. So Yes, and I'll come back to that. Right, so let's talk about the first question, right: could there be live-lock here? Alright, live-lock, remember, is when we don't have deadlock, our processes haven't actually just ground to a halt, waiting for an event; no, they're dancing around, trying to make progress, but they never actually make progress. They never actually are able to proceed, they're always saying, okay, can I take it now? Can I take it now?" It's, it's like trying to make a continuous kind of phone calls and you're never actually getting through You're using up your, you're running your CPU program but it doesn't actually achieve what you want it to. So you still suffer from starvation. So, the code tries to prevent live-lock That's kind of the idea behind this tries_left" thing. We don't want a philosopher to starve; if it kind of keeps trying to pick up one fork and it fails to pick up the second one, 'cuz our trylock says I'm sorry, another philosopher has already got it" Eventually, the philosopher gets angry and says I'm not standing for this live-lock business. I don't wanna keep holding onto the left, picking up the right, letting go, picking up, letting go, picking up, letting go, picking..." you know. This is not working out for me, I'm hungry. I really want to get access to my resources, I refuse to be live-locked." So, on the third try, I get a lot more aggressive and I don't do this trylock", right, when my "tries_left" has been decremented to zero, I just say "ah, just grab the right fork." And I'm refusing to play anymore games. I'm just gonna grab that right fork. So, on the third go, We say, no, I will pick up the fork on my left, and I'm gonna wait until I can pick up the fork on the right." So then yes, we could be unlucky, it could so happen that there is a precise moment in time when all five philosophers are holding onto their left fork. And they've all done these games of trying to do trylocks" etc. But on the third time, they all decide ah, I'm just gonna wait until I can grab that other mutex." And if that happens... The system deadlocks. Yes? So. So if they all end up in here If all five philosophers end up in here Then we have a problem. We're gonna have deadlock again, we're back to our original problem. So we haven't solved it; We've just written code that appears to work. Right. Let's see if we can prove this. Right, so, we can see a way that deadlock could happen. Do I have... right... okay, right, so...
Alright so let's run it let's actually see let's actually watch this deadlock here we go alright im just gonna make it a little bit faster im going to  instead of sleeping for so many seconds im gonna do microsleep because we want deadlock to happen right there in a few seconds right so here we go there you go see! it's working. deadlock! what? did I just? make a mistake? We showed that theoreticlally deadlock is possible but it doesnt seem to be happening! Our test is good! We should deploy this to our google servers and run our email system based on this code. So hang on we showed that deadlock is possible, why didn't it happen? Yeah, you have to be really unlucky. Just how unlucky? Right, and it ran for 40 seconds and we've just proved that our code is great. No, we didn't/ We can only prove that the stuff is good or bad by actually reasoning about it so let's see if we can force it to have a deadlock how could we try to force to have deadlock? well we need to make the chances of circular wait to be much greater and right now, uh we, we uh we grab one lock and we grab the other one so let's make it so that we'll grab our left fork, we'll wait for a little bit, and then we'll grab the right fork alright so im between these two locks im going to increase the percentage time that my system is doing hold and wait so im increasing the probability that we're gonna have a circular wait during this time so let me put in a number here like say 10 microseconds right we'll run this still no deadlock! [jibberish] when I played with this earlier, so that's fascinating. right this is a hard demo so then i tried, okay well let's try making it random so i'll do say rand mod 10 and that still didn't work oh okay 20, okay well that didnt work but when i did 60, now we're much more likely to have deadlock so let's, actually no, i managed to get it to work with 30, so okay so here's one possibility is that now by making it long enough there's a chance it might deadlock straight away because all five threads started and all five threads ended up doing those two tries and getting to the point where they all decided to say oh no, forget this. i'm gonna just not use try lock anymore, i'm gonna call lock" right so if we made that time period long enough, there's a chance it might deadlock straight away. but it doesn't always happen, right? so it could be that... okay there we go this managed to break eventually  Okay so, that was kind of a deadlock and what i have shown you is real code for dining philosopher's and also this idea that just simple testing is not enough to prove that your mutex locks and your other stuff is correct we gotta reason about it carefully and and then proving it does work is also kind of difficult. you actually have to show... you have to expand the time where hold and wait and circular wait actually might happen otherwise, a simple like minute test or 40 second test is not enough to prove that your code is correct questions about this? Okay, right. So, a couple of comments first of all, there is no prep for section this week because the MP is out Well, there will be some stuff in the section. um we, We'll probably give you some things to play with with dining philosopher's I'm gonna write section stuff today but there's nothing to prepare for, for section right, now i've gota  challenge for you time for the fat wallet challenge, okay so do I have my wallet with me? Haha, I don't have my wallet with me Can I borrow this? Right, say this is my wallet Alright, umm Actually, I need something here we go right right, this is my wallet, okay, it's got, I don't like it to be empty It's also there's a constraint on the number of items I can actually put in this, okay? So I've got some functions where I can add and remove things from my wallet Here it is And I can define some constants like hey I never want to be less than zero or greater than 100 I wrote about money because we like to think about money but it doesnt have to be money so I want to keep this variable always within those bounds always at least zero and always 100 or less But here's the exciting thing This is hints for the next MP! Right, for the MP that's currently out, if we can reason about this, maybe you can do well on the MP Right,  and here's a challenge then: So, I've written or sketched out how these functions should work If I didn't know about synchronization So, if you try and remove something from this wallet If you want to remove a certain amount First of all, don't do it While I shouldn't quit and if the money minus a certain amount is less than min, do nothing! spin, spin, spin so it's just a busy loop Right, busy loops are bad, they burn up CPU time And our CPU could be spent doing other things instead Well finally, okay, if we dont want to quit, so if quit is still zero, then actually subtract it Okay, add works the same way, if the money is greater than the amount, then spin spin spin spin spin and just wait And finally add it to the amount Right, being seasoned CS 241 students, you can immediately see oh we've got a potential race condition here" right, if i've got two threads calling remove or a thread calling remove and a thread calling add at the same time, then, I've got all sorts of race conditions like this negative equals and plus equals they're not actually atomic operations It could be that you read a stale value of money because another thread is updating it at the same time There's another race condition that  The value I read it in here is protected so another thread could be changing the value before I get to subtract it
self so we've got a lot of work to do we've gotta have first mutex locks in here and we're gonna have to put some condition variables in here so that if we're not yet ready to add or subtract our thread should just block, it should just go to sleep right, so a quick refresher on condition variables how should we use them? well, remember, before calling cond wait,  you must have locked a mutex right, so above it somewhere at the beginning of your code you're going to lock a mutex but the good thing about cond wait is that it will unlock the mutex for you right, so let's pass in our pointer to a condition variable and a pointer to a mutex and when we do that, it unlocks the mutex, the other threads have an opportunity to run, and then it sleeps okay, how we wake up a sleeping a thread inside cond wait? easy, kick the monk right, how do we kick the monk? call cond signal! and that wakes up the monk before that thread can continue, though, it must reacquire the lock on the mutex so, it's ready to go, it's woken up, well now it's stuck inside a lock call so remember this actually does three things: it unlocks locks or sleeps and then relocks before returning. right, so this doesn't actually tell you what happened. so, in practice, what do we need to do? we need to write a little while loop here where we put some condition while something is true, go back to sleep if we want to wake up a whole load of monks, then you use broadcast  on the condition variable right, the last thing to do is before you return, call unlock and the beautiful thing about this is that the code that we actually see in front of our eyes can only be executed by one thread at a time because of this lock that we've booked, i'm sorry, unlocked because of the mutex these mutual exclusion means that only one thread can be doing stuff, can be accessing our variables inside the code that we write alright, so I'm going to stop and then i'm gonna let you go, so we've got the pthread mutex initialized in here and, there's something similar for condition variables as well, so there's pthread cond initializer so it's just a magic constant which says please initialize my my object here, my condition variable or my mutex right and now this is where you come in. it's time to write those three methods using mutex locks and condition variables
Okay so let's convert this code into some actual code that works. Remember that there might be multiple threads actually trying to do this at the same time. There could be multiple threads calling remove, multiple threads calling add, and we only want one of them at a time to actually change the value of our money variable. And we wanna make sure that we don't end up in deadlock and if we say, add enough money into our wallet, then a waiting thread will now move, she could then potentially carry on. So let's think of how we can do this first of all, let's put in some mutual exclusion here so only one thread at a time can actually access these variables right so how do we do that?  well we're gonna need our pthread mutex lock calls and let's pass in... variable and we'll... course we'll need that inside our add method as well and at the end i'll need a pthread mutex unlock if I could spell it, there we go, all right okay And you might say oh hold on a moment, you didn't stop pthread mutex lock correctly." That's okay, with vim I can do regular expressions, where I can say things like  Substitute on all lines p_m for pthread_mutex and do it global on each line so if there is more than one match per line, don't do it so... so there we go. right um, so okay right We haven't done condition variables yet though so the next thing is rather than doing a spin loop,  we wanna go to sleep, and guess what?  Our code we've written here is very close to what we need for condition variables. Rather than just burning up CPU, let's just send our little to sleep. How do I do that? Well, I can... Let's delete this word Delete word delete word delete word, right oops, too much... alright I can say pthread_cond_wait And say okay, wait on the condition variable and here's the mutex I want you to unlock. Okay So you might start by initially  By having, okay, paste that line in again By saying oh I just need one condition variable" But actually, let's do better than that. Let's make all the threads that are trying to subtract go to sleep on one condition variable, and all threads which are trying to add... Go to sleep on another variable. And if we do that, we can make better performant code because we only need to wake up the right kinds of threads when we make a change to our system. Alright, so This one will make sleep on our second one. So if you're trying to add, then go to sleep This other condition variable Right, are we done? No, okay, so one thing we should do is wake everybody up. So if we stop, we should pthread_wait wake a thread up or two, how can I wake up all my threads? So broadcast, and I should wake up at least all the ones on cvs1 and also  do it on cvs2, right Now, how am I doing with time? okay, so So this thread, this broadcast would work in this particular case because its a one-way flag on most processes.  But actually, if we want to be really correct, what we should really do is We should always lock a mutex before doing this Okay Okay, so, just by for convention, if you're going to just as a kind of pattern thing, and for technical reason involving many barriers we're gonna actually just lock our mutex before calling broadcast.
Right, so, we're gonna wake all the monks up But have we finished our code? I'm sorry? Signal? Okay, so if we've just added money to our wallet, it could be that somebody that's trying to subtract could now proceed So let's wake up someone in the subtraction So are you going to do something like pthread_cond_signal on which one, on the other condition variable? Right, so, this will wake up one thread and that happens to be waiting to subtract. Would you do that? So hopefully your answer is no, I wouldn't do that, I wouldn't write that code" Why not? Perhaps you could explain to your neighbor  or to your imaginary friend why you don't wanna wake up one thread Okay, so, let's think about a particular example Let's suppose you've got ten dollars in your wallet Are we doing... I'll change it like this Say we've got 90 dollars in our wallet And one thread wants to add 10, another one wants to add 20 I'm going to make them larger sorry Add 20 or add 30 So they're both blocked right now And then  A moment later, another thread comes in and say, pull out, let's say, 15 bukcs I could see that the adding 20 could now proceed But our code was unlucky, it decided to wake up just one of the other threads, and so it woke up the one trying to add 30. It came out, it managed to lock the mutex, it tested its conditions and said oh i'm sorry, I would still blow the budget, I would still go above 100, and so therefore I'm going back to sleep" What we should have done is woken up all of the threads trying to add, in case any one of them could now continue Right, so the correct code in this And get rid of that... Is to wake up all of the other threads, right, so let's fix our code... let's substitute the word signal" for "broadcast" everywhere in my program There we go Right, and now I think I'm done. Now I think I've got an asynchronous wallet where all threads sleep until they are able to add money, yes! When do I unlock, when? Why do I unlock after broadcast? In this particular example, it doesn't matter... for the stop method... But for the other ones, it does matter. And it comes down to the fact that you can reason about exactly when things happen. And you don't want another thread going into...  Let's say you're an add, you don't wanna know the threads going into the remove method,  and going to sleep just as you are sending the broadcast message. Otherwise you have a very small but potential race condition. If you have the lock, then you know that it can't actually go to sleep while still sending the broadcast message. And it's a tiny, tiny, tiny race conditon but it's easy to fix by always having this mutex lock. So, with that, welcome to the world of synchronization. Thank you very much, hope you got a lot out of this lecture; for those of you that want to find your tests, please come down here and have a great section and have fun with the MP! Thank you very much.
I didn't get the memo that half the class would be in EOH i guess so for those of who are here, welcome, and congratulations for making it, also sent to myself right , so here's what we're gonna do today. we're gonna talk about virtual memory and uh, we're gonna look at how it is implemented in 32 bit systems and 64 bit systems, okay? so, we're fortunately not gonna need to design any hardware but we are gonna understand enough of how it works so that we can see some the advantages that it gives us and also see some of the considerations that you need when you scale from 32 bits to 64 bits right, so, just a, first of all, an important point is that uh let's see, if i got, if I've got 32 bit addressing if i got a 32 bit address to talk about then in 8 bit bytes then i need to oversee 4 bytes to store that pointer, yeah? and, if i got a 64 bit address, then just double that i need 8 bytes to represent a pointer or to represent an address so that's gonna come up again when we talk about storage relief because remember, for each of these entries, it depends on on whether we're talking about 32 bit system or 64 bit system okay, so, yeah, we're used to seeing this with pointers but w'ere gonna see this again in terms of our storage of addresses right, so, here's our first question so what's a page table? what's a page table!? who remembers? yes! thank you! yes, it's a way to translate a virtual address to a physical address you can imagine that if we didn't have page tables, well then we can have a HUGE associate map for EVERY possible virtual address and map it to an arbitrary physical address okay, how much space do we need for that map? well we'll need one entry for every possible physical address and each entry will take 4 or 8 bytes hold a moment, we have just invented a scheme that actually takes more memory than i actually have so we do better than that by dividing our memory up into pages  and we do this arbitrary mapping for not every possible byte but we have a map for every possible page not on memory  right so here's the basic idea, we got some virtual memory address and, we're trying to turn that into a physical address so on a 32 bit system we'll take a virtual memory address and conceptually split it into two parts these bits here are called the what? paging? paging? page number! and what about these lowest bits? yes, they're the offset so if we're writing this in C code we can probably come up with a way to extract the page number from an address okay so if i say i got some pointer and i shift it right by 12. what have i got? the page number! yes and what about the offset could you write an expression for the offset i only care about the lowest twelve bits i could AND it with something yes so i can mask it how do i get the lowest twelve bits okay, for this ill give you a couple of clues everyone knows that two to the eight is 256 and of course we also know that two to the ten is a 1024 so two the twelve is four times that also known as 40996 yes! so... i could write what 4095, is that correct? okay. in other words, the bit pathing 1 2 3 4 5 6 7 8 9 10 11 12 in binary so that means when i AND it with this number, all of my upper bits will be disappeared, masked to zero so this give me the offset i could have written an expression here, i could have said something like: take one and shift it left eleven more times, the subtract one as well so we got ourselves a page number and offset now just like any good cooking show, this is where we take what we've made and we set it aside for later okay, we'll be pouring the offset back in at the very end we don't care about the offset until the very very end what we're gonna try to do now is convert this page number which goes from zero up to 2^20. how big is 2^20? okay, how do we work that out? well, I just told you that 2^10 is about a 1000, so 2^20 is bout a million! binary million so what a bout a million possible numbers to look up so we're gonna take these page numbers and stick them into just a big table and inside this table, i need to know where to go inside my RAM and in fact I'm gonna convert from this virtual numbers to these physical numbers they're called physical frame most of the time we'll never talk bout frames because most of the time we don't actually care about real memory most of the time, our programs that we write live in this virtual address space but today because we're actually gonna figure out how to convert virtual memory to real memory, yeah we need to talk about them so these are our physical frames so we just have a big lookup table ok how might that work, easy, let's just have a big array and that can give us the frame number
Okay, so if we got the frame number how do i now combine that with the offset to find the actual piece of RAM, the actual RAM location could you write down an expression that takes the frame number and somehow combines it with the offset to give you the actual address in memory that you should use you're not simply gonna add them together alright, i'm hearing some good things down here, but... lets see what do we got up here any ideas somebody shout out something even if it's wrong, it's okay! alright what do we got... gimme an idea Adam! Okay. thanks for playing... guess again! right. Our problem is that our page number just goes up in ones. err Sorry our frame number goes up in ones zero one two three four five. we dont want that we want our addresses as you can see. they go up by 4096 bytes so we need to multiply that by 4096 bytes. Yes you got the correct answer thank you [something] right, so, I heard you talking about it earlier right so, we wanted to take this and somehow multiply by 4096 so i could write that that the physical address is gonna be then the frame number, Fnum multiplied by 4096 plus the offset but i dont want in hardware to multiply by 4096. do you realize how much silicon that would take??? NO i dont want to do multiplication. What would be a better thing that multiplication  Yes! Just a step to the right if you haven't seen the rocky horror picture show, I encourage you to do so. Right so we want to step to the left we're going to shift left...right? and we need to go up by how many? is it twelve? yeah we need to multiply by 2 to the twelve. so we'll shift it left by 12 how do you shift left by 12 in hardware? easy you just move the wires off by 1. you just move the wires up so by shifting in hardware is trivial, you just relabel what the electrical wires actually mean okay so got ourselves a physical address. fantastic! easy! that's our page table! so life back in 32 bit world is easy, we calculated how many, how big, our table was. it doesnt seem to big, we just have a million entries. so, uh okay, so now we can work out this kind of typical exam question. right, 32 bit system. in other words, on a 32 bit system, each entry is gonna be 4 bytes.  if each page table is 4 kilobytes. okay so that tells me that the offset then is gonna be, two to the, this is the size of the page table it's two to the twelth so this means that that my offset is gonna be 12 bits so that means Ive got 32-12 bits remaining so number of entries is 2 to the 20. or about a million okay, so we worked out a number of entries. how much space is it actually gonna require to store this entire page table for this process well each entry, has to store a number, the physical frame, and I'm gonna say we'll use 4 bytes for that you could squeeze it into a little bit less, but... we could squeeze it in into kind of three bytes or so, but let's not do that. lets keep things simple. each entry is 4 bytes... why did i need 4 bytes? because I'm taking back numbers which are 4 bytes long so ive got two to the twenty times four bytes is what? 4 megabytes! so the overhead of using virtual memory here is 4 megabytes! and we better store this table in some well known place in physical memory alright? we can't store this table somewhere in virtual memory address otherwise we'd have to use the table to figure out where it is stored in real memory so the cpu has another register that says: okay if you want to actually turn a virtual address into a physical address for this particularly process... there's somewhere in memory where i put aside 4 megabytes to store this table okay, so, a little challenge for you here let's say Ive got a program that's gonna read a byte at this virtual memory address how we many memory reads  are required? so if I didnt have a virtual memory, I would just need one memory read. I would just read the byte location 512 yeah, I would just read the byte hexadecimal value 200 but we now have virtual memory, so how many memory reads are required two! YES! we need to actually go back to main memory and say okay I'm tying to read this particular address" so, I need to turn this into a page number and offset and once ive got the page number, i'll go back to my table, lookup table, which is stored in real memory in order to pull out the actual physical frame and so this might be pointing anywhere. okay its actually in here so it took me two memory reads, i had to read the 32 bits in here, and then finally, the byte that i cared about what have i just done to my machine?! I've just through sheer brilliance managed to make it twice as slow! I've halved its speed!! remember, memory is really slow! compared to the CPU, you could often do ten to a hundred, if not more instructions for the time it takes to go to main memory remember? HI MEMORY MEM READ? HELLO youre gonna do that twice now. for every single time youre gonna read or write
So we have a problem, yeah? we have invented virtual memory, but we have halved the running speed of our machine this might be a difficult thing to sell in the marketplace if we half the speed so we need to do something about this okay we can have caches, etc but we still got the problem Now, we've invented virtual memory which is great, we don't have to worry have fragmentation so much but we halved the speed we halved the speed because we're doing this lookup alright, lets see what happens when we use a two level page design so why might be care about two level page design well lets do a similar calculation but for a 64 bit system lets keep our page sizes at 4096 bytes so, what is this? this is 12 bits... so if thats my offset. how many bits do i have for my page number? 64 - 12. i got 52 bits left thats gonna be used for my lookup table, alright? so how big is my lookup table gonna be? 2^52 how big is 2^52? okay so how do we work this out roughly. well 2^10 is a 1000. so okay its a little big this is the number of entries i'll need inside my page table i better go home and and buy a lot of memory just to store my page table so what worked really well in 32 bits is completely falls over in 64 bit land because, we... heh. our page table is just too large! BUT to quote black adam we have a cunning plan.. we'll have a cunning plan" We will use a multilevel page table because, our address space is huge, but guess what: most of it is unused! so, let's split this 52 bits up into multiple lookups so we'll take this and split it up into pieces. uh, we'll um lets start it with just two. so the idea is that I've got an initial lookup here lets say that its, that we use um... i dunno.. 10 bits? sometimes they only uses 4, but this is matter of example so we use the upper most 10 bits some of these can be empty, they may not refer to anything. they may not be used in that huge swath of address space we dont even need an entry in here so lets say that the lowest and highest entries are used here so this will point to another page table  with a whole lot of entries, lets say in this one, we have twelve bits and these entries may or may not be filled, but they dont refer to frame numbers yet. i can keep playing this game for as long as i want until i got up to a total of 52 bits alright so how many bits have i used up so far... twenty twentytwo....  so now ive got thirty bits, for example in my last one: and so on so ive just invented a little page table system here, a multilevel page system, where to convert the page number to a frame number, i now have to do one two THREE memory reads and each of these can point to a different table right so this one will point to a different area of memory... just say okay these are the entries in here, they may or may not be filled and so on so now i've made my 64 bit machine even slower than my 32 bit machine, right? now a single read or single write now takes 4 memory looks up the actual read itself and all these page table look upss if I was working at Intel at this point, I think i'd be fired, yeah? we've come up with a machine that is now twice as fast as last years model but dont worry its got a bigger number on the box, so people are gonna buy it right so this is the idea: so we've got a basic idea of how to split this up with the idea that we can do multiple table looks ups we have just got a little bit of a problem that most of the time, its incredibly slow so in a little bit, we'll talk about how to fix that alright so lets do this we'll work this out on a 32 bit system and for a two level page table example, we'll say we'll have 10 bits wait a moment, i wanna get up to uh yeah, 32 okay, and then um 12 bits for offset so how many memory reads are require to read a byte at this address well you wanna do a read first of all, you go to top level page table. this gives you the address of the next page table and finally this gives you the frame number for memories so in a two level page table, we are running at three memory reads for every actual read or write that you wanna do sorry. three memory accesses that your program tries to do. so we're three times as slow so this is a great system that allows us to have virtual memory, but as i keep saying: ITS SLOW so whats the fix? the fix is this... translation lookaside buffer
called TLB so our processes rarely need to access page frames in a completely chaotic, random manner most of the time, if you recently accessed a particular page in memory. guess what! in the next few nanoseconds or microseconds, youll likely want to access that again so lets cache the result lets cache the result of all the lookups that we're doing on the off chance that we'll need it again in the next few nanoseconds as thats the purpose of the TLB its an associative cache if you have a query about which physical frame you want for a particular page number then if youre lucky, we've already calculated that in the recent past and we still got the result in the TLB in fact, TLB is designed so that 99% of the time, we have a cache hit the result IS in the TLB one thing to note about the TLB, we do this in parallel this is hardware. so in trying to figure out what physical frame we want to go to, we ask the TLB at the same time as trying to start this other lookup through the multiple page tables and whoever gives this answer fastest, wins because remember, we're using this everytime we want to talk to memory so it is a critical piece of CPU performance ok, questions at this point? yes okay, so uhhhh let me give you an anology and then i'll try to do as it as the concept itself its bit a like this: suppose i wanted to go from a phone number to a student name so I use the first few digits of the phone number to go to a particular filling cabinet, so the 217's" im all gonna put in this particular filing cabinet. and the 604s in the other cabinet so i start off with  the top most digits (000 to 999) but i wouldnt have the actual entries inside that filing cabinet, this should tell me which other filing cabinet i should go to for those entries so its... and it could be that some of these are empty, we dont have anybody with a 555 filing.. uh phone number okay? so it will be a bit like this  we'll get the first result and we'll have our first table and we'll use the  the highest bits  but we've shifted them down... so this is just kind of pseudo code and this tells us, where the next table is so if you like, its a pointer to another array ok result 1 and we'll use the middle bits as a number inside that table and that gives us finally our frame and then we just need to multiply or shift it and then add the offset  so we dont know.. so theres multiple ones of these middle tables and they correspond to different entries in the whole address space so if you think about your process. OKAY the stacks at the top. The heaps near the bottom. and the very bottom is the program code" so you might find that you might actually got three entries for example, in your very first table. one of the very memory addresses and a couple for a the lowest memory addresses. nothing in the middle yes. yes it skips all of these lookups itll give us the frame number no because the TLB is part of the CPU it doesnt need to go back to main memory. its a tiny piece of associative cache its a expensive, its fast, and it tries to do it if possible within one instruction because without this, the whole CPU, it doesnt matter we're gonna add the most played numbers together. as soon as step outside trying to use registers, we have to use the TLB its essentially, its stored in these pairs a page to  ... frame number and i dont want to go too much further, because guess what, we can spend a whole semester talking bout TLB's if we were hardware people it turns out that on real hardware, we have TLBs associated with each level of cache. we have a TLB associated with table lookups and data lookups and TLBs associated with CPU instructions etc etc etc this is how intel figures out to make very very fast chips by optimizing the size and performance characteristics of these TLBS that youll find on the cache and you gotta decide as well.. how do you.. do you want to share these between different CPUs theres a lot more detail than we're gonna think about today I wanna comment on one important idea though we've talked context switch when we get our CPU do something else, when we want to take the CPU state and save it
so we need to do a context switch for example, you're gonna need your CPU to start working on a different thread or start working on a different process so a context switch as far as we're concerned, we save the CPU state my question for you is what should we do with the TLB is it still valid, are there the entries in the TLB still valid in a context switch? what.. take a moment to talk about it with your neighbor okay so the question is... what should we do with the TLB we got these lookups from a page to a particular frame of memory and what happens during a context switch well its a trick question it depends on the kind of context switch because here's one example, suppose we got our CPU to stop working on one particular thread of our process and please instead start working on this other thread of the same process all our virtual memory is still the same since inside the same process so all the cache lookups that we've done ... we can keep that ok here's a different example suppose we tell the CPU to stop working on this process and start working on another process our virtual memory is no longer the same the address is no longer mapped to the same pieces of memory, so then if we swapped another process we should clear the TLB the state of the TLB is only relevant to a particular process because virtual memory addresses are unique to each process as long as is... it depends on how much money you have to spend okay right ready? page 2! alright so our processes are working along one day and tries to do a simple read or write to an array, an ah! the TLB says 'i have no memory of this page' and a few nanoseconds hundred nano seconds later, we finished walking through the page tables and hah! NOTHING. nothing i got nothing of this particular page number. it doesn't actually point to a piece of real memory. what happens? its on the harddrive. yes! we can cheat ok heres the beautiful thing about virtual memory is that we can lie to our processes is that, they are like inception, live in inside virtual world in virtual memory and we actually need to have their data in physical RAM when our processes try to read or write it for the rest of the time, haha! we can just dispose of it and use that ram for other things for other processes that always want to access memory ok so where it can be find. it might be found on disk inside secondaray storage ok so, we can store it where might you find it? for example what's known as a swap file or in linux: a swap partition where area of your disk is not used for storing/making files but for storing this copy of memory so we can swap out a page at a time and store it on disk and we'll leave it there until  an attempt to read/write memory fails stop and think how that might work alright your processes are like okay read this piece of the array, or read this variable, or call this function" at that moment, the hardware says oh guess what" this virtual memory address doesn't correspond to a physical address i better kill the process the hardware of course doesn't actually kill the process instead what it does, it raises an interrupt on the CPU and we have to write some operating system code that says aha look at that!" our memory hardware is complaining. it couldn't find it" we got two options at this point we could say clearly this process is a bad program, and that address is just invalid; it was trying to read a bad segment of memory. segfault" Or it says hold on hold on. dont look! and pull the relevant data from the relevant disk and stick it to memory" itll be like trying to call comcat and they employed people in that time that you actually called them up hello i'd like to complain.... um so we can do something clever right here and that is where the dirty bit comes in with each frame of memory, we can store a little bit of matter information about how its being used by the process for example has this piece of memory ever been modified as long as its dirty why didnt we call it the modification bit I DONT KNOW  but anyway its the dirty bit to say that the contents of this memory has changed since it was first created either loaded in from disk or malloc'd when you expanded the heap  but the point is we got stuff in memory that we care about so if the dirty bit is set, we know that if we want to put this data on to disk, we actually got to save it
so what kind of optimization can you make if the dirty bit is not set if the page is clean thanks! yes! great! you don't need to necessarily write it back to disk. it could be we already got a perfect copy on disk.  whats the point of actually writing it again when you know that its identical so you can save yourself from time if you know the page is clean could be that the page for example is just NULL / zero. you havent touched it at all. youve allocated some memory and you havent used it yet it could be part of your process. the CPU instructions that actually make up your program when you know you got that stored on DISK, whenever you need to read that, just load that page in so it tells us whether the page has been modified thats not all we can store about each page what else can we store we could have a  happy bit we could have a Fri.. not im just kidding we dont have a friday the 13th bit or a happy bit but i invite you to take on a hardware company and add that yourself when you want it so what else can we put inside each page. thats matter information. what would be useful to us yes! a valid bit okay. we should a valid bit that says its a real valid address, perhaps its not currently loaded into memory what else?! ok... clearly clearly i need to make you a lot more evil think for a moment how we can our processes more secure how would you like protect memory in some way. yes! okay, what's that do? if you try to read from memory it gets you a segfault. okay i'll that ! yes how about we protect what you can do with this memory so two common ones are whether its read only and whether you can execute it or not  so think about your virtual memory map for a moment. weve got our instructions down here. our functions that we've written or the CPU code. we've got the heap we've got the stack up here ok i realize thats unreadable but you notice now! we've got the stack at the top and heap and functions the only error that we'd expect the CPU to execute instructions in is this bit down here, where we've written function code we dont expect to start executing instructions inside the heap and the stack and in fact if that happened, it mightve happend because someone's managed to have a buffer overflow and DELIBERATELY put malicious instructions into our memory and somehow managed to get the CPU to jump to that location so most processes, you should not be able to execute code thats store on the stack/heap and an exception might be a just in time compiler, such as java but most of the time we don't expect that so we should be able to mark our pages and say do not execute stuff inside this page, if you do raise an interrupt and tell the operating system about it" another one is read only. read only is really cool because that allows us to share pieces of RAM for example the code for malloc, for example for strlen how about all the of the code inside the C library, libc we could put that inside one piece of memory and then share it with all processes that need it. for example how about the openGL library for example, right, and i can start listing all the common libraries and we only need to put them inside physical memory once! so its a huge saving and i  can share with all these other processes, so that i can minimize the total amount of physical RAM right here's a little demo here okay, so in fact i can  look at this special file called maps and  in fact with linux i can see how thing are mapped so ive got and we'll talk about this virtual file system later on in the course but you can see ive got libc, and for this particular process libc, different parts of libc are mapped into different parts of my address space right so we talked about sharing stuff to be able to share libraries theres another reason why we might want to share some ram and that is IPC also known as inter-process communication, a way for two processes to share and  today we're just gonna talk about a few examples just so you can at least name drop this stuff inside interviews and here they are mmap allows me to setup some shared memory between two processes  so i can say fork and now actually have some shared memory that exists between the child and the parent so its a deliberate way to say nonono we actually want to share this physical piece of RAM together between the child and parent" how else can you connect two processe? how could else you could send some info
signals yes! its a very simple form of interprocess communication but you can send a little signal for example HEY TIME TO QUIT" or send it say 'siguser1 and siguser2' and you can decide what these particular signals mean how else can you comunicate well ill give you a hint about we'l talk about next lecture and that is pipes! and the nice thing about pipe is that you can push stuff down one end and another process can pull stuff out the other right so ok in the last 30 seconds lecture we'll talk about Amdahl's law ill give you hint about what this means for mpmerge im asking you to make mergesort go fast but think about the program for a moment. whats it do it reads a whole load of data, look at the source code . youll discover its using scanf and converting a line at a time into an integer. then we do the sort and then we printed it out to a file so your challenge is to make this bit go faster but in the basic week 1 version of the MP theres nothing you can do about the timings of in and out. and in fact if your interested, you can see just how much time these take and that would help inform you what kind of speedup you might expect for the process as a whole and with that. have a wonderful weekends. im here if you have any questions. ill you see monday! thank you very much monday we'll talk about pipes and seeking through files
Good morning class  How are you? Good Morning  How are you? Great, Isn't the weather wonderful? So here we are only a week back from the Spring Break  Let's kick back and relax  As you know  Uh  Come on  Okay, alright so  We are going to look at two important things  First is pipes The second is working with file descriptors and moving around in files Okay  So, the  other important thing to note is that there is a quiz on Friday  No, just kidding  It's Wednesday  Okay, so the quiz on Wednesday we'll talk about in the second half of the lecture  So let's get started with pipes  Pipes are a form of IPC  Interprocess communication  It's an easy way to go to send data from one process to another process, especially when you want to talk about child and parent processes  And the great thing about is that the data that you sent stay in memory  So, yes we could have opened a file and write to communicate with different process  But we can use pipes very efficiently when we have processes in memory, so the kernel system can manage this as a stream  Now why do we call it a pipe  Because it behaves like a pipe  We can use one file descriptor to push data down one end and another process can say Okay, I'm ready to read data  Let me start pulling data out And it behaves exactly the same way as reading and writing to a file  So this is a fundamental concept in Linux and other operating systems is let's have something called a file descriptor which can actually be more than a simple file descriptor  We're going to see this again later in the course when we talk about socket and when we talk about networks  Guess what I'm going to set up a communication to another machine somewhere on the intweb and I want to send some data to it or pull some data from it, and it just like reading from a file Well  Kind of  Of course there is little bit more details but that is the basic idea  I have an integer that represents the communication pipe and I want to be able to send and receive data  Now, first thing to note about pipes is that actually you get two file descriptors for the price of one  We're gonna use the first one for reading and the second one for writing  Okay, so we have two file descriptors So they are specialized  So a pipe actually is a one way device  We could use it to send data to ourselves  It would be pretty silly, but we could use it  There is a danger to that though, which is that the pipes like a ring buffer have a limited capacity  If you try to send too much data on the pipe, your write call will block until somebody actually pulls data  So if you use single threaded process that's bad news, because now there is another thread available to actually do the read  So let's actually start by actually looking at some code here  Okay, right  Let's pull up the screen  Do we have a picture Okay  Ah  Step 1, plug it in  Hurray  Okay  Right  So here is our device now  other comments on this that there is more to read about pipes and you can read more in my little wiki book  Here we go  For example, files and working with pipes  And so there is more to read about this  So, how do we make a pipe  Okay, so the trick is first of all just make an integer array of size 2  Here it is  I'm going to call it my file descriptors  Here we go  And so we are going to pass a pointer to my array  How do I do that? Easy, just use the name of the array to this function called pipe"  Okay  So that makes an object inside the kernel that represents the communications  I can now use between different processes So for example let's now just have a look at those numbers so we got the two file descriptors fds 0 and fds 1 So we made ourselves a pipe  Now this being an in memory thing  Here we go, it used file descriptors three and four  That shouldn't be too much surprise because I already know that 0, 1, and 2 are being used, right? 0 for standard in, 1 for standard out, and 2 for standard error  Alright, so we got ourselves a pipe which then just died because process died  So we want to do a bit more than this  We want to set it up so that we can send the message from our parent to a child  Okay, so let's make a parent and child  How do I do that? It's time to fork  So here is our fork result, and if I get a number bigger than 0, then that mean I'm actually the what? The parent or the child? I'm parent! Alright  I have a child f so I am the parent  Okay, so we are going to send something from the parent to child  So let's send something down to the file descriptor  Right, now the first file descriptor is used for reading and the second one is used for writing  We should send something to fds 1  Right, what should we send? So how does the write work? So remember, it's just takes a pointer to some memory, and if we pass in a string like Hello, what do we get there? Well you get a pointer to where this string constant Hello's So we have the address of the H and we can send that And we can send that right  Later I send a new line as well  So how many characters  How many bytes is that to send down? That's one, two, three, four, five, six, right  So we will send six bytes to that file descriptor, Now we could have send it to the standard out, and we would have seen it appear on the output, right? But we are not doing that  We're going to push these six bytes down the pipe  And we stand a good chance of not blocking  Most operating systems allow you to send at least 4 kilobytes of data Others actually some allows you up to 128 kilobytes I've seen in the past, so we know this is not gonna block but what should we do now? let's just prove that we've done something we want to print out  Okay, so parent sent some bytes  Okay, and we'll  just finish
Okay, so other thing to do then is to be the child  As a child, you want to write from this  Okay, so how can we do this? Well one low level way of doing without the c-library is to do directly call read, and if you call read, you need say which file descriptor and so, that would be fds 0  You need to say, Hey here I got some buffer, I got some memory you can use, and also say how many bytes I am prepared to accept  so if I were to make, for example, a little space on my stack here  I could then say read into the buffer, and here is the size of my array Now if you call read like this, of course you may not get a thousand twenty four bytes  So actually we should see how many bytes we got So here is the number of bytes and we expect that to be greater than zero  In fact, read will block until we get some bytes out of that pipe  Okay, what should we do with this bytes?  Well, let's for now print out Hurray I can't some bytes"  say the number, and we could say, read what happens  Right, and you can perhaps guess what might happen here  So we want to say we got this number of bytes and here is our buffer  Okay, and I'll do a new line, so we flush this  Right so let's try this and see what we get Alright, so parent sent some bytes, and Hurrag I cant some bytes"  Right, so my typing today is a little off But we saw six bytes, and we saw Hello  Now, one two three four five  We were lucky in this case  Why were we lucky? Yes! correct, we didn't send the null byte  We sent Hello" and then new line, which happen to be six bytes  But we never actually sent a null byte  We chose to not send a null byte  We just sent it as bytes  And the operating system doesn't care  It just says Okay we got some bytes from my parent" got some bytes from pipes that stick them down, and later it says Okay we'll read this many bytes" So, our code is actually dangerous  Our code could have printed out gibberish after the Hello Let's fill up our buffer with some garbage, right  Let's put an extra character in there  And you'll see that we manage to print out the hash as well  which is not a part of the message  So our mistake here is that we forget that the string has a null byte, and if you want to do string processing on the byte that you get back, remember to include the null byte  Either send it explicitly down your pipe or add it afterwards The operating system doesn't know that you're sending a string data  It's just bytes as the operating system concerned  It's just Hey, I'm gonna put this on the memory  Here's some bytes to send the pipe So, what could we do with this  One common thing to do is to include special character in the end of our message  Maybe a null byte, for example  Or another character to say Okay, I'm not going to send anymore data" So, if I for example, I could say I know that my normal data would never use an exclamation point  So that my reader would say, Oh look, I just saw an exclamation point I now know that was the special terminator to say that okay my parent is done with me, and it's never gonna send any more data So telling the reader that you have no more data is easy  You could just simply include a special character Okay, so telling the reader, you just send something special You send Okay, good bye", and then you write a little bit of code and say, "Oh look, I've just got the final piece of information I know there is no more data coming There is another problem, which is What if the reader closes and the writer doesn't know" And we will return to that in the second half of the lecture, so this just a quick introduction to pipes  Look they are pretty easy and now they can give you a form of inter-process communication  If you want your child and your parent to send stuff to each other, guess what? You need two pipes And, I deliberately didn't tell you one more detail, which we will review in a little bit  About closing these file descriptors  This is kind of naive version of pipes  We'll come back just in a little bit  Instead, we'll gonna talk about fseek and ftell  Unless any has any quick question No quick question  So the comment here is Whoops, we should be closing stuff" And we should be closing stuff here too  Okay  Alright, so let's do fseek and ftell Alright, so the next thing we'll talk about is our file descriptor, when it talk to a normal file when we call let's say open or fopen a file  Have a position  Right? We can say Okay give me the next line Say call read line  Or read the following next 8 bytes And every time we talk to a file descriptor then, we're changing the position in a file  So the operating system is keeping track of that  We can change it  One other cool thing we can actually do is jump to the very end of the file So, why might that be useful? Okay, we want to write some data again  Suppose you want to know how big your file was is the plan  Move the file descriptor, so it's right at the end of the file, and then say Excuse, what position am I?" And that tell's you how big the file is  So please tell me my current position
So, the things I'm talking about are fseek and ftell  Let's have a look at that Okay, great  So, ftell, tells us our current position  So if you go to file descriptor and you say, Where am I in the file?" That's useful in case you want to get back there later for example  It's also useful if you get to the end of the file and you want to know how big the file is  So a common way of finding out how big the file is is the following  We'll fseek to the end Call ftell and then fseek to the beginning of the file  To do what we're gonna do, say copy it In fact, past cs 241 exam had asked you to identify or write code that does this very thing  I wanna know, for example, how big of buffer I should need in order to read in the entire file  Great, no problem  I'll just find out how big the entire file is, and then go back, so I can read in the entire data  And it's a common gotcha or common mistake to forget this line  If you move to the end of the file, they say, Okay now we need this many bytes" your operating system will say, Ha ha ha I'm sorry, I don't have that many bytes Alright, so don't forget to move back to the beginning if you intend to actually read the data in  Now, fseek is actually pretty powerful  You can use it in three different ways  You could say Hey, I want to get to the end, I want to get to the beginning, or I want to get to the absolute position So if you'd actually earlier called Hey, ftell was my current position"  You could use that to say Now I want to return to at that point" Okay, let's have a play with this Okay  So, I want to open a file, how do I do that? Well let's do it in using C, so we have a File pointer here  Remember all these basically wrap a low level file descriptor, so we can call things like fprintf and fscanf, but underneath it all, they will be calling write and read  So, we could say open a file  Let's call it data.csv"  and I want it to say open it for reading and writing  So, let me print some data to it, so I'll have 1, 2, 3, 4  And, let me fclose this  So, that means creating a file, writing to a file descriptor, and closing it  Okay, so we'll will run this And we made a file  Now inside here, I got my data.csv and I could look at its contents  There we go  Oh look, there it is, 1, 2, 3, 4  So, let's do this again, but this time , we will play out our tricks with it  Let's have a look at fseek  Here it is So we pass in a point to the stream  We can specify an offset that typically is gonna be 0, and then this whence constant, which is either gonna be Hey an absolute position, the very beginning, or the very end" So we can just seek to the end today  So we'll go fseek on f  No offset needed today  And we want to go to the end  And please tell me then where am I in the file If we look at the ftell, ftell gives us back a long  Let's not print anything to it this time Okay, and we'll have a look at that position Alright, what do we get? Oh zero, L How did we get zero L? Because that's not a real type Right  So we made a file with 1, 2, 3, 4  But the position is zero  Why? I'll give you a clue  Let's look at our data file Whoops  We just opened a new file for writing and we cleared its contents So the file is empty  We've truncated it back to zero Alright, so let's have a look at this data that I made earlier This time we'll open hello.c for reading Okay, I will see that this time we found that our program size  Whoops, why can't you see that? Just jump to the left Is that better? Right, yeah  We printed out 71 Okay, so what do we do? We opened hello.c for reading and we seek the end  And we said Okay, what's the current position?" So, with this, then I could now read in all those bytes from that file  For example, I might at this point say, Now I know how big this file is, let me have a buffer of exactly of right size" Alright, so malloc position and then I can call fread  Okay, so fread, I would like to read all bytes as possible please  And how many bytes do I want? Well that many So, does that manage to read in my file?  Let's see what we get  Alright, so this time, let's print out the   okay that was our position Let's print out, call it, num bytes read Okay, forget size of this  Probably it is size type or long, but we will use that for now
Okay. Let's check man 7 fread. So we need a pointer and size of nmemb, and stream, so we got the order wrong here So our pointer into the buffer. And okay. Alright, the number of bytes read was zero. Why? Yes! It's still at the end! Whoops.  Okay. So before we read in the entire file, let's seek back to the beginning. Alright, so how can I do that? I could do this two different ways. We could specify an absolute position 0. So I could call SeekSet. Okay, let's do that. Where is my..there it is. Or I could do relative to the current position. So if I know that I'm 71 bytes ahead. I could say move negative 71 bytes backwards. Alright, this time how many bytes we got? What? 1? Oh I must have messed up the constants here. Number of bytes read... Uh.. bop ba bop ba doo. Alright. Or we may have to read the... Oh no no no no no. That's correct. I did this wrong way around. Okay. Here we go. So, I specify this as Hey read 1 chunk and that chunk size is position." So now if I set my fread constants correctly, it would say the size of chunk is 1 and I want to read 71 of them. In other words 71 characters. Then the result I get is correct! I managed to read 71 characters. So great, I read the entire file into memory in one go. And we could print it out. So let's just puts. Where is the buffer? Okay. Buffer. Now is this safe code? Do you trust it? Look, it printed out the contents of that file. Printed out Hello world.  Is that safe? Correct! There is no null pointer guarantee at the end. So actually we should have made the buffer one byte larger and then actually put a zero byte in at the very end. So, safer code would just say Look, I know the file is there, so I'm gonna treat it like text later." But fread is just saying, okay read all the bytes into this memory. If I truly wanted to treat it as a single string, c-string. I better make sure that it is terminated at the end. So my code might have to be put at the buffer.. There we go.. Make sure that truly is terminated. Alright, so now we got a fast way to read in the entire file. Yes!  Here? fseek here? Okay, so this means the very end. Past the end of the file. So if you would to then open this as reading and writing, you would actually being appending to the current contents of the file. Yes? Okay. So.. does the a typical text ... does a typical text have a null characters in it? No they don't. It's only when we pull strings into memory when we append a null character to represent the c-string. But files don't have the null characters in them. Sorry, the text files don't normally have a null characters in them. No. It does not have an end of file character. So, instead there's some meta information to say, Oh actually this file is currently have this many bytes." And there is going to be an alternative ..so the meta information we will see about the file is the thing would be something like when was it modified? Who modified it? Who created the file, and how many bytes on disk does it currently use. Right. So the fseek does not actually walk along the file checking for the byte. It can quickly use the meta information of the file to tell how big the file is. So it's pretty fast. Yes? Would there be what? Yeah. There's actually is something call stat. But we will talk about it later. Yes. So the alternative way to get the file length is to use stat. But I'm using the fseek, ftell as a way to introduce fseek and ftell as Hey here is one practical way of using it. And stat is low level system call. If we use fseek and ftell, you are using a c-library and nice thing about that is that it is little bit more portable then getting straight down into the POSIX. land of using stat. Okay, for example, this would work on a windows machine. One gotcha is that you saw is that fseek gave you a long. So this would only work on medium sized files. These days we can have files that are gigantic. And much larger can be represented than just a long type. Yes? Right, so if you fseek back to the beginning, you can set it up so you can only write over specific bytes. So the trick here is the option we give to fopen. As so whether you want it to start brand new file or append to an existing file. But the way to think about this is simply that my file is basically just an array on disk. And I've got a pointer that points to where I would write some bytes. So if I wrote 3 bytes, I'm going to just overwrite 3 bytes.
Other questions? So... Interesting problem happens is. What happens if we open these file descriptors and then we fork? What happens, right? Cause I've got clearly something opened, talking to a file. So I can now modify that. I can fseek to different places And I can close it. Okay, so. First the little problem is let's suppose your parent calls fclose. What do you think will happen to the child? Can a child still use the file descriptor? Make your guess now, and you want to be sociable, tell your neighbor Okay, here is why I told to tell your neighbor, because psychology has shown that you'll actually remember things more if you're surprised when you are wrong. Okay, so make a commitment. It doesn't matter if you get wrong. Just at least be surprise. Okay. Alright, so the answer is that it doesn't affect the child. That these actually appeared to be independent, so actually if the parent closes, the child can continue to use the file descriptor and vice versa. Alright, so, in that sense they are independent. Alright, now what about this one?  What happens if you fseek before forking? What do you think the child and parent see? Do they see the same position? Make your guess now. Okay, so if you seek and then fork, both the child and parent will start from that position So for example, if you seek to the very end of the file, and then forked. Both the child and the parent start from that position. So, they will both see or use the new position. Okay, what about this one? What happens if say the parent or the child fseeks? Does it affect the other process? Make your guess now Right. Yes, it affects the other process Okay, hey, that's not fair, is it? Alright, so here's why. Let's think about this from the system's perspective. It's got a big list of file descriptors which are opened, and if you fork, then actually it increase reference counter and says Oh look, I've actual got two processes using my internal file descriptor. So it's a bit like showing a library book with somebody that if you want to turn the page of the library book, guess what everybody else using the same file descriptor has to look at that page of the book. Alright, so the analogy is like a book page. Okay, so the surprise is, Yes", in terms of closing it, it's independent, but in terms of using it, "No." It's actual one open reference.  So, think of it as the kernel holding a reference to a file at a particular position. And by forking, all you've done is double the number of, or increment it by 1 of number of processes using this same open resource. That means the parent could play bad news on a child. Here you go. Have this file descriptor. Oh ha ha. I'm going to change the position that you are looking at and you didn't know. Alright, so you can really mess with child's mind here. So it's like a book. There is one particular position, so that's a common gotcha.  And thus. Here's something that is kind of useful. If you wanted to write code to write to different parts of a file, at different positions. Then, if you had multiple threads, then there is a problem, right? all of them would be calling fseek trying to move to a different position. It would be nice if you can just say, No, no. I want to send some bytes and this is the absolute position in the file that I want to send these bytes. And so, this is why high performance code these days. If you go to the HPC. HPC lands high performance computing stuff. They often use something call pwrite, which allows you to specifically write to a certain position in the file independently of this fseek and ftell stuff. I don't think we'll use it inside cs 241. I just want it to mention it. It is just like a cute thing to talk about in an interview. It's like, Oh yeah by the way, this pwrite stuff exists" That came about because of changing the position of the file becomes the bottle neck. That all of your threads or child processes suddenly say, Okay, hands off everybody. I want to change the absolute position of the file and no one else can change it once I'm using it" So that's clearly a course of contention
Okay. Are we ready? Page 2! Let's so.. Okay here we go. What's a named pipe and unnamed pipe? So, I actually showed you in an example of an unnamed pipe. Where inside your c-code, you can say Okay, give me a pipe." And you pass it a reference to a little array and it fills that in with two file descriptors. That's an unnamed pipe. Does not exist anywhere other than inside the memory. There's actually another form of this, which isn't used very often. But it's called a named pipe. Which is something you can create apparently on the disk, and here's how you call it. You could say make fifo and give it a file name. Okay, so we'll call it a bag pipe. Anybody from Scotland here? Okay.  Right, so bag pipe is an instrument where you can set up a drone and you keep squeezing it, and you wear a kilt and you Stand on the great hills of Scotland. Alright, so that's a bag pipe. It seems to exist on the file system, and in fact the joy of using a bag pipe like this is that it's lifetime is independent of your process. The bag pipe will live for other processes And you can create it using this make fifo.  What do you think fifo stands for? First In First Out, right. So your first breadth into the bag pipe will be the first data that comes out when you try to read from this file. Except this is not a file. It's a pipe, so the order of the data. So reading from it and the writing of it doesn't behave like a file. It's like a queue. First-in First-out queue. They are not often use, but they are worth knowing about Remember signals? I'm not talking about con-sig. I'm talking about software interrupts we can do such as sigchild, sigint, sigkill. Pipes themselves have a signal Alright. You get a signal If you send data down the pipe and no one is listening See, if a tree falls in a forest, does anybody hear it? As the writer, how can you discover that your reader has died? Is no longer listening to the data And here's how. Actually, you can get a software interrupt, you can get the signal. Say, Oh by the way, there is no one listening anymore. All the file descriptors have disappeared, have been closed. Maybe deliberately, or maybe the child process itself has finished, but guess what? You can send as much data we used, because you'll like try down this pipe, but there is no one there to read it anymore. So you get a sigpipe, so you can choose to handle that. You can set up a signal handler to say, Oh look, my reader from the pipe is not getting anymore data" Now, a couple of comments on this. First of all, this means if you fork, then make sure you close the unwanted file descriptors So what do I mean by that? Remember we did this kind of thing, we said Okay, give me two of these", we call pipe.  Look how easy this is. Alright, so now I got my read and my write. Then I call fork So now, conceptually, we got four file descriptors. Yes, the child has two, the parent has two. But we're only going to use half of them. If the parent gonna do the writing, the parent does not need the read. If the child is gonna do the reading, it doesn't need the writing file descriptor. So a common pattern of this is in the child, the first thing you do is that you would close the one that you're not gonna use. So for example, we might close the second one, and in the parent, we do the same thing.  We close the first one, the read.
Why'd do that? To make sure that when our true reader really does finish or close their file descriptor then we'll get the signal. Then the system truly knows that there can be no more, that there is no one left to actually hear the message. Right? So that's the pattern. you'll see this, and you can read the wiki book to see examples of this, where you close the unwanted one. Okay, now the joke of the day and on EWS it doesn't work. The EWS linux kernel 2.6 whatever it is, has a bug such that you never see sigpipe.  But don't worry. I'll tell you a work-around on Friday.  Or maybe the end of today, we'll see Right, should we have time for this?Alright, how do we send an integer... a value of a variable? Okay. I showed you code that just use read and write to send stuff down to a pipe. If you wanna start sending more interesting data like integers, etc, we want to be able to call things like fprintf(), right? We actually want to send.. a user send a c-library. Guess what? Here's something very useful. I can call fdopen. Where it pass in one of my integers, a file descriptor So, for example, if I want to use the write end, and then the other is... I'm not trying to use this for reading or writing. And this gives me back one of the file objects. There, I can then call fprintf(). Or if I'd opened the reading one, I can then call fscanf() So this is a way to promote a low level unix file descriptor up to a c-based object that we can now... I don't mean object in C++.  I just mean a resource in a system so then we can call fprintf or fscanf and work with more structured data. So this takes us from a simple integer to the C-based version. Now I can use fscanf and fprintf. Questions? Yes? Yeah fdopen. Alright so we're going from an integer to a C-level object Alright, yes? When it happens, it happens when you try to write stuff in into the pipe no one is listening. So you want to try to write some data and then you just discovered that no one's listening. You don't what happens to the reader. That's the point. Maybe you could set up a different pipe to say Okay, I'm gonna finish it, you can use another pipe to send the data." But the idea is that the pipe itself can tell you when no one is listening. No. no, it's when you try to send the data itself. If there is no one there already, you get the signal. Okay, so.. right. Yes we have a quiz on wednesday. I'll publish some practice questions in a little bit. But here are the topics you can expect. Conditional variables, semaphore, mutex locks. You have mastery of these amazing tools. You know what producer consumer is. You know how to make a fixed size multi-threaded ring buffer. You could do it with semaphores, you can do it with conditional variables. You know how to analyze a good and bad implementations. You know the coffman conditions. You could understand the definition. You know reader-writer. You could analyze good and bad implementations. You know dining philosophers. You could talk about the different implementations and will they suffer from deadlock or livelock. And finally, resource allocation graphs and how to use them to determine which processes are deadlocked. With that have a wonderful week, and I'll see you on Wednesday. Thank you very much.
okay good morning class as you might have realized, spring break is starting and so congratulations for being here as opposed to enjoying the sunny weather outside, oh wait so first of all if your sitting in the back and want to have a more cozy experience, why don't you get up and move to the front and see what it's like at the front for a change I promise not to bite too hard either sit down and relax or come on down and see what it's like at the front and we can have a cozy class right so here's what we're going to do today we're going to talk about handling errors and how we detect them with our system calls and then we're going to talk about some fun stuff, we're going to start talking about networking and this is kind of important right? we want our machines to talk to each other so we'll get done today with some of the basics about ip4 and what's the difference between UDP and TCP but before we do all of that, let's see if your brain cells are working today in terms of pipes right so I mentioned before that you can get a SIGPIPE when something happens - when? when does your process get a SIGPIPE? I'm sorry I'm not listening yes, when you have a PIPE and you write some bytes to the pipe and there's no one there to listen and the failure [will cause your process to] get a SIGPIPE so you can write some code inside your signal handlers to say oh look the listeners died, maybe I'll just fork exec a new one for example now a common gotcha though is when your playing with pipes and fork as you might have found out in the lab, is that you forget to close all of those file handles that you don't need so if you still happen to have a reading file descriptor open, you won't get the signal because in theory you could still read form that okay, so that's our first little question right alright so when all the readers have closed and you try to write to a pipe, you should get a signal in practice we've found it doesn't actually work on EWS the old EWS machines don't support that yet but here's the good news, you may have gotten an email, did you get an email from me this morning? fantastic, right that's my new email script I can now send email as anybody to anybody inside UIUC anyway I won't make jobs about the provost so hopefully you've logged into your new virtual machines brand new feel free to destroy it, install software, etc etc and in the worst case, I'll just give you a new one so it's probably not a great idea to store your family archive on this machine but it is important because hey with this box you've got root you can do root-y things like mount file systems, like connect to named ports and run them ports we'll be talking about that in a little bit but anyways, so let's finish our pipes off so when can a listener discover that there are no more writers how about this then, because in section our listener right was wc, we were using word count to pull data from standard in how do you think wc knew that the pipe had closed, that there was no more bytes coming okay so we had to flush it but actually we had to do more than flush flush simply says to the C library hey you know those bytes you're looking after for performance sake I don't want you to look after them anymore send them down the pipe, in other words call write but we need to do more than that because flushing doesn't actually mean that the pipe itself has closed we want to close it but we haven't actually answered the question yet of how does the listener know when it's not going to get anymore bytes and the answer is if you call read, it returns zero so it's not an error yet, it's just simply that hey I'm going to give you zero bytes and the pipe is closed so let's do this let's have a little play okie dokie right so I made a pipe  I'm going to close the second file descriptor, in other words the write end and let's try reading from it okay so bytes read equals read we need to give it a file descriptor okay so what shall I say fd[0] is where we read from, how many bytes do we want? well here's a pointer to buffer and I'll take sizeof buffer minus one why minus one you say? well for safety for example I might put in at the very end a termination byte for example, just to make sure my strings don't go on forever okay so let's print out to see what value we get okay and I want to print out the result of my read call hey and look it's true, we do get zero, fantastic okay go away right so that's one way right? now that's obviously if we're doing the low level calls like read and write if your working at the C library level you can check for an end of file EOF condition on that pointer so remember how we do fdopen to get yourself a C library pointer well then there's a thing called fopen right so that's relatively easy then to discover that something is closed another way of doing it of course is that you come up with a special token or special character to say hey if I send them asterisks or a zero bytes, then I know that that signifies to me that there's no more bytes coming another way is to say at the beginning of your message, hey I'm going to send exactly 4000 bytes and here they come another way is to know exactly how many bytes you are going to send beforehand anyway and hard code it into your program so that's all we're going to say about pipes today let's mess up our program, let's try and read from a file descriptor that doesn't exist okay so let's say from one hundred and twenty three okay I don't need this right, so what's going to happen now? alright we get a result of negative one the read failed, I cannot read from file descriptor 123 well you and I know that's because there's nothing connected to that integer it's an invalid file descriptor but we want to actually know more than that, we want to know something about what went wrong and for that there's actually this global constant called, whoops come back thank you, errno right error number, so error number will have been set so let's find out what value it was  okay so we'll stick this in here and we'll print it out
actually we can do more than just print out an error number there's a function that allows us to go from that error number to a useful string so we've got strerror and we can pass in a number like twelve well I don't want just twelve, I actually want the number that the system has set for us, so let's print that out as well and see what we get okay right here we go so yeah our read returned -1 to say hey I've failed we've got an error number that's now set to a non zero value and we've got bad file descriptor, which now makes sense to us yeah we've passed in an invalid file descriptor number so before we've played around with things like printerror and it will print out something like It is a Friday let us go okay and perror takes the text we've got followed by okay here we go It's a friday let's go with a colon and guess what, the same message: bad file descriptor which is if you were a user a completely useless message bad file descriptor? sounds like the beginning of a bad movie no it's worse, so okay put this into your log file but don't display it to the user of course but now you can see how perror might actually be implemented in terms of this strerror function okay so that's our error number, it's set when a system call fails so if we go back to our little handout here so what is errno? it's just an int and when is it set? well when a system call fails you can find out what went wrong so nine is not a particularly... yes [question] a new line? you mean because printerror adds a new line as well? is that your question? okay right so we don't need to deal with these numbers like nine, we don't need to remember that nine means bad file descriptor because guess what? on the man page of read [something] we discover the return value we got a list of errors, here they all are so lots of things can go wrong and if we wanted to write a robust program we might actually choose to handle some of these you might say okay in the generic sense, just crash the program or write to the log file but there might be others where you might decide to say print a message to the user and that's how we can do it, we can check errorno to see exactly why the system call failed and then we can just compare it to these constants so in our code here, we could say if errorno equals bad file descriptor EBADF, your file descriptor, your program is a mess! okay so we are going to handle this particular problem what are we going to do about multiple threads? let's say I've got threads making system calls, they are calling mutex lock, they are calling sem wait, they are calling read, they are calling write if they fail, don't we have a problem? how would you know which one actually failed? suppose you're trying to read error just as another thread also fails houston we have a problem we don't know which thread set errorno muahahah yes, okay, errorno is not just an int each thread gets its own errorno integer how does that happen you ask? easy magic actually it uses something called thread local storage but never mind about that so that means if you want to know what happened inside your thread, easy, write errno if you want to know what error happened inside another thread, you can't you'd have to write the mechanics to share that information right, so it's actually local to each thread which is particularly clever yes, you can which brings us to the next question thank you very much for playing, right when is errno set to zero? when your process starts and that's it so here's a gotcha, that if we did something like if errorno is equal to something like we have the EBADF then we just assume that that happened because of the previous call we just made that may not be true, perhaps this happened, perhaps errno was set many many many microseconds earlier in our program so errno is never reset back to zero if you want to set it back to zero, do it yourself and in fact that's quite a good kind of programming practice that if you intend to check its value then remember to set it to zero beforehand
right so there's one other thing to be aware of with errorno is remember signal handlers? where we could write some code to cope with a signal like hey hey we've got a closed pipe condition so in your signal handler if we're going to be calling things which might set error number say we want to remove a file or we want to make a system call that we're allowed to call from a signal handler then it would be really really impolite to change error number for the other part of the code remember how does a signal handler work? we steal the current thread of execution we don't make a new thread. we just actually say to the CPU hey stop executing the current piece of code I want you to run this other little piece of code over here please and when you finish yeah you go back to what you were doing I'm not going to give you a new stack, I'm not going to... right we literally just steal it to run it so that means our signal handler might do bad things to error number so a good handler, a polite signal handler will remember the old value and just before returning we set it so it might go, if you want to write robust code... be careful with your signal handlers and two, if you're going to check the value of errno, it's probably a good idea to reset it to zero beforehand so that you know that if you're discovering an error, that it actually came from the code that you were looking at I've got a cute example here the other thing to be careful about is in your error handlings be careful that you're not looking at errorno values from your actual error handling so for example here it is where we're trying to discover why does semwait fail and so we printed out the problem with this code is that the very first fprintf itself may set errno and that could then lead us down a rabbit hole right? we could say okay why am I getting a bad file descriptor? well it turns out standard error was closed or something like that we had out of memory and it was actually coming out of the fprintf call so it's better to if you're going to make more system calls, more function calls, grab it and stick it inside your own variable so you know that the value you're looking at actually arose from the original call okay right so do you remember how do we print out a particular string message? yeah, easy, just call strerror and that gives you back a pointer to a string so typically you'd pass in errno here and you'd get the string that string might mean something to you and another system programmer but not much to anybody else I've got some bad news for you though it's not thread safe brought to you by homer simpson, yes that's correct your code in trying to handle errors might run into difficulties because in calling strerror in calling two different threads at the same time can contend with each other and overwrite each other's value so we've got two ways to fix this one is that you call mutex lock and unlock between getting back the pointer and using it so you would get the pointer perhaps copy it into your own memory that is being used solely by your own thread and if you do this everywhere in your code that's going to call strerror then you can be confident that only one thread at a time will be calling strerror you've made it into a critical section just remember to do that everywhere inside your code including all of the library calls that wait you control? you don't control. you don't have the source code of all the library functions that might call strerror so this is actually pretty hard to do well and consistently but I have seen people do it the other way is that actually there is an alternative called strerror with an underscore r strerror_r which is thread saf and the reason why it's thread safe is because you pass in a pointer to some memory that you would like to use okay so the next thing we're going to talk about is this EINTR hey this is the hey I got interrupted, do you want to retry? so there's quite a lot to say about this interrupt idea and we're not going to talk about all of it inside 241 suppose you make a system call that's going to go on for a long time for example, you want to write some bytes down to a pipe that's going to connect to the internet you want to call semwait which is going to wait until someone calls sempost these calls can sometimes be interrupted and immediately returned so basically, they fail they fail to actually do what you ask them to do now in the simple kind of lecture code and in the MPs we just say hey don't bother about this, it's fine but in robust code, we actually have to check for this when you are writing robust code, you have to say ok what was the return value of this system call, did you really do what I asked you it's a bit like talking to a toddler, did you really flush? [gibberish] I'm pretty sure so that's what we have to do, we actually have to say oh look, it returned negative one to say it didn't work and now we have to say but why was it something bad like I gave it a bad file descriptor? or was is it just being annoying and if it's being annoying I say hey I've been interrupted, I'm sorry do you want to play again? just call it again
now we're only going to see this for slow running potentially blocking calls so things like semwait reading and writing to the network but it's important to handle this stuff well, otherwise your code will get to what we tested but in real situations it will then fail and imagine playing kind of russian roulette with your code I tell you what, just for fun we'll make sure one of the calls you make today is not going to work do you still feel lucky punk? so that's the purpose of this EINTR, it's to say oh look these thing were interrupted, we better call them again so let's see what the kind of code would look like in this case we'll make a call like semwait and we need to check to see if it failed okay how do I do that? you could say was its return value equal to negative one? right so if that's true, we know there was an error so let's find out if the error was hey I've got interrupted if that's true, hey we'll go again right so here's our plan while this is true... go again! alright so perhaps you and your neighbor can tell me what's wrong with that code [silence] so I'll give you a clue, what's an equals sign between friends? the worse thing about this error is that you get to see this kind of pattern right? you see this kind of code and you immediately say oh that's just calling sem_wait inside a while loop it's trying to be robust code, and you don't bother of course to actually read it so what are we doing here? well errno is settable, it behaves just like an integer and so we're just setting it so what's the result of this expression? a non-zero value so therefore it's true so what our code does then is say rather than check to see if it's equal to EINTR we just set the value to EINTR and so we go around again right so what effect would this have on the code? would you spot this error? when would it do bad things for you? thank you yes, if sem_wait failed for other reasons so for example, suppose you forgot to initialize the semaphore or you're running this on a system that doesn't support semaphores sem_wait might return a different message so what do you do? you call it again! it behaves exactly like a semaphore, it doesn't proceed, it just keeps on going around this loop forever and then you say ahhhhh why is this not working? right so be careful about that, watch out for your equal vs that so that is kind of a typical pattern sometimes you see a little bit more to this as well sometimes you see that actually we want to know say the number of bytes read so we might write something like this while negative one equals okay let's store the value of our return call so let's say we want to know the result of calling read blah blah blah blah blah alright and errno equals EINTR so now I'm assigning the value of read to my result so I can use that later inside the code perhaps I want to know for example if this is zero or the number of bytes that read managed to perform so if you were to drill down into the C library you would discover this kind of implementation that every time we make a system call, we potentially have to check to see whether it was interrupted or not for CS241 exams, unless I specifically ask you to write code that does this checking, I'm not going to expect anybody to have to write this full length out but put this in the back of your mind for the day that you're actually writing real system code outside a class questions? yes? aha, right so this normally happens when a signal comes in and your process has to process the signal but that could be anything, that could be a child finishing for example you might have noticed in some of the earlier programs we wrote that if you had a sleep and a SIGCHILD happened, the sleep itself could be interrupted so why is this? the short answer is that it makes operating system programming easier remember how I said that when we have to process a signal interrupt, we steal the CPU and we actually run some code for a moment and then we give the CPU back as if nothing happened well as you can see, it's not quite true actually as part of giving the CPU back, we just give up we say hey you know that system call I was trying to do, ha, I just gave up it's a nice day, I don't have a problem with that. do you? it's kind of like the californian hello, hello yes let's do lunch and not really so in making the design of the operating system easier, we've actually put the onus on systems programmers on our user code to actually deal with handling these interrupts, with failing system calls so fantastic, you actually now know a lot about how to actually write much more robust code by checking errno  by knowing that you have to potentially check this EINTR thing there's a bit more to say I'll let you read it on the wiki book as you usual but I'm not going to be writing this code all the time in future examples are you ready? page 2!
great, we get to talk about networking so here's another cool bit of CS241 we're going to write code to make servers we're going to make code to make Yik Yak type stuff where we can send text and other data between different machines you could start with your virtual machine right now and with a friend on their virtual machine you could start setting up servers and clients and start transmitting information and this stuff is kind of near and dear to UIUC we were involved in some of the earliest network designs we are still today designing the network protocols deal with the internet 2 and the internet of things but we're going to go right back, all the way back to talk about a very important protocol which is called ip4 so ip4 or ipv4 is a way to send data from one machine to another and for that every machine will have a number, an address so if we're going to send these little packets of information from me to you or from my machine to your machine I have to know, what your address is and this is what ip version 4 is about so this is not a full exposition of the whole description of ip4, just that every machine here or every connected device can have  an ip4 address okay sounds pretty good to me, that was the plan that was the vision so when we are sending some bytes down a wire what we'll do is we'll say here's a sender, here's my ip address and here's the ip address of where it needs to get to and so these ip addresses we'l make them huge we'll say two hundred and fifty six, we'll have 256^4 in other words four bytes or if you want to be precise, four octets so octets is a fancy word for byte in other words eight bits, in other words, we've got thirty two bits to play with in other words,  four billion possible addresses I need a red pen, anybody got a red pen? throw me a red pen ah alright great, this is a great plan when it was designed we can't do every device anymore why? sorry! the pen that wouldn't fly thank you, yes, we've run out of address space but this is the dominant way, today 95% of the internet traffic is still ip version 4 so we have some tricks, we can hide a whole load of machines behind just a few ip addresses for example we can have multiple websites hosted on the same machine and so they all share the same ip address but we've got a problem, this initial specification of saying every device just had a ipv4 address is no longer sufficient so we'll be going over to ip6 slowly the protocol is already out but today ip version 6 accounts for less than 5% of the internet traffic we'll talk more about the actual details of ip version 4 after spring break so let's instead talk about a very special place, anybody going home for spring break? yes! great this is where you're going okay, so 127.0.0.1 is a very special place in our hearts it is the ip address of your local host your home machine, so if you try and send a packet here, it doesn't have very far to go next time you find a script kiddie on the internet, tell them to hack this ip address right so it's very very common, every system programmer knows this address if you set up a server for example and you want to test it you might to try and open this address in your web browser to say okay connect to the server on this very machine alright so rooting this address is this trivial, it doesn't even need to go to the network port the kernel will notice that hey I'm trying to talk to myself and not bother to actually craft any electrical pulses on the wire, it doesn't actually leave your machine and you can use this on a virtual machine or a real machine etc etc etc so this is your local host you can even buy door mats that say there is no place like 127.0.0.1 okay so that's your first ip address, fantastic! most people don't remember many ip addresses but they know that one and they might know an ip address for the dns server but more about that after break instead let's talk about a port so we're going to send some electrical pulses, some bits, down the wire and hopefully it will arrive at the other end at the machine of our choice so once it gets there we have to say well what are we going to do with these bits who are they for? so the idea is to think of a port, like a C port where things arrive we won't give them character names though we'll just give them numbers so on the outside of our packet, we'll say hey this data is going to go to machine whatever one hundred and twenty three point one blah blah blah and I want to go to a particular port so our packets then have thirty two bits or four octets hey look, here's an octet octet octet so in other words we can choose numbers between zero and two hundred and fifty five I just made this ip address up so this is our ip address four times eight bits or four octets but we also need a port number and port numbers use sixteen bits why? it seemed like enough at the time and eight bits didn't seem to be enough these are fairly arbitrary decisions back in the nineteen seventies and earlier to say well we know that we think that this internet thing is going to get big and if we have this many bits, then hopefully we can have different processes listening to different port numbers and that's the basic idea
so perhaps you know a few standard ports like port 80, what's port 80 used for? yes, the web! if you make an HTTP connection to get a webpage, there's a process listening on port 80 so today you could write a process that listens on port 80 and sends arbitrary bytes back to people and you've got a basic web server what about port 443? this is secure HTTPs so secure HTTP does it have to have https content? no, it's just a convention and your client then, your web client, if you connect to say the BBC if you put this into your web browser it's going to turn this into an IP4 address this is the simplified version for friday okay? and also it's going to say look I'll try and connect on port 80 and I'll connect to port 80 and I'll say something like hey give me the home page and hopefully the process at the other end will send back some bytes okay do we know any others? 22, what's 22? yes ssh so your ssh client knows by default to connect to port 22 it doesn't have to connect to port 22 by the way, you can tell it to connect to a different port now if you write a program and try to try to listen to these ports, you'll fail here's why port numbers up to 1023 are known as well known ports and only root can connect to them or sorry, only root can listen to them, only root can serve on these ports the thinking here was hey we've got some trust issues, if people are going to connect to my box, then we don't want any old user process being able to serve content from these ports we'll restrict it to people who have, to all the processes that have root access, that are admins  questions? so the last thing we'll talk about today is two different ways to talk to a server this is not a complete set there are other ways to send bytes to a server there are different protocols but these two are good ways to get started because they are very common and they have different characteristics here's the first version UDP UDP is packet based meaning, can I borrow this? thank you, that I can write where my packet wants to go so I write down your IP address and then I send it out in the wire and who knows? maybe we'll get there it did! in fact today, if you were to do a test between two different data centers between two different continents, 97% of UDP packets would get there so it's packed based, and if you like, it's kind of fire and forget you don't get any tracking number with these things you simply say here's my bytes, I want to send them to this IP address, away you go, good luck out there, hope you make it, if you don't, too bad and like I said, typically 97% will make it the other 3% who knows? they just died half way, they gave up, they found a cafe so there's no guarantee, there is no real reliability guarantee that UDP packets will get there however, it's pretty fast because there's no accountability it's just hey let's get it through as many routes as possible to get to its destination there is no ordering guarantee either so if you send two packets one after the other, they may arrive in different orders here's the other thing that can happen there could be duplicates right, so you send one packet the other end gets 0 gets 2 gets 4 of them so this is the wild west of sending data what do you get for all of these issues? answer: speed you're not trying to track anything, you're not making any constraints on the network, you just say hey get as many of these things to the other end as possible so when might that be useful? yes? video games? for what kind of traffic? why? okay so if you want to stream some data out where you don't care about the old data and you just want to, say, update the current position of all the players or perhaps send some audio where if you drop a few frames, it doesn't matter then UDP is a pretty good choice but you do have to work harder under these kind of constraints your code that you write has to say I might not get the data, I may not get the data in the right order, I might skip some data yeah so it's often used in where let's say audio or games where old information or data is unimportant
alright so the other one TCP we'll talk about what TCP stands for after break TCP is the opposite TCP is like a pipe unlike the pipes that we saw before however, you already have one file descriptor TCP allows us to say okay here's all the bytes that are going to make my home page off you go here are all the bytes in my file push it down that pipe and out the other end, at the other machine that we've connected to, those bytes will come out in order without duplicates without missing bits so some magic must have happened between our two endpoints the packets that were sent maybe some got missing, maybe got duplicated, but we are unaware of that complexity with TCP, it becomes just a pipe and if the network between our two endpoints improves TCP will speed up the rate at which packets are sent if it degrades, it can automatically reduce the speed so TCP gives us a way to hide a lot of the actual network complexity of how those packets get from one machine to another and we'll talk about those guarantees after spring break have a wonderful but safe spring break, I hope you have a lot of fun playing with the new virtual machine the TAs will be in touch with you when it comes to grading MPs thank you very much! come down and see me if you have any questions
okay good morning and welcome back from spring break you might recognize that music as part of the Star Wars music, we'll find out why in a little bit well what we're going to do today, of course, is talk about networking here we are towards the end of the semester and the major topics we're going to look at is networking that is, how we can connect one computer to the rest of the internet and also how can we deal with scheduling and files and a few of the, kind of, loose ends towards the end of the semester so this is it, right? this is the part of the systems programming that allows us to watch Star Wars on a computer from another machine, or anything else who you'll find on Youtube, which of course, was invented here by a student and we'll see how you might've even seen Star Wars prior to Youtube so let's, kind of, take a look at that, right so let's get started first of all, kind of a little bit of sure case for, perhaps you're interested in networking, we're not going to all networking, or course in 241 but, there are courses here that take it a lot further so this is really just some highlights of first of all, if you wanted to know about networking and you wanted to able to talk like you know what you sound lick you're very to quick to start talking about the OSI model and this is really just a set of abstraction layers, so when you talk about vulnerabilities, or you want to design a protocol, you're actually going to be doing it inside one of these levels so let's have a look at some of these okay so, for example, our friends over at the ECE building they worry about the physical level, like what voltages do I want and how am I going to represent my 1's and 0's etc. 241, we're going to be playing mostly with in this level in terms of looking at packets and different mechanisms of transport in particular, we're going to be playing with TCP and UDP that's not the whole story though because of course, we don't want to simply send a packet of arbitrary data we like to make applications applications themselves have protocol so, if TCP and UDP are methods, are well-defined ways to communicate at lower level, at the higher level, you're going to find things like HTTP when do you see HTTP? websites! yes sir, if you wanted to talk to a web server, you need to know how to talk HTTP, and there's a document about that about how what it means to talk HTTP, what bytes you should send, what responses you should get if you want to send mail, there's a prototype called SMTP alright, so how about all of these different kind of levels of protocol inside CS 241 what are we going to see? well, we're going to see, like I said TCP, UDP most of the internet today, as you know, uses IPv4, or often shortened to just IP4, or even sometimes IP and this is an addressing protocol that allows me to talk to machines, but we only use 32 bits to describe the endpoints, the starting point and the endpoint so we're limited because we have more devices than that so don't panic, we came up with a new protocol called IPv6 which now has 128 bit addressing except even though it was designed many years ago, it still represents less than 5% of today's traffic and it still has problems that you'll find routers, which are misconfigured throughout the internet and IPv6 is not yet as reliable as it should be right but there are, okay so that's the kind of as far as we go in terms of these lower level protocols i'll show you what the actual bytes look like for IPv4 and IPv6 in another lecture but for now, we're just going to say, hey this stuff exists, and this is the way I can send data from one machine to another machine so let's have a look at this TCP and UDP alright, first of all, we better understand what they stand for so UDP is user datagram protocol" so, by the way, the word datagram comes from data and telegram it's like this, I want to send this telegram to you and I'm not quite sure when it's going to arrive and in fact, if I send two telegrams to you, maybe they'll arrive out of order maybe we'll get lost along the way, the carrier pigeon will be eaten by a hawk who knows, right? we don't know whether the information I send will truly get to the endpoint maybe a scribe will actually send you two of these things so, we talk about datagrams when we have this unreliable delivery mechanism so that's its main characteristic, it's unreliable and that pen doesn't work too well, so let's a different one unreliable so we can get our datagrams out of order if your general says, hey! retreat!", and another telegrams says, "hey! advance!" without actually putting your own timestamp information inside that, you don't know which one is sent first so UDP gives you no guarantees about when things are going to arrive, the order of things going to arrive, and whether you have missing data, or even duplicate data so, essentially it's making no guarantees about the lower levels of the internet it's saying, if there's any problems, if someone decides to disconnect the cable, or the router between you and me is misbehaving, you're open to those problems you have to deal with it but it's fast there's no handshaking as soon as I send a packet, and arrives at your end, you see it okay, so one of the main characteristics is it's unreliable, what does that mean? we may see dups we may see missing datagrams it may be out of order so there's no guarantee about sequencing essentially, it's saying, yeah, I've got a post office and I've got telegram service, but I make not guarantees about how good it is". it might change from second to second it might change from second to second"
alright, so why would anybody use UDP's? and the answer is: most of the time, we don't because it doesn't give us many guarantees however if we were writing an application where we prefer to handle these missing packets, so all of these unreliabilities stuff over late packets, over late information arriving, then maybe UDP will be a good choice alright, so let's flip to the other protocol, that is quite common, and that is TCP or transmission control protocol so if UDP was giving direct access to those telegram service TCP inserts some control now between you and actually what happens, actually what goes out on the wire actually, it will abstractly no, it will hide all of the problems we might see when packets are actually sent from one machine to another machine so what are we talking about? well, you're going to see the following great things first of all, it tries to add some reliability I feel like I'm a used car salesman at this point Hey! Don't worry about your car! If it breaks down, we'll send you a new one. No questions asked." if your packets get lost in transit, don't worry, I will handle it for you I guarantee that your data will get from A to B and in the right order! just give me the data you want to send, and you'll be fine and in fact, I'll give you some error collection as well so, we might write this as error detection, or guaranteed that your message is error-free which is whiter than any other cereal, no what? okay actually error-free is a bit of a marketing hype, actually the checksum is only 16 bits so actually, you got one in the 2^16 chance of this error detection not discovering some random bit flips so that's a little bit of a hyperbole but, it does do error detection okay, what else we got? flow control and similar to that, congestion control so our protocols are, at an abstract level and we don't know whether we're trying to send data over a fiber optic link or piece of telephone wire or even just some old barbed wire that we happened to have that stretches from my farm to your farm TCP can cope with all of these of course, the number of bits we can send per second in these two examples are very, very different so we want a mechanism to ramp up the speed at which we try to send bytes and we need mechanisms that can cope with partial failures so, suddenly, our route from China to here changes drastically and we can no longer send as many bytes as we'd like per second TCP will notice that and actually to reduce the number of bytes it sends per second, so we can optimize the use of available bandwidth in real time and finally congestion control hey, we don't share these links, so we actually want to be careful that we don't step on each other's toes and so, we attempt to make sure we play fair with other users of the link how do we do these things? magic! no we, of course, TCP actually includes additional information, in addition to the bytes that you want to send, includes additional information inside each packet as to how many bytes should be sent and the status of each end we might talk a little about it inside CS 241, but if you want to know more, take a networking class at the 400 level one of the most amazing things about TCP is that it, it has to work even with adversarial people, or attacks on the internet that will try to steal those bytes, copy those bytes, masquerade as you, and TCP is evolved of the time to try to cope with some of those threats and we might talk a little bit about that right then, so let's answer some of these questions okay, which one of these you think uses handshaking? yes! TCP! before TCP, can send any of your bytes it actually has to set up  it has to send a packet from one direction to the other direction so there's a latency, there's a startup cost to creating a TCP connection which one do you think requires more system resources? TCP, yes! so, TCP behaves a bit like a pipe except that we can use the same file descriptor for receiving and sending so remember how we're seeing read and write, and you've seen in terms of being able to talk to stdin, stdout you've seen it in terms of being able to read or write from a particular file, you've seen it in terms being able to read and write from an unnamed pipe guess what, we can use these with TCP as well! so once you've set up a connection with TCP, sending stuff is easy! and I'm going to put it in quotes easy for system programmers like yourself there's a few gotchas and we'll talk about some of those today and in future lectures okay, which one of these do you think encrypts your data? make your guess now neither the bytes you send on the internet using these are completely visible to anybody else that is sniffing on the wire so, do you trust every telegraph operator between you and your mom? because they could be copying the bits that you are sending Hi mom, having a great time. Send more money. Thanks" being able to see those characters so of course, there is an art to making sure that those characters don't mean anything that's we can encrypt them in some way but that is not part of these lower level protocols
so a long, long time ago, we didn't care about  sending things in just clear text on the internet because there were no bad guys no one was listening to those bytes that we were sending and in fact, there used to be a service, a telnet service, where you could log on to a remote machine, type in your password and you'd have a remote terminal these days, of course, we use SSH on port 23 but it didn't always be like that there used to be a service on port 22, which was completely unencrypted good luck today finding an unencrypted port 22 a terminal service on port 22 well, guess what? i've found one let me show it to you of course we're talking about an application here, a virtual terminal, where we can connect to a remote machine and start sending it some bytes so here it is right let me okay, right [gibberish] okay, so there happens to be a server on this particular address let's connect to it yes, you couldn't actually log into this particular server, but it will play Star Wars movie four in ascii and so it slowly sends bytes to you, and your terminal interprets those bytes as characters, and displays them on the screen and the servers careful not to sent too many bytes too fast right, so do you think this particular server, this terminal connection is run with UDP or TCP? TCP! because normally where we want to connect to telenet, we want to make sure that [gibberish] the screen size is a little messed up, but you kind of see the idea this is what happens to good protocols they end up serving Star Wars movies fortunately, a UIUC student came up with Youtube, and we no longer have to watch this kind of stuff, right? okay this is way too much fun so it's easy to find, just type in telnet" and "Star Wars", and you too can watch Star Wars and enough of that so these days of course, we have this major use of the internet, which is web traffic so when you want to talk to a web server you need to understand this high level protocol from the seventh layer HTTP, hypertext transfer transport protocol this of course runs over TCP and HTTP is actually an offspring of an FTP protocol and it's pretty old now, version 1.1 is about 15 years old and it was a  text protocol just recently, we now have http version 2 of this protocol which is now a binary so if you go to a model server and you say hey, i'd like to talk to you using version 2 please", then you'd need to be able to speak it in binary but the original protocol was text and so we can just play with that today, we can actually connect to a web server and get it to send us a page get it to send us some information and that brings us to page 2 alright, so let's do a little demo first we'll try this right, so let's try connecting to a machine i love the music right, here we go we'll do illinois.edu and I'm going to connect port 80, which is where web servers listen on great, we've connected right, so we've connected this machine and now, I can send something, so I'm going to type in get / HTTP/1.0 and we'll hit return twice okay, great! look at that, it actually understood what I said, and it sent back a whole load of stuff it said, oh look! this machine, this web server is serving using apache version 2.2.15 so if I was a hacker, I'd immediately type in apache 2.2.15 vulnerabilities" and tell us which version of SSL and OpenSSL great, I'll use those as a hack as well to discover if they've got any vulnerabilities it tells me when this page was last modified, so if I have to have a cache of this page on my local machine, I know that if my version is more recent than Friday that date, then 2012? my goodness then I can use my own version, right? and finally it tells me a little bit about what's there, so basically there's nothing there and it's in this particular memtype, this text/html so my web browser can use that to understand this content, and we know that we expect seventy-three bytes of content let me try a different machine let's try
so we'll get that and HTTP/1.0 okay, right! and I get a big chunk of text, including stuff that says Hey, maybe you want to use Javascript as well" alright, so I'm getting a little bit of text, of a script on that page and finally we see these tags down here, </body>, </html> is that part of the HTTP protocol? No! what is it? it's HTML! HTML is independent of our network protocol HTML is just a way to describe a webpage and of course you can save that on a file you can save it on a USB stick HTML is completely independent of HTTP, so HTTP is about talking to web servers HTML is about how to mark up web pages they are two different protocols so we've shown that I can use this little tele-command to talk to webservers and this number 80 here is a port number if you want to run things on port 80, you can't unless, you run it as root so, the lower port numbers port numbers 0, 1, up to 1023, require you to be an administrator on the machine which is great because you will have a virtual machine now, that you can root into you can do sudo, or you can log in as root, and you can then set up a web server on that machine on port 80  let's see what we're going to do today we're going to write some code that basically does this from C so we're going to connect to another machine so this is kind of what was enough for you to write half of Yik-Yak, if you'd like at least the client end here's some code I wrote earlier perfect timing and this is the beginnings then, of what network coding looks like now what we're actually going to create is something called a socket so a socket is a system object  not a C++ object, of course but just an object that represents the connection endpoint that we can send bytes into and get bytes back from so it's like a, think of it like a socket you can plug into it's going to be a way for us to communicate with remote servers and also weigh a socket's you can set options on a socket we're not going to do anything fancy today but how to identify sockets? easy just with a file descriptor so this will just be a small number and once we've done all this magic, we can just call read and write on this socket descriptor, and use it just like an open file so let's what we've got here i'm going discuss this amazing beast this didn't used to be inside CS 241 or any networking class, this is relatively a new addition: get address info, and it makes writing network code much, much easier it does so much for us, it sets a whole lot of C structures for us and it can be used in a variety of ways, we're going to look at one way today, which is to go from a host name that we understand a fully qualified name here, like www.illinois.edu" and turn that into an IP address a binary number so to use it we actually have to create a little struct notice the struct name is the same as the function getaddrinfo but in fact, there's going to be two structs we set one up as a kind of hints" structure, to say this is the kind of stuff that I'd like to know about and we get back a pointer to a different struct of the same type so that's why I have one called hints" and one called "Okay, yeah. I'm also going to need a pointer to one" so I'm not going to set up result, that was going to be set up for me and if you look down here, you'll see that we pass in not the pointer, but a pointer to that pointer because this function is going to mess with that pointer it's going to set that pointer to the completed information right so, what do we care about today?  well, I would like to have information for connecting with an IP version 4, so I want to make a connection yeah, yeah, just like 95% of the rest of the internet traffic using using version 4 and I want to use TCP and as we know, TCP is a stream, it's like a pipe and these constants are kind of hard to remember, don't panic in an exam I give you a crib sheet but also, just as a hint, notice that they always come in this variety where the AF corresponds to a hint for you about what things should this be connected with? so sock, for example, the kind of socket type is a prefix as to what this constant should be now these constants are just integers they're just there to make our code look more readable as opposed to hard-coding constants unfortunately, it can mean then that you can accidentally put the wrong constant into the wrong field, and the compiler won't complain your code simply won't work now, writing network code is hard because it's like going to McDonald's, where everybody inside working there hates you unless you specify everything exactly correctly nothing comes out the window at the ned like doing a drive-thru and trying to do it with an English accent I have a really hard time at McDonald's You want fries with that?", and I'll say something, it doesn't really matter what I say, and I never get fries so when new is desperately working trying to figure how to say  another fun thing with an English accent is the phone things, you know like say one" to "one" I never get anywhere so this is the fun of networking code is that you've got to specify things exactly and you've got to be on your tip-toes to make sure you haven't accidentally put the wrong constant in the wrong field because no one will tell you've made a mistake right, that's the first gotcha is give the right constants for the right fields the next gotcha at least for this code, is for the unused fields, we better set them to 0 and that's the purpose of this memset there's a whole load of things in this struct that I don't want to set and if I don't do this memset and this is just on the stack then as you know, the stack memory is arbitrary so make sure that you've set unused fields to 0
so this getaddrinfo() is  sort of a powerhouse of a call it does an awful lot of work behind the scenes including making a network connection, say hey! hey, anybody! anybody know who this is? www.illinois.edu? anybody got an ip address to this?" so what am i talking about? i'm talking about dns, and we'll talk more about dns a different time well that itself, but that call itself could be making network requests to say hey i need the ip address that's connected to this name" so the whole lot of stuff that happens behind the scenes just to discover the ip address right, so what does the ip address go into? it goes into one of these structs and where does the ip address actually appear? it actually appears inside here, this little [gibberish] here, this address, and this other thing called addrlen is set so why can address be different lengths? well, socket is an abstract idea, and it might have different kinds of sockets we might have an ip4 type socket, or we might have an ip6 kind of socket, or we might have an apple talk socket so these c structures are actually designed to be potentially different lengths, so when we call connect, we actually have to say and this is actually the size of my data structure" right, so so what have we got? we've got getaddrinfo() to fill out that socket information for me if we didn't have this, we'd be writing lots more code, and it's really ugly, it's got lots of casts in it the beautiful thing about this is we set up a hints thing, we say do we want ip4 or ip6, or we don't care, and we say say the socket stream, or we want UDP, and then we create a socket and we can connect to it and we're done! we're ready for action! right let's write some code then so connect will do the handshaking, so now we're going to actually use this thing  right, so i need to send it something, okay right, so what i'm going to send? here can be my request it'll say GET" homepage make that larger, here we go right get the home page, i'm going to speak http/1.0 to you, and i need to send it these newline characters to say that's the end of my request /r/n", if i wrote it twice okay, we could  for debugging let's just print this out okay and i'm going to write the minimum code that will kind of work, this is not robust quality code by any means that we'd used a real web server, or any other client but it's good enough for lecture demo today right, so how do we use write()? well, remember that you need to give it a file descriptor okay, that's what i got from the socket you need to give it a pointer to some bytes that we want to send okay, that was my request and i need the number of bytes, yes if right, even number of bytes so, could i say request? how many, what is the size of request? that's 4 bytes or 8 bytes? because it's a pointer, it's not - we didn't specify it as an array remember arrays, kind of like pointers, but they're not pointers if you ask for the size of a pointer, you get a size of a pointer, which is 4 bytes on a 32-bit machine, 8 bytes on a 64 we didn't want that we could've either made request a different type, we could've made it a character array, or we could just calculate it during runtime so let's do it during runtime so strlen(), give me the number of characters inside request i do not need to send the 0 byte the protocol is not about c-strings, it's the end of the line, the end of the request is to find in terms of these double newline characters, right so we send that  i could get the return value to see how many bytes were sent, but nah, it's a lecture right, so let's get back to response, okay, we need some space for that, so as this is just a quick demo, we'll just have some space on the stack here it gives to my response and  let's read from that socket right, sock_fd i need to give it a pointer to some space, some memory how many bytes do i want to read up to? we'll say 999 why 999? well, because if length is, get at least one thing we will print it out as a c-string, so i'm going to terminate it and finally, we'll print it out okay questions at this point? aha, it's easy! right? the file descriptor wasn't set once i called connect() i've connected! i am network man! anyway, so we've now got the power of the internet at our fingertips well at least all of the internet we can connect to using TCP right, so let me [gibberish] okay, we'll do illinois to begin with right, so we'll run this  what'll i call the code? [gibberish] alright, awesome [gibberish] ah! great, happy days right, so let's run awesome hey! look at that! we wrote some c code, we connected to another machine! this is what it's all about, this is what makes 241 so powerful, right? now we can actually talk to any  machine, and now i can run my machine, i can run this a hundred thousand times, and run a ddos attack on the internet don't do that because every server, of course, can log the ip address and log the content of what's being sent to it
now I actually have done attacks the difference was, was I had a nice, big legal agreement not from the janitor of the company well, from a C level executive i.e a CEO, a CTO, that kind of thing and I did this as part of a company, so I had liability protection, etc, etc, etc and I kind of knew what I was doing right so with great power comes great responsibility, and unfortunately, now, you are now treated as people that are no longer normal the justice systems hates you and they would love to see you put away for many, many years even for simple hacking, as defined by the newspapers right guess what? there's a log somewhere that says your peer address was used for x, okay that's good enough me!" send him to jail and he can work a dollar, or she can work for a dollar a year" splitting rocks, whatever probably not the ending to your university career that you're hoping for also yes, the server has logs, but there's routers in between that have logs as well, so it's relatively easy to discover where packets are coming from so if you must hack a system, here's a system i suggest you hack get in there and delete as many files as you want that of course is the ip address for your own machine, right? the packets never leave the machine, the kernel actually recognizes that as an ip address and we'll not even send that to the network hardware alright, so let's have a quick look at this response we saw that this http request includes the number 200 and little strings that says hey! okay!" how do you think we can generate a different number? you probably know one of these number already with a four right? 404, not found? that is part of the http protocol let's change our address oh, sorry, let's change this so we request a resource that doesn't exist we'll go aprilfoolsjokes.html see if there's anything about that, right? okay alright, so we'll let's compile this okay let's run our awesome client okay, what do we get this time? we got a different number, 404 so this is how your browser knows that this particular page does not exist, and it would render some blank content you could put some other stuff in there as well there are other definitions to say hey, this page has moved. please redirect to this other url, etc." so the http protocol species all of that right, let's take a break for a moment, and talk about the course couple of comments i hear that quite a few of your classes have given you, like lots of homework to finish and even exams this week, so no exam this week mondays in future weeks not too good yes, please expect, unless otherwise stated, that the in-lecture exams will be on mondays for cs 241, okay i will try to get out practice questions before that what else do i want to say? oh, yes, oh yes, right so the last thing i want to talk about today is some alternative ways to program first of all, yeah, you've probably now know about, kind of, vi and vim vi has a historical background to say, suppose you have a really slow connection" the beautiful thing about vi is that it tries to actually work even if you've got a pretty slow connection, and it has some cute tricks in it as well, so i think i've shown you this one, where we can say, change our current lines, so we can substitute, and if you know regular expressions, you can write regular expressions in here so, for example, we can change include" to "exclude"  right, that's a kind of simple one, right? i'm just changing it to exclude" let's undo that we can change a whole load of things, so for example, let's on all lines, substitute 'if' for 'while', and the 'g' just means, if there's one matchy thing on a line, then substitute it, so now i've got bad code, right? let's quit this without saving but i want to mention that that's not the only way to write code another way is to use the cat" command so you've seen cat" in terms of reading from a file, right? well, cat", if you don't specify anything, we'll just echo back what you've typed
right, so now we can do cat>hello.c so now we're going to pipe the output of cat into a file hello.c" so this all you need to program right? so now do #include <stdio.h> int main() { printf(hello\n"); return 0; } right, how do i finish? i have to tell my terminal that i don't have any more input, so i'm actually going to close now stdin how do i do that? by doing ctrl+d here we go and now i can compile my program hopefully, and if that gives me return value 0, then i also want to run it so there we go right so if you ever find yourself without any editor, don't worry, just use cat okay, right questions? no questions still no questions, okay right, have i shown you that the includes actually exist oh, here's a useful command, which" right so which" is, you'll probably use it next time you have java installed you say, okay, where's that?" alright? or where is my gcc installed?" and so which" looks along the path to discover where these commands actually are, so how's it do that? well it looks inside every directory including inside $PATH so next you install something you might want to edit this $PATH variable and you'll notice that the directories simply have a :" here on a linux machine simply have a :" between them and where can you edit that? well on a linux and mac, you can edit your  okay let's go to my home directory, which is like this little [gibberish] you can edit your bash oh, come on oh, that's why bash_profile, and you can define things and add additional things to your path, right? great! so, the next lecture, we'll start talking about TCP servers and UDP client-servers and i will get the interview questions out for thursday by the end of this evening! Have a great week, good luck with the MPs thank you very much! have a great week, good luck with the mp's
alright good morning class how are you  alright let's try again, good morning class how are you ok great so here's what we are gonna do for the last lecture we look to making a TCP client   we made a socket and we ask the socket to connect to a remote server we connected it to Illinois.edu and we connected it to BBC.com, this time this lecture what we are gonna now is to go to the other end of the equation and we are gonna make a TCP server, and I'm gonna walk you through the steps and some of the gotchas for that so we'll talk about some of the nitty bitty of the code and although we'll put it all together and ask you about the server ok sounds like a plan, ok let's get started before we do that, let's see how much you remember from last lecture alright so what do we need to do to set up a client TCP socket ok so here we go um so back in the mists of time get address info didn't really exist and we have to carefully setup a struct um but fortunately for us today, getaddressinfo does exist so the first thing we might do is um we'll use get address info, so how do we do that well we setup um a hint set up... the um.... addressinfo struct  and we'll setup the hints we'll copy this struct. another intended use for this getaddressinfo we are just gonna pass it into getaddressinfo and so here's the thing that we care about like we really want a stream based protocol hey we wanna use IP 4 or we wanna use IP 6 or we um or we don't care we'll use either but anyways we said about our struct like we are doing down here we said about we are configuring it um we could get address info to setup the real struct for us and then we can use it so now here's the um here's the main part write a socket call connect so in a sense making a client actually requires two calls get a socket and ask that socket to connect to something that's not quite true because we are using this getaddressinfo to help us make the connect call but this is the actual part, if we actually know exactly what we wanted to put set it to connect, we won't need to be calling getaddressinfo that's just a helper method for us actually it's just these two calls: hey i want a socket, and hey please connect to somewhere. please connect to BBC and here's the IP address. right alright so um last semester no, last lecture i lied to you just a little bit i said getaddressinfo returns a struct of these addressinfo objects. well that's kind of true actually, it returns a linkedlist of them so here's what happens, you say, look, in my hints i would like a certain kind of connection, like, i would like, say, IP 4, for example and i would like, say, a stream based port for, say, TCP getaddressinfo says, okay you wanna get this remote host, i will find all of the possible ways to set up a socket and connect to the remote host and return it to you and that's what we get, we get a whole lot of these addrinfoes now and for our little code inside CS 241, don't worry about that, just use the very first one that it gives back to you assuming of course that getaddressinfo gives us a success result code but if you are writing a more verbose server, you might say i wanna connect to the BBC and i don't care if you can find a good IP 4 connection or good IP 6 connection i know what i'll just try both alright so, in fact you get this linkedlist alright so what have we got inside this addrinfo  alright we've seen these um, this half up here which is kind of a description of what we want this is the stuff that we are probably gonna be using in our code later on and that is this structure here, sockaddr and also the number of bytes in that address so you'll be seeing us passing those addresss. so you'll be seeing us passing those two fields into our connect call and our bind calls in a little bit ok so watch out for these, so this is the stuff that is setting up for us so we don't need to set up ok alright so we got our addrinfos alright so how many addrinfoes does it return? 0, 1 or more? i promise you that we'll never return you a negative number OK um.  one little thing that you might notice on the code before which is that if getaddressinfo fails you can't use perror() or structerror no, it doesn't set error number like that it's got its own error error code that you could use to return an error and we'll look that up in a bit instead i wanna charge through this because I actually want to get to the demo today the demo is the most fun but so what is AF_INET6? what kind of address family is this it is, yes, IP 6 IP version 6. well we can talk about nodes we can talk about hosts, we can talk about machines using 128 bits of addressing in other words our address base is much larger alright so it's gonna take us a while to exhaust 2^128 possible addresses so IP version 6 was created because people foresaw the problem that hey we are starting to run out of addresses with IP version 4 so what do you think this might be I'll give you a clue there's no place like home this is how we talk about our localhost  using IP version 6. so if you want to hack yourself using IP version 6, this is the address you need to connect to there is actually a shorthand for this where we can collapse the longest ones and zeros and so there the shortest version of this is just ::1 i'm not gonna talk about all the rules about collapsing IP version 6 addresses you're welcome to look them up but i guarantee you that they won't be on the exams. the wikipedia references is perfectly good enough if you ever need to actually need to talk about IP version 6 addresses but that's the shortest IP address IP v 6 address. and yes this might be on the exam or this should become acknowledged that hey, this is yourself and this is localhost
okay so lets see if we can set this up then I'm going to start writing some code then to make a TCP conneciton so yes we need to setup one of these int objects and we'll have a pointer as well to get the result so what should i set for the family? well if i want to connect with version 4 I would be connecting with IF_INET6 if i want to do ip version 6 i would put a 6 in here and what about the socket Well we want a stream based protocol in other words TCP so for our socket type we specify socket stream if i had left these entries as zero we're basically saying hey we don't care and then we get back that linkedlist what are you connect to the BBC using the UDP using um datagrams you could connect using tcp and these would just be different entries in that linkedlist and then your code could try them all hey lets see if we can get a webpage over udp and the answer is actually quite a few webservers will do that they'll look at you strangely and go what do you want? but they will actually say okay I'll give you back some data as a single packet right so right we're going to fill this in ok so what do we put in here our function call of course is get address info and what do we pass over here well we need to pass in the hints and we need to pass in our reult okay, so lets see if your neighbor can first of all the mistakes i've just deliberately made in that code and also what are the two missing things that I need to fill in here what are the first two parameters so what mistakes did I make and what's missing in that code okay right so  couple a mistakes we made first of all actually we want the address of our hint struct so we'll put an ampersand there and also we want the address of this pointer it's going to change that pointer for us ok so what do we pass in here? well we pass in sometimes it's called the node but you can think of it as just basically the machine we want to connect to so we could write www.illinois.edu we could write www.bbc we could write we could say for example do ::1 if we wanted to connect to ourselves using IP6 we could write 127.0.0.1 if we wanted to connect to ourselves and we were using ip4 for here, i'm going to now specify the port and you can do this with two ways you can literally just write a string like 1234 but for well known ports like HTTP, HTTPs you can actually write the protocol name like HTTPS  if you happen to know the port number, yeah you could use that so get address info is surprisingly useful if you give it a ASCII name it will try to convert that to a port number for you so if it returns zero we've succeeded if it fails now we can actually find out why and that's where that function comes in  we could call gai_strerror and pass in that result code and that would give us back string okay now I'm not going to expect you to remember that, the string error but what you might do as a system programmer with this networking code and in fact any time you want to write good code is check the manpages so if we were to go to manpages is this going to work here we go alright we see that um okay i can take the return  if i now read the description and the return value of this it would tell me that hey this integer can be plugged into this call to give me a basic message about what went wrong and let's have a quick look down here to see the kind of things that can go wrong we have a bad family bad flags no data no name this call can fail in all sorts of ways we might fail at turning a name like bbc.com into an ip address okay but lets say it worked what do we do next well the first thing we might do is okay let's make a new socket now you seen in some of my earlier examples that i've made the socket at the very beginning of the code and i hardcoded in exactly what family and type of socket type I wanted but you could also just use the return values
there we go we've also go the information we need inside here to actually create the socket so if you expect you'll get address info to return maybe an IP6  maybe multiple kinds of different sockets then you'd be pulling that information out of that linkedlist each time so we've called socket and then we would try to connect to that remote host and let's say we've successfully got a connection hey great we're now talking to that machine right so this connect call is heavy it's big it's slow  it actually goes out there and connects it doesn't just like oh, connect please" it's "no make contact" send some packets to and from that machine so connect might take a second or more to complete might take a minute if you're remote server you're trying to connect to is a long way away so this is potentially very very slow how quickly you can talk to the remote machine if you're trying to talk to yourself that should be pretty fast so you could talk to yourself very quickly and discover if you can connect to a particular port there's one thing we didn't talk about yet and that is  this magic call called bind so usually we don't like to be bound up but today we're going to be calling bind on our socket we're going to take our socket and we're going to bind it to a particular local port we're gonna say hey! use this local port" now most of the time when you want to connect to a remote server you don't care where your packets leave from you don't care which port is used locally just let the operating system let the kernel choose the outgoing port but when we want to make a server typically we do care if I'm going to make a webserver I want it to be on port 80 so we can use bind if we want to set the  local port you could also use it if you've got say two network cards and you want to specifically use a particular network card but it controls the local side of the connection  which is exactly what we're going to need when we make a server  so if i tried to connect to your cellphone right now on a particular port i'd probably discover that it's not listening on that particular port that I was connect to connect would return back and say haha I'm sorry I've failed I've managed to send a packet and it said nothing  i didn't get anything back for your cellphone so connect fails what we ought to do in the server is the opposite we want to sit here and wait for people to come to us wait for packets to come to us wait for packets to come to our port what we want then is a passive connection not something that goes out and tries to connect but just sits there and says huh no let us the packets come to us we can do this and it's very very easy alright so a passive socket level one understanding is just hey it waits for connections to connect to it it's sitting on the key side of the particular port saying okay I'm on port 80 send your packets to me I'm ready and when they do I'm going to do something special right so what's a passive socket  first of all it's a socket that is listening  it's also known sometimes as a server socket because we use it for serving we just it for waiting for connections so it's passive in the sense that it's waiting for connections and it has a cute little trick  lets say I'm the client, you're the server can you catch? let's say you're the server right there you go that ladies and gentlemen is a dropped packet alright here that server wasn't listening okay fantastic right so I've sent my-k-I've just connected to the server on the passive socket now here's what the passive socket does when it returns the connection, when it does the handshake back to me thank you it sends an additional piece of information which is don't talk to me, don't talk to that port anymore I've got a new port set up just there that is the special connection that is just between you and me so we'll see that in a moment on the C side as well  we'll see that on the seaside, I like that so we'll see that in terms an additional file descriptor that's part of that handshaking once we make the connection on the server side, no no we have a completely different port just for that one connection why do we do that? well guess what we're making a server we're trying to take over the world or whatever and other people might be connecting to port 80 as soon as they do that they're going to be talking to you again so in order to keep all these connections separated we push them onto different ports alright so the time you actually spend talking to this particular port is minimal okay so why do we create one so we can have a server I want to make a server right so how do i do all this have I put this in yet no so here's what we should do  in our hints struct we're going to specify one more thing let's go back to here something we haven't used yet is this flags and there's a flag to say hey make a passive socket for me please trying to think if it's yeah must be uppercase right so before making your get address info call, just say oh, by the way, I would like a passive socket by the way i would like a passive socket
now if we were to run our code by the way I didn't talk about this little guy in here what did you think he's there for? right? this little tiny question mark is the ultimate april fools in the sense that this will get you every day of the year this is C going oh you mean you didn't set all of the parameters in a field? don't worry, I'll make your code work today but, if we don't set all the fields inside a struct, then who's to know what the values are of the ones that we didn't set now maybe you made it in global memory and you know that there's going to be zero but if we didn't if we just made it on the stack then who knows what those global fields are going to be and we're just giving them to the operating system so who knows how getaddressinfo is going to interpret those unset fields so I'm talking about these in terms of setting up network code but this is actually a common common gotcha with C is you hey I've got a struct, I'll set a few things and I forget to set the other fields so right how can I fix that? well I showed you before one way is to call memset okay so how about we do this? memset on the hints sizeof(hints) zero and I can relax that I've now got job security my code will work! haha april fools so what have I just done? I've just managed to set zero number of bytes to a small integer value in other words the memset call I just made had no effect whatsoever because I accidentally swapped these two values around I suggest that you ideally just don't make this mistake or don't make this mistake in production code because the worst thing about it is that you probably won't realize it, you probably won't notice it right? the memory half the time is zero and it's only when say you are reusing old stack memory that you might not get nonzero values so watch out, watch out anytime you work directly with memory that's the most likely time that you'll get some very subtle bugs right so we've got our thing set up getaddressinfo is returning zero, it's working, right so... here's what we can do now remember how I said... in a client we make a socket and then we call connect and we connect to a remote end in a server, we go socket and bind we're not trying to connect to a remote end at all we're just saying ha I just want to set up a local socket here that doesn't connect to anything, it's just going to sit there and listen and all the parameters that we pass to connect to the same ones as bind so we're going to be passing in... these two again, this address and that length of that struct we'll see the real code in a moment but basically we've swapped our connect for a bind because we want to talk about not a remote endpoint but a local endpoint right... so at this point we'll just take a little bit of a break to mention these guys and also to kind of show you what the code might look like if you didn't have getaddressinfo so when setting up a socket one of the things we want to talk about then is the port address and the IP address and you'll notice if you do a lot of google searching on code, you'll quickly come across these functions here this htonl and htons here's what they do, they swap bytes around sometimes they swap bytes if you run this on an x86 intel machine why? why do you think we might want to swap the ordering of bytes? security? good idea but not the answer I was looking for endianness yes! so endianness why do we care about endianness well the point is we're sending information over the wire right? we're sending stuff out to the network, we don't want it to depend on the order with which we represent integers so if we're talking about a particular port number that's sixteen bits we better agree when we send the packet out on the network as to whether we want to put the low byte first or the upper byte first so network order is big endian and that should be independent of our machine so if the kernel says by the way, this remote host is connected to you on this particular port or here's this ip addresses we better be careful, these integers may not actually be the integers that we normally understand we may actually have to deliberately read that value with the bytes swapped so that's where these functions come in if you happen to compiling this code on a little endian machine big endian machine, they don't do anything, they are a no op they don't need to swap any bytes if you call them on an intel machine however, they give you the result with the bytes correctly swapped from big endian order to little endian order
vice versa so what do they stand for? they stand for host to network short and network to host short [silence] so here's an example where we want to specify the port as port 1100 notice how I chose a port greater than 1024  and I want to set it directly into this structure here socket address and so I have to remember to actually set this up to be the network the network port number so this port number is actually going to be passed directly into the network card we're going to assemble the packet and that packet will have these bytes in now the correct order to say okay [something] on this particular port you can use these inside your own code let's say you wanted to have a high performance server and you're not going to send ascii information, you actually want to send binary information and you want to send say the position of your players to all of the other, you want to cast it out to all of the order players on your game server you would have to decide on your protocol to say am I going to send this out in little endian or big endian format and you could use these kinds of calls to make sure that it doesn't matter whether your C code is compiling on an ARM platform an Intel platform that we always on the network are sending bytes out in the same order same endianness  alright so that's just a little aside, you'll see these codes and now you know what they do and here's the other one where you use it for a long so you can use it for 32 bits right so okay right so it's quite often said that setting up a server takes four cores we better say what they are and it's a common exam question or interview question to say what's the order of these? and what does each one do? right so the first one is easy, hey we need a socket you're not going to get very far without a socket we need a way to configure our network and a socket gives us back a file descriptor that we can then start to use once we've got that file descriptor we want to bind it to a local port let's bind it so we are now going to be on a particular local part and we set it up, we pass it now actually we're ready to go here's the nice thing that we can do with server sockets we can ask the kernel to do that little handoff trick and to start queuing up any connections so now we can start listening at that moment... we're live! our kernel is starting to actually accept connections for us and we'll generate a small queue of incoming connections that we can now start to process so with listen, we actually specify the queue size so as part of that little handoff process when we say oh actually go and reconnect to me next time on this other port number now the kernel has taken that and said okay by the way expect connections on this other port number, so internally its got a little queue when we want it from our user's side, we call... yes I'm prepared to accept this reverse call accept! so on the server side, when you call accept, you get... a new file descriptor okay so here's a big gotcha is that you've now actually got two file descriptors to play with if you want to be talking to your clients that are connecting this is one you get a new file descriptor each time accept returns also, this blocks until we have a client if your code is a bit slow in calling accept don't panic, that's why we called listen listen says look uhh my user code may not be able to call it except immediately so have a little backlog of connections that the kernel will maintain and hopefully I'll be able to call accept in the future so its very simple code, very simple server we can just call accept once, and that's it and that's what we'll do in a demo in a moment later can call accept in the loop to process one client at a time probably not going to be the best webserver in the world but hey it works and we can run that on some tiny embedded hardware later we might do things like hey let's for every accept call start a new thread and then everybody can talk to my server in parallel well that works until a thousand people try to connect and then you have a thousand threads that start on a machine with 8 CPUs that's probably going to work out so great so then we need to start figuring out even better ways to have a high performance server but anyways that's our four calls, socket, bind, listen and accept alright let's see this in action ooh look code!
Here we go! I'm going just hard code my, my constants. Like I said, we could have got this back from the address info. Today, I want to play with IP4, I want a TTP connection. There's my flags, those other flags you can set them here by bit-wise or-ing them. But we want a uh... a server, or passive connection. Yes, I remembered to set all my other unused fields to zero. Right. Yes, I'm going to call getaddrinfo. Check the result code; if it fails, I'll turn that into a useful error message. It's really really useful if your code doesn't work to actually check error messages by the way. Okay, so. We got a socket call, we got a bind let's connect to a local port. And look at this! I'm using the stuff I got from my getaddrinfo. I'm passing in that point of that struct and the size of that struct. okay, that's my set up: socket bind. Now, we start to say, Ooh!" Um, please start listening and have a little backlog of ten connections. Okay. So, just for fun, I want to show you that I can say, I'm just doing a particular port. If I reach into one of these low-level C structures, I better remember to reverse the right order to turn it into from network to host (ntohs) and use the result of that call. And now we're going to have our little server. This server code didn't actually send anything back to the client. It just listens to hear what the client has got to say. How do we do that? We call accept. Later on if we wanted to have to fill in the structure, like where the client was connecting from. We wanted their own IP address we can fill out these structures here. And remember how I said accept returns a new client? Here it is! Here is a new file descriptor (fd), and I'm going to use that on my read call and then turn it into a C string and print out what they said. Okay So, let's uh, let's run this. Hmm. *bzzzzzzzzzzzz* Okie dokie, alright, so there's no error checking in this last part, um, alright. So I can... clear this right gcc ./server1 (./server1.c). Okay! Alright Oh, look at that! That's my OSX is saying do you want to accept it? Wait! And it chose file descriptor 3, is this your port 1234? Shall we connect to it? Okay, alright. So, let's do this um, now I could write some C code, but instead I want to show you a pretty useful tool. It's called netcat. Here is netcat. Blah blah blah, blah blah, blah blah blah, blah blah blah. Look it's like cat, except you can connect to an arbitrary machine, using an arbitrary protocol. And anything we sent this, it will use standard in and standard out. So today, I want to connect to 127.0.0.1, my local host, and I want to connect to port 1234. So our code is working! The accept call has returned.  And it has given back our new file descriptor. Right, should we send something to it! Yes, okay here we go. HELLO GET / HTTP/1928349q87eyfaiu7tbeiqvwfa SAfuigae And here we go. So, it got that from the socket and printed that and stopped. This is the most useless web server in the world because it accepts one request then quits. Very easy to make a denial of service (DOS) on this particular web server. So what we'll do is make it so it cannot accept multiple clients. We're not going to do any threading code in this (we could though!). Right as soon as accept returns, why don't we make a new thread and pass it on. Instead, we'll just put this little part inside a loop. Alright so a while there. Okay, so we put this accept call inside a loop Make another connection, and so on and so on. So we got the basics now of a little web server. What we have to do now is figure out how we are going to pause this. what do we want to do with this information, and what do we want to send back to the client? Alright, so in fact what we've made is something a bit like a honey pot. For example, here's why it's called a honey pot.Take a jar of honey, open it, and see what insects are there after a minute or an hour. We can do this with our server. We can get it to simply listen on a particular port and see who connects and say capture the IP address. Or we can pretend to masquarade to build a real machine. Oh look! people are trying to log into this let's see what kind of pass let's see what password they typed in. We can see what kind of attacks they do to our machines. So, on many modern networks now we have these machines which appear to be real machines, but which are infact are simple honey pots. This is the simplest kind, right? Where we can simply log the connection attempts, who they're from, and what information is sent to us.
Alright, another thing we're going to finish today is epoll. So I suggest for a simple server, hey, just uh, just little while loop. The next simple server is: hey make a thread so at least we can do this with uh multiple threads so that I can be servicing two clients at the same time.threads so Well, these kinds of ideas work until now you have hundreds or thousands of clients connected to it at the same time. And um, a bit of history is that we used to have a core called select" you'll find in everywhere (works in a mac), but these days, epoll is a common solution to a hyperbolic server; in fact, you'll get to play with that this section. And what epoll will ask you to do is with sockets or pipes, and you'll get to play with pipes. You can say, Actually, there's a whole load of file descriptors that I'm interested in." And so, the basic outline of epoll is: you make, we make a set you'll create, and then, using a control function we add a whole load of file descriptors, a whole load of file descriptors. You say you'd want to read or write to these. What's your intent? And then you can wait--wait for an event. That's the basic idea. So actually now, I can have a single thread waiting on a thousand clients. If my clients don't talk to me very much, when one of them does, I can immediately find out which one. ...because epoll call will tell me, Hey! By the way, now you have to talk to this particular file descriptor, now you need to be talking to this particular file descriptor." The old way of using select: will select allow me to go to sleep once something is happening; but once select returns, I'd have to kind of go through every single file descriptor. I'd have to do a linear search to find out which file descriptor was the one that I need to process. So, that would be in session this week with epoll, and the other section thing we hope to do with sections tomorrow is to connect some class 7 code on the tablets as well. With that, have a wonderful week! Good luck with the MPs! I'll see you on Friday <3
alright good afternoon class now so today we have quite a few pretentives in the orders if you traveled here because you ... cs 241 but ur just visiting the class today please just wave your hand i know theres quite a few of you right these people I invited just been accpeted to cs major program or they are visiting campus so be sure to be nice to them and tell them what a great place wisconsin is so here's what we are going to do today we are going to finish our discussion about sockets uhh in terms of .. what we can do is we use imports, and  what happens if is my mic on yet what happens if we dont set various socket options when we are developing our programs and we discover that the port is in use and that kind of stuff and then we talk about how can we make the server actually discover who is connected to us so we can find out for example its ip address so yesterday you made yik yak, or at least use a very simple version of yik yak, where we connect to our virtual machines on the android tablet and now that we want to make it so that our server can actually find out who connected it a little story for you that is the very first time i visited urbana champaign was I was visiting wolfram research they're just down the road, you may have heard of them they made methametica i did some 3d visualization software which connected to wolfram using sockets they connected to mathematica using sockets and this is back in the day when we actually made a plugin  an external piece of software to display 3 dimensional shapes so i was talking to them and back in the older days of the web, before blogs and they said, you know, one trick what we do, about our web server, is we got various competitors right now and we dont want them to know immediately when we release our product so when they come to our website, we check their ip address of the connection and we serve them the old content so our competitors see our content at least two days old so they'll be a bit slow in discovering when we actually release new software so that's something you can play with with the yik yak implementation  that give bad inforamtion if you don't like the client connecting to your server hey, give them something, give them some alternative information ok so how can you do that? easy! look at, say, the ip address, the bytes they sending to you you could invent a new protocal all messages to you should have a hash value which should start with a colon etc. etc. etc and why not share your protocol with your friends at cs 241 so that you can connect to each others' virtual machines and why not tell some bad information to the people you dont like in cs 241 and then you can tell them when the exam's on when they re not alright  so lets go out for our handout for today uhh we need i can ... some content today alright what's the honey pot easy! a place for honey! remember this? we can make servers that masquarade as real machines  and then uhh see how they've been used on internet for example, what you see in todays lecture is how can we discover what client is connecting to our server so we can label those ip addresses you could for example on your virtual machine have a port 80 open up  and see if anybody tries to connect to your machine okay so what are the purpose of these calls, htons and ntohs?  what do they do? yes host to network and network to host why do we need this? well because if we gonna be transfer bytes to each other we should agree on what order we should send the bytes for example if we are talking about an integer of two bytes long, we are sending the low byte or the high byte first and our cpu may not respect that perticular ordering and in fact if you on a intel machine it is actually the wrong order ok so we can use these to make sure that any integer values we send as binary are correctly ordered, that we put them in the right order for either working in our cpu or sending out on the wire we send it to the network card ok so its time for host to network short, network to host, short so we'd use this, for example, when working with port numbers umm port numbers are 16 bits ok so what are the four calls with the network server we've done this already remember our basic idea is we want to make a socket we'll say what kind of socket right then well call bind because we want to bind to a particular local port we may also use it to bind to a particular network card so weve made actual socket now so how do we get started we call listen all of these things will happen very quickly the next one will block, and that is when we call accept accept now will block if there is no one trying to connect to our server.  so it only returns when a client has actually connected.  why do we call listen? because we may want to set up a small queue so that if multiple clients connects together, the operating system is prepared to look after those immediate connections until we get them from accept and each time you accept, you get a new file descriptor and each time the client connects, it gets a new port to talk to alright so we've seen that now one thing i didnt talk about before was freeaddrinfo yes we've been playing with getaddrinfo to fill in a pointer to that struct  and remember that struct actually could be a linked list so when we finished using it rather than having to walk through the linked list ourselves there happens to be something called freeaddrinfo that does this for us and of course that is going to pull out the next pointer before calling free on each struct so what do you think might be wrong with this little piece of code here? you can assume that inside the dot dot dot i've called memset on hints and i set up the hints struct correctly  umm but what do you think mistake i might have made in writing this little bit of code make a pointer, called getaddrinfo, and then I called this function called free to say  ok, free that linkedlist that getaddrinfo set up for me what could possibly go wrong? yes? oh should i pass the address actually no freeaddrinfo takes a pointer to the first struct and go through destructively and frees up each member of the list  okay time to put your, yes thank you yes right so, remember we need to ask ourselves what could possibly go wrong ok here's one possibility  suppose getaddrinfo failed for example, you haven't actually connected to the wifi so it cant do the domain name lookup and find ip address so suppose getaddrinfo fails that means it never changed this pointer 
so what is result pointing to? could be anything right? we just made this little thing on the stack its just whatever happened to be at the stack memory at that moment so we just called free on a arbitrary block of memory whoops our program is probably gonna crash at this point but its certainly probably vulnerable to other attacks at this point ok so how should we fix this? well here's what i would do i will probably set this to null to begin with and let me check, I'll only called this if the result has been changed so if its not equal to null then call freeaddrinfo that's a more robust program right port hijacking so i love this i want to dress up as a highway man as a pirate yes! there's a potential for port hijacking when we write our server programs imagine this, imagine you write a fantastic web server or another program that uses sockets to communicate and then your program finishes, perhaps it crashes at that precise moment, another process starts listening to the same port mua hahaha... and it gets some bytes that were intended for yoyu well this is a security risk we should prevent this, right we should prevent another process from immediately starting up and so that actually led to a socket rule where if you claimed a particular port, another process can't immediately reuse it if that process belongs to another user, we have a longer time out let's actually see this as a little demo and then we'll say what we can do uhh ... where is it... alright... so ok, right, good i have a program here. so now let's run my little server here ok so gcc server1.c alright, so here's a little program we service for where we waiting on accept waiting for connection right, so let me connect to this. i'll start a new window,  and is today i'll use nightcat , so nc localhost 1234  okay, we've connected. Yes! it's good! so I can send something over here let me at this point quit my program, i'll make a few changes, and i'll run it again.  oops. bind failed address already in use.  I couldn't reuse that port so that port for little while is still being bound to that old process even though the old process is quit, we couldn't immediately reuse it.  okay, so what can we do as developers? uh we like to be able to reuse our programs so i'll test it quickly [gibberish] it's okay I can reuse my port 1234 again so what options is to use hey, dont develop too fast but no we can do a bit better than that we can actually disable this security feature by setting an option on the sockets so lets see how we can do that hello ... just trying to connect to my machine right, my machine. so let's see what we can do here and there's a little option called setsocketopt where, make this larger, where ... on my server socket, i can say i wanna be able to reuse the port in the future so if you set this option on the port, that this when your process dies, or quits, another process can immediately reuse the same port okay. some odd syntax. we are gonna see this in a bit more examples.  of this.  is that youll see that we have to , in this case, pass in the address of the integer value, and then the size of an int so we are gonna see this passing a couple time today when we pass in the addresses of something and size of the thing that we are trying to pass in but thats just a bit kind of useful line of code that youll be using in one of the later mps one of the mps that we've got lined up for you is called wearable's mp, where we are going to simulate having a whole load of devices talking to, say, a server, so you might have to watch, you might have a pace maker, you might have a, i dont know, hair, that talks to your server  and this is the single ... connecting and constantly talking to your server which collects your data, maybe collecting your blood pressure, and a whole load of your vital signs so  we want a server when we developing these stuff we wanna be able to quickly reuse ports, so here's the option to do that okay, so let's make a note of this how do i do this? if we start our programs and we use the same port, easy, we gonna use setsockopt and the magic ... is this SO_REUSEPORT thing which should be in the wikibook. If not, I would add it and notice we do this before we call bind so we do this early on just after creating this socket set this option on on the socket right so we've played with very very simple kind of server, now you wanna do more.  right? this is uiuc, this is illinois of, university of illinois, we wanna go up to eleven. we don't wanna have just a single connection to a single client we actually want to write servers that can talk to thousands of clients at a time how can we do that? well, a long time ago, we realized that i dont want to always block on my read call waiting for my client to send me something, it would be nice to find out which client is coming talking to me has sent me some bytes so, the idea of select was born okay, right, so the very first implementation to attempt to making performance servers is to use the system call, is called select probably about 5 minutes after someone designed select, we discovered it wasn't any good. 
it was good enough at the beginning for the first four minutes but here's the problem with select you have to do an order N scan after it returns to find out which file descriptor you should be talking to you should be calling well that means an order N like up to say 1000 system calls and that in itself takes time, it's going to take milliseconds of time to say or should i be talking to this one, should i check... so select was a first pass, the great thing about select is that you'll find it everywhere if you want to write code on say simple embedded devices on windows, on mac, hey! just use select and don't worry about performance, it's good enough and it's easy to write code which times out so you can say okay I'd like to wait for say a second to see if the client sends me anything so select is a reasonable choice at that point so what happened next... is a system call called poll is defined that solved some problems, but today what we played with and what you've seen in lab is epoll the only downside of epoll or the main downside of epoll is that it's on linux but not mac not BSD so now you're stuck right? what should I use? select? poll? eopll? etc so epoll is performant, it's great for if you have a thousand long lived connections so it's ideal if you've got thousands of long lived connections so this is your yik yak server now a single machine can support thousands if not more connections, epoll would be a very good choice and as you saw, the way we used epoll is we set up a set and we just add file descriptors to that set and then we say okay now I'm prepared to wait, I'm prepared to block until I'm able to read from at least one of these and then when it returns it tells me which file descriptor I should use so for CS241, yeah we can play with epoll in the MPs and should you ever find yourself in a startup or fortune 500 company that wants to write a server, let's see that's probably every single fortune 500 company these days or just about most startups have some sort of client server architecture you might come down to which one of these should I use? just remember that there's actually three different versions here's some other thoughts on your server though which is.. sorry of you startup... is that why don't you do what chromium does, the browser that you found inside your android phone or chrome if you've downloaded as an app it uses the library called libevent and libevent basically wraps these three things so it provides an abstraction on top of the system calls now we're not going to use libevent in any exams, this is just an FYI it's that next time you want to do your startup, check out libevent because then you can write code that runs anywhere and it just provides implementation underneath that talks to select, poll or epoll to get the best possible performance on each platform so I've been throwing a lot of information at you very quickly today, any questions at this point? okay I've got a bit of news for you I understand its passover this weekend so I'm going to ask the TAs to push the deadline for the MP back to Monday night 11:59 pm okay so one minute before midnight on Monday is there not an MP that's due.. somebody sent me an email saying hey I need an extension so I'm going to ask the TAs to make sure there's no deadlines on this weekend okay if there are two deadlines this weekend ok well I push the one on Sunday onto Monday if you do not observe passover, you may still take advantage of this if you feel it's unfair to have two deadlines the same evening feel free to submit the first one just on Sunday night and then pretend that the extension hasn't been given I'm also asking the TAs to try to provide more verbose information about the MP merge by the way, the MP merge tester runs on a VM just like yours so it's probably a good idea to check your VM code on you personal virtual machine okay right so any quick questions? okay right let's jump into some other kind of little bits of know how then so we've been making servers that listen on a particular port if you're just doing development, you may not care which port your server listens on you'll just say hey give me any port that's currently unused here's how we can do this first of all when you call getaddressinfo if we're setting up a server, obviously we want to talk about localhost, that's NULL and just say I want port zero which is another way to say hey I'll be happy with any port well now we've got a problem though, we need to find out which port number we're actually listening on here's how we do this, there's something called getsockname sock of course stands for socket as opposed to things you wear on your feat this code kind of looks a little bit like the code you might have been writing before getaddressinfo existed we have these different structs for example... there's this sockaddr in which you can think of as a version or as a subclass of this other struct but because C doesn't support [something] we can't say hey this extends this other struct we have to forcibly typecast it and so there's all sorts of interesting gotchas, any days that you forcibly type stuff you might forget for example to put in the ampersand here so there's all sorts of gotchas I'm not going to ask this on an exam, I'm just pointing out, if you want to develop code that listens on any port, this is the way to do it you call getsockname on your socket and now we from that struct we can figure out which port there's just one little gotcha here if we try to use this value directly.. hahaha oooooooh we're going to be in a world of pain why?
one important thing we have to do to this particular value if we want to know the port number okay let's go back to the beginning of the lecture dodododo hello everybody welcome to Friday and don't forget what do you think htons means? network to host means? remember those little functions? yeah these C structures are the C structures to do with hey the bytes that we're trying to send to the network card the port number that is represented inside this struct is not really an integer like we like to think of it like an integer that's on our CPU so if we actually want the value of this entry, we've got to convert it so don't forget to call... network to host short ntohs and that will give us back an integer value that is actually the integer of the port so next time you hate your lab partner, just walk over and delete that code and watch them try to connect to the wrong port for the rest of the discussion section right so that's a little gotcha there, no one will tell you that you've forgotten to convert your integer to the right value other than the fact that you'll be trying to connect to the incorrect port the other thing you might want to do is find out who is connecting to your server here's how we can do that, remember this accept call, the thing that blocks waiting for a client to connect remember how it gives us back a new file descriptor? well we can now pass in a pointer to a struct very similar code here hey I've got this C structure, please fill it in and if you do that, it will tell you information about the remote client it won't tell you their login name but we can find out things like their IP address and their port number so for example, if you didn't like the remote client, why don't you send a thousand packets back to them and try and shut down their machine and send them a denial of service no don't do that for real unless you happen to be the US government okay so we've got that information and we now want to print something out here's how we can do it you can say okay turn this number to an ASCII value and that will turn it into an IP4 address like 127.0.0.1 we can see that and also with the port number, oh look here we go again, don't forget to convert that struct entry into a real number and then we'll print it out okay so let's see that as a demo okie dokie so I'll go to server2 let's see if this works okay right right so I've got my code now, it just picks an arbitrary port number that is available and let me try connecting to that well actually why don't you see if you can connect to that if anyone's got their laptop open you can telnet to 172.17.248.187 and see if someone connects to that port number okay fantastic right and I got your address so now I can telnet back to you for example right let's see if you're running anything on port 22 no you're not, okay so I can't try and hack into your machine today alright so that's in what you need for the next MP and to make your next multibillion dollar startup company of course this stuff underpins webservers, it underpins a little company called youtube, you might have heard of it, it started by an undergraduate here it started, well, what are we in siebel center networking, this is what it's all about, being able to connect multiple machines together and we've seen the basic socket calls that do all of this so for the remaining part of the lecture, let's say goodbye to networking and talk about a different systems programming topic are you ready? right, page 2! okay so today a couple of quick comments yes we have a quiz on monday it's going to be topics that we haven't talked about for a while remember virtual memory? do you remember page tables? translation look aside buffer? no? okay well don't worry now will be a good time to learn I will send a practice quiz in the near future remember pipes? do you remember how to use fseek, ftell, fpause? and finally we got the dining philosophers concurrent problem and also the reader writer concurrency problem so they'll be in it too okay so expect that quiz on Monday in lecture any questions? alright then so let's talk about a new topic scheduling! you already know as a student a lot about scheduling probably the scheduling algorithm that you're most familiar with is called earliest deadline first yes? right? my chemistry home is due and its due in 10 minutes oh no! okay so this is a problem of just how efficient can we be? can we use our CPU resources and other system resources to get as much work done as possible? well it turns out of course that earliest deadline first isn't actually the most efficient algorithm because we might spend a lot of time flipping from one piece of work to another piece of work and so we actually have addition latency involved with these context switches and with scheduling all of this work so for example, if you find yourself constantly updating your calendar to say oh I'm going to do this work here and this work here you've chosen an inefficient scheduling algorithm
so this is a non-trivial problem. we got things we wanna run inside our machine which are very urgent we got say mouse movements to update, things on screen to change we've got things are not so urgent but requires a lot of cpu a lot of disk so this will like batch jobs where we dont necessarily need them to be quite so responsive, but we want to schedule them so that they finish within a certain amount of time so these basic questions lead to a very large amount of mathematical analysis and experimental analysis as we try different scheduling algorithms and we try to find ways to make our system have a highest performance as possible and this is non-trivial, and if you get it wrong, people dont like you programs, say, hey, this java thing sucks or hey this machine is no good for processing audio. i keep getting dropouts because my process isnt given enough cpu time when i need it or hey my scheduler just crashed my car because it didnt give enough cpu time to the neural network that decides whether to turn left or right so scheduling turns out to be a critical part of the system i'm going to look at it in terms of three different scheduling algorithms,  and also, just to give you an introduction to some of the terms of how we might actually compare different schedulers alright so lets define a few terms first of all, turn around time what is 5+11? 16 see, those about 2 second delay, when I ask the question, when i demanded the response, the completion of the work, and you actually give me the complete response thats turnaround time the time between when someone says hey, heres your chemistry homework, and you actually finish it.  ok, thats turnaround time, theres pretty obvious meaning, theres nothing special about it waiting time, so well define this as the total time that a job is able to run but is not schuduled in other words, if you got your chemistry homework, hey give me another subject.  anybody have other, what homework do you have right now? stats ok, heres this stats homework, right, its on your desk, its ready to go, but you dont get to it because you are inside a cs 241 lecture ok, theres part of waiting time of this job, of this homework later you do some of it, but then you decide to go out with lunch with you dog or something. so again, this is more waiting time for this job. so if we want to compare between different scheduling algorithms, like the lunch first scheduling algorithm, as apposed to chemis right, we can talk about the total amount of waiting time this homework is done we can exclude tho, the time you actually writing on this so honestly the waiting time we'd like to be as small as possible  right, what about the response time? okay so heres a little difference between response time and turnaround time remember, the turnaround was basically the difference between the end and when you actually first submited it when you first knew about that homework the responsible time, is the time to the very first response so if it was your chemistry homework, it might be ok, you dont submit the whole thing yet, just submit the answer to the question 1a.  so you dont need to finish it, you just need to start producing or showing some output from your job. so if you going to run a very long job, we dont care when you actually finish it, we care about  when you actually starts it, able to give its first response.  first result so thats just a little gocha response time is not the whole time, its the time required to generate the first output then we might care about throughput throughput is the number of homeworks that you can do each week, no you dont care about that, okay fair enough throughput we care about the number of jobs that we can complete. if your system was always swapping between bit of this hw, bit of that homework, your brain get so fried by thursday you say huh, if we get this I'm going to choose an easier major, right umm so your throughput will go down you haven't chose a good scheduling algorithm so throughput we care about the number of jobs we complete in some unit of time latency we can define as the overhead of our scheduler that leads to delays or additional overhead of this scheduler that slows down our ability to actually do useful work and then starvation right, starvation on your chemistry homework will probably get you an F on your chemistry homework  how could we get starvation? how could a scheduler generate a starvation you forget about the job ok yes thats not a very good scheduler  i dont do homework, ok what else? thank you! ya! so you always do your cs241 homework and you never do your chemistry homework or your stats homework so if you have a priority system when you  always do high priority stuff or you only do the homework you like, or you always do the easiest hoemwork the shortest homework that very project that is due for the woodworking 101 is never gonna get done
so yes you can see starvation with this systems so we gonna look at these terms and we are going to umm analyze different schedulers right, so here's a few common schedulers and next week on wednesday we are going to look at these in detail and run some examples through them fcfs, right, when i call it fcfs because in literature we see these things so commonly shortened because its a bit of mouthful first come first served so this is the mcdonalds scheduler you arrive first, i serve you first. its a queue, right its a simple queue. you put your homeworks in the order that they arrive.  is that a good thing? uhh it depends, we gonna have to think about whether these schedulers good for batched jobs or for our responsive needs because we actually have our user that wants to see progress on their work so we have first come first served in other words , its just a queue right, the next scheduling algorithm, its fantastic, here it is shortest job first now, we can use this, we can analyze our scheduler mathematically in practice you might run into a bit of problem if you try to actually implement shortest job first. whats the problem? yeah, how do you know? so what you need to do is go out and buy a crystal ball and become clairvoyant and steals some tacheons from physics lab, and simply know in the future, how long your job is going to run now ok some specialized circumstances, you might be able to do that. for example, if you ran exactly the same program yesterday, and you are running the same code, with the same kind of data today, you can be pretty confident that your job is gonna take two hours to run but in a general system that is not true. we dont know how long our jobs gonna run but we can still at least analyze this. if we have some fake data, say, job1 takes 10 minutes to complete, or 2 hours to complete, we can still do some analysis. so shortest job first in practice ... [cant hear] difficult to implement because you dont know how long it is right ahh haa, this is the pirate one, its the round robin now this might sound like a kind of quaint english thing and we dance around and jib with some medieval music  that would be an incorrect answer round robin, heres the idea, is that all of you are important, so im gonna spend a bit of time with each of you alright i set my clock, i talk to you a minute, and bye i talk to you a minute, and bye, i talk to you a minute, and bye, now of course i'm the cpu, right, we are talking about the cpu giving resource to each of these jobs, so imagine like if i got all of these homework, all of these stuff that my cpu can be doing, i'm going through all of these processes, and they got the cpu for a minute, and lets say, you're the last job, yes well we gonna go around again ok so you can see if this say for fun all of these jobs has three minutes worth of cpu to complete,  ok none of them complete within three mintues, ok i'm gonna keep going through. these got a little slot of time, so thats why we call it round robin. now it turns out that this homework, half way through, has some problem on it that cant be completed, without additional information from the professor so the cpu say, you're blocked, you're waiting on a semaphore, you're waiting on a callback function that, so i'll skip you. you are not actually runnable at this point so our scheduler only needs to run jobs which are not blocked.  so for example, if you just wrote you server code and your calling accept, we dont need to spend any cpu time on that process. its blocked, theres nothing for it to compute.  anyway, thats round robin so the idea is that we have a little piece of time and you get it and you get the cpu for certain amount of time of course it might be that if i give you thirty seconds, hey you're done already nothing more for you to do. you've finished copying data to the disk, you just called accept, you just called mutex lock and you're waiting for it to finish.  so your process might give up the cpu before you minute is up before you time quantum expires, but if you dont, ha, too bad for you, i'm taking the cpu away from you, and i'm assigning it to a different process so your little process is now stuck in time that homework is half finished because the cpu is now working on a different job.  right, preemptive scheduling. ok, this is easy, if our jobs, if our task have different priorities, hey, system programs is really important to me, and i'm going to get this done before anything else, then we can use that as a scheduling decision so lets go back to round robin for a moment, and say how long should our time quantum to be? all that tradeoffs ok, lets turn that into a homework problem again. suppose that we work on this problem for ten seconds, and then this homework for 10 seconds, and then this homework with 10 seconds, and then this homework has 10 seconds  what's the disadvantage? yes?  thank you! i'm doing a lot of context switch. I'm going to spend a lot of time, actual woke up time, real time, just switching one problem to the next problem so much so and now i've introduced some latency into the system, so much so that um my throughput is no longer good, its because actual cpu time is burned is spent doing all these context switches okay, so lets go to the other extreme than. I'm going to work on this homework for a day and then i'm going to work on another homework for another day and the next day, so i've made my time quantum very very large now
what's wrong with that? ok, if a process runs forever, or one homework is really hard, you taking cs 473, you think 241 is hard, ha! wait till you take 473 right, or take 373. anyway, the three hundred class, now, the i may not get to some short jobs quickly, right? if this job over here is just Hey, send all those email, they reply, you can have to wait a long time, even though it's gonna take a minute for you to complete this job, i've got a very slow quantum so those are two extremes, I got one way where i got to introduce a lot of overhead, because of the context switch, another, where short jobs are now waiting for a very very long time, to be accessed so what do we do? on a real system. on, say a laptop, or on your linux. where for starters i'm gonna talk about linux just a sec because linux has actually got something better we gotta choose an appropriate quantum and you will see times, typical times of ten to hendred milliseconds in other words, a little hardware clock goes of says, hey, your time's up and interrupts the cpu, and kernel gets involved and say hey, time to move onto a different job" why do you think we chose ten to a hundred milliseconds its empirical. yes, so in what factors, what factors influence that decision ok we got a lot of things running in parallel, we've got interactive jobs, you typing on a terminal, for example, and as you type, you want the letters to appear. if we context switch, if we go off to a different problem, many times a second, you won't know. people won't know that they are sharing the cpu with multiple jobs right? you could be logging into a server, or you could be typing in a terminal, and it looks like hey, the system is mine" the cpu is all mine to play with, and if we keep swapping it around fast enough, no one except for the people taking cs241 will know no one will know that actually we keep swapping the cpu  so that's the first idea to why we choose to this kind of time which is its not so short that we have a lot of overhead, but its short enough so that our system appears to be responsive when we interact with it these days you might see even faster times as well right, and finally, what does linux do today, it uses something called ... oops ... a completely fair scheduler ok some comments about this, one is, huh, there is no such things as someone could be completely fair.  you ask any two-year-old alternatively, it's completely fair for some definition of completely fair  final thing is, this scheduler was actually stolen from network theory.  the ideas behind it were generated by understanding how to schedule packets on the network  and that's what we talked about it today with that, thank you very much. have a wonderful weekend, i will see you on monday for the next mini exam! thank you very much. Come down to see me if you have any questions
Ok, class welcome class to CS 241 First announcement Yes, CS 241 is a lot of work but you may have noticed there are seniors still walking around in this building They survived CS 241 and you can too Why not get a T shirt Yes I appreciate its a lot of work But this is what kind of sets you apart from other students in other universities By the end of this course you really are going to know your stuff  And you really are going to change the world Ok so here's what we're going to do today We're going to talk about scheduling We're going to look at some simple different ideas about how to do different schedules And similar effects it has on things like the waiting time And exactly when each schedule is is uh uh exactly when each process is scheduled Right so let's have a look at this and in a moment I'm going to ask you to calculate this So as this is a model of - we're going to uhm be clairvoyant - we we we know when as a design we know when our processes are going to be ready to run And uh we've got four processes, we've labelled them one two three four We can say hey process four doesn't exist at the beginning or it's not ready to run Perhaps it's waiting on a condition variable, the process is waiting for some data to revive But anyway we don't need to consider it in the very beginning of our model here Uhm and then these different processes have different amounts of execution time they need in order to complete So for example in process one takes thirty milliseconds So we're going to look at our little simulation in ten millisecond blocks and see which process is using the CPU for each block of time Now here's our different scheduling approaches we've got Okay We've got something called round robin So with round robin what we do is we try to be fair and say Well you can have the CPU for a certain block of time In this little example, 10 milliseconds And after 10 milliseconds the alarm goes off Ding! A little hardware clock goes off And that causes an interrupt the interrupt then causes the CPU to execute some code inside the kernel The code inside the kernel says AHA you're out of time And now I'm going to give the CPU to a different process So the idea is we're going to do this every 10 milliseconds Uh we'll try to be fair So this means that if there's a long running job It shouldn't matter too much since after two milliseconds we're going to give the CPU to someone else And they get a chance to execute Okay so that's round robin We'll work that out in a moment And you'll notice in this little example I've actually got three processes All ready to go at the very beginning So what we'll say is the order in which they ask if you're ready Is just dependent on how we've written them done So process 1 we're going to run before process 2 et cetera et cetera et cetera  And then the next we're going to calculate is shortest job first Meaning we actually know in advance these timings And we give this to the operating system To the scheduler So it can decide when to run them A I gotcha here" is remember you can't actually run process 4 at the beginning of time because it doesn't exist yet It only comes into play, it only enters the stage after 10 milliseconds Alright so that's not a choice at the very beginning And then we have first come first serve This is just a simple queue Whoever arrives first gets to eat first And they continue to eat, to use the CPU until they are finished So it doesn't matter how long they take So that's first come first serve, FCFS That sounds pretty fair to me but we'll see if there's a problem with it later Now we can make these a little more complicated We can talk about how to preemptive shortest job first And the idea here is if a new job arrives In other words appears on stage ready to go Then if it's shorter we'll run that instead Now, one thing to look out for shortest job does not mean remaining time It means the actual original specified time So if you've only got ten milliseconds to run on a thirty milliseconds job  It still compares thirty milliseconds Not the remaining time, it's the actual total time When we talk about shortest job first And then the other variant is preemptive priority where instead of thinking about the execution time  We have some sort of priority assigned to each process So for example if this was controlling a lunar lander Controlling the rockets is probably more important than say running the -inaudible- activity right now We need to make sure that we make immediate course corrections So uh, in this, we've got higher value equals a higher priority And if a higher priority job arrives on the scene Ready to go Then we will give the CPU immediately to that job So that's the process we're going to run in a moment Let's go back to these questions So when might a process be in the ready queue Let's think about processes you've programming, you've written Why might it be in a ready state? Not running on the CPU But in a ready state What could have happened? Yes! Okay so there's more than one process who wants to run And someone else has currently got the CPU Give me something that might have happened to your process That makes the mediates become ready Ok, thank you. It's waiting for say disk IO, or say network IO Perhaps you've called read Perhaps you've called accept And now you're waiting for a client to connect to your web server To your chat server To your database server That thread of execution cannot run yet until the operating system says Okay, yes! I've got your data, off you go Okay What else? No ideas? Yes! Let's say you call sleep and your process sleeps for five seconds After five seconds your operating system says Oh, okay, right, fine Time to wake this process up I'll let this process continue, I'll let that thread continue Similarly if you had a call with a timeout Alright, there's going to be time when your processor stops A zombie is not ready to run A zombie can't run, it's finished It's still taking up space in memory Inside the processor control block because we have things like it's exit status
Yep Okay so a thread has called condition wait Is not yet ready to run but if someone then broadcasts it It goes into the ready state So if we wanted we could draw a state diagram that says Look our processes can be in these different state It could have been just started, it be running on the CPU, it could be in this ready state And once it's in the ready state it's up to the kernel who gets to play and when And that's what this scheduling is all about Alright so we can define something called wait time And uh I can write a little formula for it Where's my notes Oh yeah So the wait time is the total amount of time spent in the ready state Waiting to run So uh if we know the completion time and the start time That gives us the beginning and end Some of that time was spent actually doing useful stuff Actually executing So if we subtract that stuff we can actually discover how much time our process was unable to continue, it was in the wait state So I can say that the total wait is the uhm completion time so Time, the actual wall clock time when we finished Minus when the process first arrived Minus - so that gives us the time interval And the other time we can subtract is the time we spent executing So the duration that we spent executing So if we subtract off those two We get a certain amount of wait time That might be useful in calculating the wait time in these examples So it's not the first uh time that we have to wait because a process might go back into the waiting state For example If a process with a higher priority and you are running a priority based scheduler Your process might be pulled away from the CPU and the CPU is assigned to someone else To a different process Okay, so we've done that So it's not the first waiting time It's the total waiting time Okay so just occasionally, maybe in these examples I haven't calculated them today You have a tie break For example your process might be ready to run again after round robin And a new process arrives on the scene ready to go Which one should you use Well we need some sort of tie break decision And in which case we might to choose the job that arrived the earliest on the scene So now we want the earliest job to complete So let's see if any of these examples require that tie break situation Okay soooooooo Here's five little examples I'll get started and then you get the next one So let's look at this round robin So round robin remember It's like a little song, each person gets to sing a little bit So process 1 gets to use the CPU for the first 10 milliseconds But then our hardware interrupt goes off and the kernel says HAHA not for you anymore And then process 2 has been waiting Also process 4 arrives on the scene But we're going to schedule process 2 because it was there first Alright 10 milliseconds later we switch our process 2 and process 3 gets to use the CPU Another 10 milliseconds later our hardware clock goes off And finally process 4 gets to play And guess what happens next? We go around again! So process 1 and then process 2 Now at this point process 2 is finished It's used its 20 milliseconds up It's finished calculating whatever it needed to calculated Then it's 3 Process 4 you're already done  So we're back to process 1 So now we could calculate the wait time and if we wish the average wait time So for process 1 how long was it waiting? I could count that 1 2 3 4 5 It was waiting 50 milliseconds And process 2, it had to wait uhm, 1 2 3 4 - another 40 milliseconds Process 3, from my notes, looks like fifty And process 4 will be uh thirty milliseconds So I can add that up to get the total wait time and then divide by the number of processes to get an average Okay So that was me working through another example Now it's your time to play 20 milliseconds? Oh quote possibly yesI'm sorry, oh quite possibly,  Because yeah it arrived at 10 milliseconds So it had uhm to wait in additional 20 milliseconds before being scheduled I think Right so Perhaps its not obvious but these are the end times of each block So this one goes from 10 to 20 and then 20 to 30, et cetera et cetera et cetera  Okay Right Sooooo Now is your chance to get cozy with these different scheduling algorithms And to run through these little examples It shouldn't take you very long Any questions? Okay, have a go.
Okay so with the shortest job first We're not interrupting the existing jobs So even though process 4 arrives and is ready to go And is 10 milliseconds We let jobs run to completion Alright so 4 before here has to wait an extra 10 milliseconds before it can run There is no preemption Okay that's what we're going to do down here When we do preemptive shortest job first When we actually take the CPU away from a process In the preemptive version yes we start with P2 But then P4 arrives on the scene, the new kid on the block Alright and so P4, off you go P4 runs to completion and now P2 can be scheduled back It beats P3, it arrived earlier And then P3 runs And then finally P1 has been waiting all of this time and it gets to run Alright K First come first served Couldn't be easier, right It just simply write down the order in which we wrote them down here No brain power required whatsoever And then the last version we are going to look down here is preemptive priority Yep It's not about the remaining time  It's about the total time of the job It's not remaining shortest job It's about the total So don't do any subtraction stuff It's a common gotcha Alright so and the priority in this example saying a higher priority number is more important So process 4 is the highest priority but it's not around at the beginning of time Instead process 3 gets to run And then it gets interrupted Process 4 comes along and says I need the CPU and I need it more than you So process 4 finishes so we go back to process 3  Process 3 finishes And then we go back to process 2 Process 2 finishes And finally process 1 So we could calculate some wait times This one is 160 over 40 That gives us an average wait time of 40 milliseconds Shortest job first: the average wait time turns out to be 20 milliseconds First come first served: average wait time 37.5 ms Preemptive shortest job is 22.5 ms The last one is also 22.5 ms Alright so we don't care that much about the figures But what we do care about the following Firstly there is a difference in ordering And yes this was just a paper and pencil exercise But it kind of shows you depending on how much you care about a particular job You might be in the ready queue for a long time, you might be waiting for a long time Secondly we have a clear winner here The shortest job first minimizes the wait time in this example And uh in general as well And if you think about that, that kind of makes sense The long running job and I put that first, all of my other processes are going to have to wait for that length of time Therefore I should put the very longest job at the very end of my queue  And I can just prove that recursively therefore that my average wait time must be minimal if I put my shortest jobs at the beginning of the queue And I order them by total execution time So if my idea of fairness, if my idea of an optimal system, was just in terms of how long my processes have to wait Then I would choose shortest job first There's a problem with that of course First of all we'd actually have to know how long our processes really do run for And that might call for a crystal ball Or at least an assumption about how my processes work today are exactly the same as how they worked yesterday And that's kind of stretching it about with real systems Our preemptive schedulers worked pretty well Of course they're more complicated We're going to have to write a kernel who is prepared to switch out a process and save it someway so that we can preempt and pull it out And replace it And our round robin actually has the worst wait time even though it was going to be pretty fair though we thought it was going to be*
So what about this? We've heard about starvation before where a process never gets to complete it's uh, it never gets to make any significant progress. Which scheduler could lead to starvation and how? Maybe there's more than one correct answer. Don't tell me know; tell your neighbors and see if you agree. Okay, so uh, a student has let me know that my calculations are suspect so I probably am off by a quarter millisecond or so. So I apologize for that. Silly  numerical error. Okay so which ones can suffer from starvation? The second fourth and fifth. Shortest job first, yeah, so if you're getting text messages continuously you might never get to your chemistry homework. So next time you don't fill out your chemistry homework, or CS 241 HW, keep sending yourself text messages. They're nice and short, you'll do them straight away. So shortest job first; we can set up a starvation by keep making short jobs and we'd never get to the long job. The other possibility is pre-emptive shortest job first. So again uhm I would never get to my long job if I keep submitting short jobs. And preemptive priority. Same idea If I keep having an urgent thing to do I might never get to schedule my low priority items Is there a problem? Yeah. We have to choose a tradeoff. We have to decide what we mean by fair. So which schedulers are appropriate for batch jobs? Of course the answer is It depends! By batch jobs we mean aren't interactive which are typically run for long periods of time without user interaction. They have all the data they want to process Maybe stuff out of files or network Do some analysis on that data So we might care about say earliest job finishing first or shortest job finishing first in which case we might choose a shortest job first scheduler We might care about seeing the results of all of our jobs And we are prepared to wait so we might choose round robin Uhm The other possibility is to, in a real system Suppose your job crashes or runs forever, has an infinite loop If there is no preemption if we don't forcibly remove that job from the CPU everything gets backed up So we have to careful if we're not going to preemptive running jobs Right So there isn't a simple answer for this batch jobs It depends on what your criteria are So what scheduler does Linux use? I mentioned it last lecture Yes! The completely fair scheduler. Which is a little bit of an oversell Alright so it's not completely fair But it is similar to round robin where we are prepared to interrupt a process Every 10 milliseconds or so But we're prepared to give an extended period of time to jobs which don't use all of their time quantum So for interactive programs, desktop programs, UI programs These tend to have very bursty needs of the CPU  Like OH QUICK the user touched something OH QUICK I need to read data on disk And they won't use it for 10 milliseconds They will only require a tiny bit of CPU Processing before we end up say sending it an event to the system Update the screen And we're done And we wait for the next user event So the completely fair scheduler says we'll remember that these processes didn't require a lot of CPU in the past So we'll prepare to give it a little bit of extended CPU in the immediate future So we'll try to make the system as responsible as possible K here's a classic problem in scheduling It's known as the convoy effect And we see this with the first come first served Scheduler And you can imagine a real system where I've got jobs which are very strongly CPU bound And other jobs other processes which are IO bound And if you branch in the queue going this way by first come first serve I might have a big job which comes I illustrate by drawing it a large size It's going to take a lot of CPU time to run And behind it I've got loads of little jobs which They don't take much CPU but they take some IO to do And then the classic description of the convoy effect Is we imagine this process uses the CPU for a long time Then just a little bit of IO And then repeats And here's the problem. These are the processes that start after this CPU heavy process They can't use the disk Or the IO They only need a tiny amount of CPU It's like going to McDonalds to grab some little ketchup packets or something And someone there is taking all the space I just need a little ketchup packet" I'M SORRY WAIT YOUR TURN" And so we have poor use of uh IO CPU usage is great. it uses the CPU 100% of the time Very efficient But these other jobs are stuck and uh So our disk utilization is pretty poor We could have had a better choice if we used something like round robin Where we let these little jobs jump in and let them use the CPU for small amounts of time And then they can actually get on with their disk IO Right The questions about threads I mean uh scheduling
Okay so we talk about this classically in terms of processes What a thread really is just a thread of execution Uh everything we've talked about processes applies to threads And uh you can actually set the uh scheduling if you wish uh in the pthread library And so for example there's a pthread call that allows you to say hey I want to use round robin scheduler Or hey I want to use first come first served So it's possible to set that as you create each thread Bear in mind If you set them first come first served Be careful because if a thread never finishes All the other threads wait forever wait an infinite amount of time Because we did first come first serve and you are at the front of the queue And you're saying Hah I'm going to take up this server forever MUAHAHAHAAH So that's just a little gotcha if you truly try to set the scheduling policy Uh so another quick tidbit there's this little command called nice People would like their commands to be nice So what you can do is Linux changed the priority of your process by nice-ing it And uh mere mortals, non root people, can increase their priority number which decreases their priority Which makes it less important And so you can say Okay I have a long running job Its going to take a lot of CPU But only run if there's nothing else to do In which case you might call nice As part of that If you are root you can nice the other way You can actually make things more important and higher priority But you probably won't need nice unless you're trying to run uh background computational jobs And try to make it so they don't interfere with your UI So that's enough about scheduling Let's have a look at page tables So we've been playing a lot with TCP packets And uhm most of the internet uses TCP However uh we did mention there's another thing called UDP Which is packet based It's not a stream We simply send our telegraph or datagram off and hope it gets to the other side Let's have a quick look how we could make a UDP server And see how it's different from a TCP server Okay so uhm if we want to fill up a UDP server Listen on a particular port We'll set up our hints as usual Oh good we've set it to zero And today we want to use IPv6 128 bit addressing So how do we specify that Well for our family we don't want address family INET We want INET6 for our socket  We don't want sockstream We're not trying to make a streaming interface here We just want to send these little datagrams So we have SOCK_DGRAM And we want to listen on a port We don't want to actually send something anywhere We're trying to make a passive socket So for our flags here I need AI_PASSIVE Okay so we set this up We can call get address info as usual I don't need to connect anywhere I want to connect to port 300 And we'll get our result Let's assume that works So well check the return value of this Here's how we can set things up It just takes two calls Yes we need to make a socket as usual Remember that represents our kernel object The thing that is going to talk about our ability to the outside world And we pass in everything we get from our result object Note the hints Yes we want to continue to a particular port So we need to call bind on that socket But then that's it There's no queue to make There's no exec to do We just wait for packets to appear How do I do that? I call recvfrom And when you do this Not only can you get the data that someone set you So let's pass in a buffer and how big our buffer is You can also find out who sent it So that's the purpose of this structure here And we pass in the size of this structure as the last argument
So what are these UDP packets look like? So here's the specification of UDP It's this little diagram here And there's really not much to it It's the UDP format I got a source port, destination port So each of those is 16 bits I've got the length here, also 16 bits a checksum which is optional for IPv4 And the data that someone wants to send me So that was the original spec So it looks like we could have packet sizes up to 2^16 Because that's the number of bits that our length is In practice that may not be true The spec actually says the minimum supported is 500 bytes And in practice most routers will happily send packets up to 1500bytes Which by the time you add the overhead of the UDP and IP fragment  It means that UDP packets are limited to about 1472 bytes So try sending a packet greater than that on a classic network Good luck How do you know it didn't work? This is the sound of silence You get NOTHING You send stuff out It goes nowhere There's a router in the middle that says I SEE YOUR PACKET I SPIT ON IT I EAT YOUR PACKET FOR LUNCH Right So There's two little problems right It's great for sending small amounts of information An amusing anecdote here is IPv6 has since designed jumbo packets Which can be up to 4GB in size I mention this because I find this amusing because right now  Most of the infrastructure spits on anything bigger than 1472 bytes And we've got spec that allows up to 4G Good luck getting that packet to go anywhere Maybe by the time you graduate we'll see jumbo packets floating around on the internet But the spec is there It's probably going to take a generation of electrical failures before we upgrade enough of the infrastructure before jumbo packets truly work You might be able to get it to work on your local subnet On your local router If you buy some very modern hardware But these days currently  UDP in practice Yes that's about the maximum size you send a packet So where is UDP actually used? You will see UDP packets for DNS domain name service So when you type in something like HEY I want to go to the host which say its bbc.com Somebody somewhere needs to know how to translate this address to an IPv4 or IPv6 address And the person The service Who knows how to do this is DNS Which cached this information So there's a whole hierarchical structure of servers that can convert hostnames and addresses to their relevant IP numbers To do this your machine sends out UDP packets And it may send out to 2 or 3 different DNS servers They might say Hey Im in a rush here And quick I need to know Who has the answer? So that's why we use DNS A single packet, if it gets lost, it doesn't matter I'm going to ask someone else as well If it times out I'll just send it again It's a simple kind of QUICK I NEED THIS and hopefully I'll get the response back as fast as possible Much faster than opening up a TCP connection So DNS traffic uses UDP Let's compare this with TCP So the TCP packets are much more uh complicated Here they are There's some similarities You'll notice that we've got a port number From the source and the destination Why do you think we need the source port? I'm sending you a packet to your server Why should I send you my source port? So you can respond So look there's multiple packets going out of different ports on my server all of the time When the other socket at the other end wants to send back some information it needs to know which port to send it to So  the source port is important because we'll need that for the destination We've also got a sequence number. Remember What does TCP try to do ? It tries to hide the fact that we're sending packets across We've kind of turned this into a stream But packets might get lost It might get duplicated So our trick is to keep track of the total number of bytes that we've successively sent in each direction So we'll mark each packet with where we are in the stream So we have a sequence number It represents the actual number of bytes that have been transferred in this direction so far So this means if we lose some packets The other end can say HEY I lost you. I lost you at this point  Can you resend starting from here? And that's part of the acknowledgement number The other end of our connection can say I hear you I've got your message so far up to this point in the stream Right
In the beginning Uh TCP could just uh back in the early days of ARPANET our sequence numbers could just start from zero Today however They don't Initially when we start the connection we actually start it with a random number So we have a 32bit random number which is our initial sequence number Why do you think that might be? Security Otherwise somebody could send some data to whoever we're talking to And if they chose the sequence number correctly They could insert some data into our stream By making it harder to guess what sequence number we're on we can make our approach a little bit more robust So it uh it's random Now with each packet we send There's various flags we can set This is not a networking class So we're not going to go into detail with what these mean But we will mention this That packets can be labelled with these little flags And the first packet you send has this little label that says the SYN-ful packet  And the receiver, the server, says THANK you! I acknowledge your SYN-ful ness. Yes Right so imagine you had a jigsaw puzzle A 1 dimensional jigsaw puzzle Much easier than a 2 dimensional jigsaw puzzle And each piece arrives with a sequence number This makes it really easy to put together That's the purpose of the sequence number if they arrive out of order, if you have any missing pieces You actually know where to put it inside your data stream You might get - a quick question It'll lap around Oh yes You couldn't send more than 4gb in a packet Yes the sequence number actually represents the data It's not just a count of the packets It represents the contents, it represents the data stream And what the bytes that you've put inside the packet where they should be fitted into inside the stream Right so you might have a packet that says OKAY I'm sequence 10 here's my data blah blah blah And there's another packet that might before or after that says I'm sequence number 20 and here's my data blah blah blah And the operating system says thank you very much I can see that the data stream that I should give back to my process should have the blue data first and the black data after  it So I might be able to reassemble the data back into a stream of data to send to the program No there's no limit Talk to me afterwards These numbers can lap around This is just a long stream And uh data was arriving from here in packets And the user is calling read so we're giving the data as the user process wants it But these numbers can just wrap around modulo 4gb Alright so So this is the connection handshake That we see between the server and the client So the client says HEY I want to connect to you And here's my SYN-ful number My sequence number The server says okay I've ignored your sequence number Here's mine So this is the client saying hello This is the server saying hello back And this is the client says I acknowledge your sequence number as well With that third packet we can also include some data So we'll see that again in the future And you see these diagrams in network classes where the client tells the server The server responds And the client responds again So we have this three way handshake But this takes time  They're governed by the speed of light*? They're governed by the hardware They're governed by the routers in the way YES Quick question Okay so The server and client nomenclature, those words, are really only important for the initiation of the connection After that both sides can play Both sides have sequence numbers Both sides send acknowledgement packets Both sides control congestion Etc etc etc There is no longer a kind of master slave relation Both have equal footing So we'll finish with this that So one thing we'll try to prevent again is something called a SYN flood Which is an attack on TCP Where we try to send a server a whole load of packets with these synchronization messages Initiation messages We walk up and say HEY I'm SYN-ful here's my number And the server replies back and is now waiting for the response So it's very cheap to send these You can just fire a packet Whereas the server now has to set up a connection And it's like okay I'm waiting for the handshake So it's an attempt to do a denial of service on a server And with that we're out of time So thank you very much And I'll see you friday
alright good afternoon everybody and welcome to friday yay so here we go heres what were going to do today is were going to talk about file systems and how files are represented but I also wanted to let you know about a cool new project that we're getting started and I'd like you to be part of it so I apologize for the spam but here's why I think its really cool wouldn't it be nice if you could go back to a lecture and say uh yeah uhh what was he saying when he talked about this term or that term which lecture was it in when the instructor or lecturer mentioned x y z so thats the idea is so can we transcribe lectures recorded lectures and then make subtitles? for people with strong english accents like myself? and for searching as well so for example remember those 241 videos that I made for the beginning of the course? supposed you wanted to find all the lectures where I mentioned printf() so we can kind of google search it and in real time find it oh yeah thats the one I wanted and you click on this and  my machine seems to be a bit slow today probably because its friday and off it goes and uh we can review the concepts so we've done that now for those mini videos and now I want to do that for 241 content and then we're going to take over the world the plan is to make it successful in this course and then say to the college why don't we do this for other courses as well inside the collge I'm already trying to make ways to prepare the lectures to say hey you know your course is recorded hey you could do so much more. lets make it successful inside 241 first so heres the plan we take a one hour video and we divide it into chunks short say 7 minute chunks and then you just take a short amount of time to type it in there is a second pass where you take those phrases someone else has done and you make sure they're lined up to the right part of the video its very easy work and we think it might might actually improve your grade because you're spending time on tasks because you're actually reviewing the content so thats the idea thats the promise lets see if it happens so please consider signing up and to help uh feel good about doing this um myself and another professor from Beckman we're going to throw in 50 dollars of our own cash each time so we have 100 dollars each time and we'll have a little lottery for each person for the people who are actually helping to do this so there's a small chance reward maybe you should use the 100 dollars to buy more lottery tickets and upscale it onto a million we'll see right so anyway thats that and i'm afraid those rewards are only available to cs 241 students at this time okay so thats class transcribe lets make this big lets make it big enough that we can crowdsource this and make it so that it actually even works for other universities as well okay right so back to today's content oops I had an overhead right class here's what were going to do I'm going to ask you now with a neighbor or imaginary friend of your choice to come up with some design goals for what you would like to see in a file system so you won't be the first person to invent their own file system. its been done done by times before but what are your criteria? what would you like to put inside your file system? supposed we said oh your senior project is to make new filesystem how should we measure it? what are the high level designs don't give me implementation details like oh I want to hash everything. I want to cache it. No. Give me some high level things What are your kind of selling points What are your requirements for what makes a good file system so take 5 to 10 minutes with a neighbor or imaginary friend and write down some of those criteria [people writing down the criteria] okay [someone talking in background] ok so lets make a list! what ideas it says pick  no lets not pick lets have some volunteers what ideas what are our design goals then shoot give me one yes you want it hiearchical  you just want me try to spell that word. ok alright so we want it hierarchical, what else? [someone talking] ok. we efficiently use our storage space so we might need to keep a map of which areas we're using and which areas we're not using ok what else
ok what about security  you want it so that uh not everyone that has access to the storage system can just leisurely access all files  we want to have some kind of access control  ok  what else you want metadata okay  what do you mean by meta data  ok so metadata like when was it uhh when was it last modified or its size  okay  what else ok what are we allowed to do with the file  are we allowed to read it  write it  execute it? eat it? the new edible file system  what else? yes okay you want to be able to do efficient searches  so that if i have a certain text file or video file umm it'd be nice if it just did my transcriptions automatically right? so find all the video files where printf() is mentioned  what else? yes  support things llike symbolic links  you said  symbolically  what you mean by that?  so you want files pointing to other files  the file you wanted is not found but don't worry  just keep following go over there have a look other there  it says haha you look over there  right  yes we want to be able to somehow symbolically say this file exists exists  perhaps in two place sat the same time  okay  right  lets uh have a look at uh some of the other things that we've got down here  right so  there are some other things that we didn't talk about like umm  you might also want versioning i want to get back in time  you know my users just accidentally deleted everything  oops  what do we say  well we get out and say you get a new job or we could say dont worry my file system supports uhh some sort of history and i can actually get back old files  maybe i want to kind of support some kind of backup  i want to be able to keep my filesystem actually running actually continue to use it as i continue to take a copy of it offsite umm and i want to be able to do that efficiently  encryption  so this is similar to uhh access control but you can imagine what would happen if someone got hold of your flash drive right now or your usb key right now  could they read the files off it? yeah  okay you can say to that little flash drive  okay give me all the bytes in disk block 0  disk block 1 disk block 2  ha  and you probably could read most of the data  even if we had set up the data to have access control  if we can actually directly access the bytes  if its not encrypted, we can read the actual data  so we might want encryption as a native part of this  what about compression? maybe our filesystem should automatically try to compress data  so that it can efficiently use our space  you can imagine for example with text that you uhh could do a great better job of compressing test so that it occupies a smaller amount of storage space  because we want great performance so that might affect how we organize our disk our contents on the disk  we probably want our disk blocks of the same file to be pretty close to each other  we want to be able to read and write and create new files as fast as possible  and some areas you might see is deduplication  so if you and i are storing the same files why should we be using multiple disk blocks? multiple storage space? perhaps we should do something clever behind the scenes and say oh actually uhh these files look exactly the same  at least for these parts of it  so we reuse this disk block but don't tell the user  we'll do this kind of behind the scenes  we'll make it a native part of the file system  alright so the things I've mentioned here are some of the advanced features that most filesystems don't support  for example deduplication sounds great, but very few file systems support it  heres something we didn't talk about  why? because probably you're cs majors you're not uhh ece people  we just assume that the hardware kind of works 99 point 99% of the time right  ha ha ha ha ha   not good enough right  we need to be able to assume things go wrong and we don't want to suddenly our entire filesystem  hey you know that thesis you worked on  no even better hey you know everyone's thesis that uhh ok  so theres a story about a another department  im not going to say which university it is in  that didn't keep backups running  they thought they were running  they weren't running  and uhh  when they want to use the backup  they discovered all the files were 5 years old so we want to make sure our file systems are as robust as possible and can cope with failures and tell us hopefully in advance when the hardware is failing  ok  so these are big design goals and actually creating a file system is difficult  and uhh we are not going to make file systems in 241 however we're going to look at uhh simple linux file system called ex2 which is the predecessor for  ex3 and more recently ex4   oh thats exciting isnt it  so we're going to look at some of the early features of ex2 to see how it represents files on a disk  before we do that  let's step outside of our high level features and actually look at how we can actually talk about files  well here's uh one idea im sure you probably already know is I give a filename like hello.txt thats relative to the current directory of my process  i can uhh specify an absolute path by starting my path with a forward slash here  so for example i could do /home/angrave/hello.txt and now i've fully qualified it  so it doesn't matter what the current directory is
i can write relative paths using the following uh uh special directory names  what does single dot mean? means the current directory  so what does two dots mean? the parent directory  go up one  go up to the previous directory  what about three dots  nah that doesn't mean anything  I just put that in there as a joke  alright don't do 3 dots  you could probably actually make a file with those 3 dots if you wanted and really confuse people  ok so yes  we can talk about relative directories  so for example if you wanted to go up three directories you could write  .... / .. / and then we could keep going and so we could do  ./ that doesnt do anything that just says ok stay inside the same directory and then go up to another into current directory x then go into directory y then go back out so now were back inside directory x etc etc so you could come up with these convoluted paths and its up to the operating system to follow the money if you like  to follow these to identify which directory you actually wanted to end up in  ok  so we've talked about relative paths  we've got an example of a relative path  perhaps you could simplify this one ok so what does this say? you start from the current directory  go into a  go into b  go up one  ok so we've left b we're back into a  now go into c  now go into the same directory  so the directory that we are currently in is just a c  and you could put an ending slash on the back if you wanted to or not questions? yes! haha okay so why is it that we do  ./a.out? and the answer is because of your path environment variable  so you've been writing code  we've written code with exec() and theres a version of exec thats got a p on it that says look for the filename on the following path so if you were to write hey run a file called a.out  it would look in all the directories specified in the path for something for a.out and guess what your current directory is not on that list  probably for security reasons  it is unusual to just run some artitrary file on the current directory  you could change your path so the current directory is on there  you could say okay my path is now $path and heres another directory the $path is just a string right  and so if i did that i wouldn't need to the dot forward to run something out of my current directory  questions?  okay  so heres what we're going to do  we're going to take our secondary storage  our disk  whether its a flash disk  and we're going to conceptually think of it in terms of blocks  and so the lowest level i can say to my my hardware  hey get me block #7 get me block #8 and a little white later, the contents of that will appear in some memory that I've requested it in so why do you think we make these the same size as our memory pages?  why is not not an arbitrary values like 1300 bytes or something? yes okay lets go back to thinking about virtual memory for a moment  what did we want to do with virtual memory when our memory is uhh when our memory is being used by alot of processes and we need more space  what do we do? we take a page of memory and copy it out to the disk  when we want to load our programs in  we're loading them in at a page at a time into memory  so most of our operations to disk are page based and we and so our disk blocks are are they are the amount that we move to and from disk is always going to be some multiple of our memory pages  so yeah we'll look at it today in terms of making them exactly the same size  right  so some of the calculations we've done for virtual memory are very similar to what we will see when we look at the file system  right so we talked about some of our high level ideas for a file system  what about then our files  what would we want to store for each file  we had some meta information such as uh the length of the file  uhh when it was last modified what else would you like to see  what other information should we store for each file? ok  take a couple of minutes to write down a list so we got one of modified we have some other timings as well  I had a few things like  when it was created  ok  what else? ok a file type
okay what else? ok so read, write, execute in other words what kind of access you can do  can you read it write it execute it  eat it smell it sniff it? yeah  who owns it  ok  what else? yes  ok who modified it last  what else? last opened? ok  when last opened  might be useful say for backing up things  or optimizing where things are on the disk  what else? hm? path ok ok  yes  hahah yes name  yeah would you like file #7 or file #8  i don't know which one is which  ok anything else  yes  ok whether its kind of binary or text  alright anything else  ok version  alright i'll add one more which is um where  how to get the actual contents  we probably want the contents of the time  we didn't actually talk about it  we talked about all this great meta information  we didn't talk about the fact that yeah all that has some contents as well  so we probably need to store exactly how to go do the disk  which disk blocks being used to actually hold the contents of the file  it'd be a pretty silly file system if we couldn't actually store any content with it right so actually what we've described here is this basic idea of an information node or an inode that we'll find again and again in various kinds of file systems  so we've described alot of meta information uhh for real inodes, let me mention some things that don't exist  there isn't a path  we just have um fact we don't have name either  uhh the other thing we don't have is um lets see  who modified it  the other thing we don't have is file type but we do have things like the left when was it last modified  there's an owner  and we can find all these things inside a basic inode  so im going to today talk about one of the simplest permission models and it's this  each file has an owner or user, a group, and then we can then just talk about the general public  everybody else  whether they're allowed to touch this file or use this file in some way and for each of these three different kinds of people that might want to use our file  there are just three permissions  read write execute  read write execute read write execute unfortunately there is no edible bit perhaps for next years april fools you'd like to write your own filesystem that is edible  so we can basically say if you're the owner of the file  if you're the user owns the file  you can read it you can write it you can execute it  if you happen to be inside this if the user trying to access this file is the member of the group that owns this file then again we can specify some permissions everybody else gets these permissions  so here is a surprising potential gotcha  in C guess what happens if you start your number literals  your integer literals with the number 0  you're speaking octal  so if you were to write int a = 0123 congratulations you just managed to confuse a java programmer  this is not 123  each one of these digits represents three bits so this is exactly what we need if we want to talk about our user group and other permissions  because we can encode three bits into this number and easily read it off as well  so this is 001  this is 010  and this one is 011  so I can easily read off what is going to be the user group and everyone else in terms of their permissions  we'll talk more about that on monday  no wednesday my apologies ok  right i'll mention though  some useful calls here  we're going to run into chmod to change the uh permission bits on a file  and there is a call you can make inside c and theres a call you can make inside the shell there's chown  if you want to change the owner  you already know mkdir for making a directory  perhaps you didn't know mkdir -p which is useful which makes all of the parent subdirectories if they don't exist  so for example I can say a/b/c and rather that complaining that a and b don't exist  it will make a and b if they don't exist  here's some other little tricks that you don't know  if you just write cd to change directory it goes back to your home directory  this is in the shell  also in the shell   tilde i uh once had a book that referred to this symbol as a corgi as in a small little dog excrement
and im now forever cursed by looking at that and thinking that way so i'm happy today to share this curse  so this tilde means also home directory  it won't inside of c programs  its just a function of the shell program  such as bash  so if you are somewhere else and you quickly want to refer to a file inside the home directory you can do ~/hello and my favorite little trick is cd - which means go back to the previous directory that I was in  so if i wanted to swap quickly between two directories I could do cd -  and finally theres push directory and pop directory  which allows me to say remember the current directory im in and later go back to it  so theres just some little kind of unix helpful things to do  with that lets have a look at page 2  so here is how we can lay out the information we want to store inside our secondary storage  we'll have our meta information stored inside these inodes and we'll just put all of the inodes together  we'll talk more about that term next week  and then we've got some remaining space  so when we first format this disk  we're actually going to say we assume I have never need any more that I have a maximum number of inodes so we just have a fixed size table here  and then I've got the bulk of the remaining space  and I'm going to split this up into the disk blocks  and then later when I want to get my data  I will actually say ok give me disk block 0 give me disk block 1 etc and so on so today. what we're going to do is look at how we can actually store the contents of a file using this classic inode structure. here's the game we want to be able to store very small files efficiently and be able to access them very quickly disk access is slow on a spinning disk you have to wait a long time for the disk head to move to the right head and for the disk to spin around before you can get um the data its actually an easy calculation if you know the disk rotation speed like 5500 rpm or 7000 rpm you can figure out how many miliseconds before it's done one revolution and moved to the right spot but its the order of 10s of miliseconds so we want to do minimizing of disk accesses for small files. so what we want to do for very small files is inside the inode we'll just store the disk block numbers for some direct blocks right so the beginning of our file will be inside block 7 or block 8  uh block 9 is actually already being used so we want to go to block 22 and so on and so on and so on so if i want to read a file  I'm going to have to read the inode which I might already have inside memory and we're going directly to these block and request the trouble is our inodes are of fixed size we just put them all together in this little array here so our scheme is only going to work for a small number of direct blocks. and typically this number is about 10 so we have 10 of these the advantage of course  is that for small files it's very very quick to know which disk blocks I need here's what happens next we'll take one of our standard regular blocks and we'll use it not to store any data in but just to store  some numbers the numbers of where to go next so go to block # 4 go to block #199 go to block # 233 etc etc etc so we better figure out how many entries we can put inside one of these disk blocks so also two pieces of information we need here size of our disk block and size of each pointer ok so lets write one out lets suppose our disk is using 64bit addressing so we can have alot of disk blocks how many bytes is this? 8 also known as 2^3 and let's say that each block is  4kb what's that in 2^n notation? uhh ok well everyone knows that 2^8 is 256 2^10 is 1024 so 4k is 4 times that so its 2^12 so if you have got 2^12 bytes and each entry takes 2^3 bytes my back of the envelope calculation tells me  that 2^12/ 2^3 = 2^9 oops there we go I can store 2^9 entries ok whats what. what number is 2^9 512! so I can have 512 of these blocks  so if that was the end of our addressing scheme. we can actually work out whats the largest file that we could store right so forget this stuff for a moment how big of a file could we have well we have got 512 data blocks here plus another 10 here so if that was everything I could have 522 times each block was 4kb and that would tell me then how much space my largest file could be so what do we do when our file is bigger than that? ok so the famous quote by wheeler every problem in computer science can be solved by another level of indirection so if you've got a problem dont worry just wrap it around we'll fix it by encasing the problem with  with another solution this was done on the DCL building have you ever walked through the dcl and notice there are outside windows on the inside that's because we have glued the building and rather than building a new building we just put the building inside a bigger building so next time you walk through dcl you'll notice ahh thats why there are window panes there so  here's our plan then is that for even bigger files well have a lookup table of lookup tables wait a moment this was just like like virtual memory yes? where we had a multi level table and the key thing here is that for medium files more of these need to exist we can grow this as needed
right so  now it's time for you to play i've got a few little questions here I've changed it so that um now we only need uh we're going to have this many number of blocks so 4 billion disk blocks okay so how many bytes is that? for each pointer? 4 bytes! also known as 2^2 alright the reason i'm using exponential notation is because division just becomes subtraction. right so i'm going to need 4 bytes for each entry. and so for  these disk blocks you can now calculate how many entries I can actually hide inside each disk block it's just going to be 2^12 / 2^2 also known as 2^10 so I have 2^10 entries inside each disk block right so that in mind have a go at answering these questions for the last question you can leave your answer in an equation form or an expression don't need to actually do the math a question about one quick line of reasoning here which is if i've got that many disk blocks 4 billion disk blocks then I need 32 bits to be able to talk about any particular disk blocks to be able to represent 2^32 possible entries and so If I've got 32 bits then that means I've got 4 bytes per pointer okay for question 2. if the  index is half full that means I don't have 1024  I've just got 512 entries inside here or 2^9 and I've got 512 valid entries then that uh reference actual disk blocks so how big is my file? you might want to want 512 and that would be the wrong answer why? thank you yes! theres another 10 here so i've got not 512 but 512+10 I've got 522 disk blocks and If i multiply that by 4kb I could tell you how big a file was what about actual total number of blocks used? it is not 522 it's why? we're using 1 extra disk block here for the index ah ok now the trickier one here is what about a triple? so we've seen it for indirect double indirect theres one more level of indirection where we can go for triple indirection which is an index of index of indices wow before we actually get to the actual datablock so how big does our file need to be before we need to go to triple indirection? well that means that we've got everything filled out we've got all of our indirect blocks we've got all of these double indirect blocks so we've got to figure out how many blocks we have in this table well we've only calculated each of these little indices can have 1024 pointers so this has got 1024 this has 1024 etc right and how many of these do we have? well we have 1024 entries  in here questions? obvious? so now I can figure out how big my file is i've got  10 direct blocks. i've got  1024 indirect blocks and 1024 double indirect blocks and if i was to add all of those together it would tell me the largest possible file I could have before i needed an indirect block right so some comments on this filesystem is that as your file gets larger it takes longer to actually get to the disk blocks that you want yes? so as  for very short files we can read these directly for longer files we need to start actually reading our tables into ram as well so we can actually follow them so there is a cost of having large files using this system
alright i will mention one other thing today yesterday for fun I wrote a scheduler at least a house computer mumbles here we go and I put this in subversion and it actually tries to solve those little scheduling problems that we have so um you can download it  you can play with it um and you can see we've got like the logic for say  um round robin which just goes round and finds the first process that is runnable and stops if there is none shortest job first that looks for the job with the shortest execution time and priority jobs where they have the highest priority for example it just prints out a little schedule for that so feel free to download my code and have a play with it with that have a wonderful weekend and I'll see you monday for the next lecture quiz thank you very much come down to see me if you have any questions
Alright. Good afternoon class. Where are you? There we go. Alright. Hi So uh last night I had some fun uh making this uh camera preview. Uh. Normally when you set up a camera preview in android uh  For speed, you don't get to see the bytes. You don't see the actual pixels. Here's why. Memory is really really slow and when you start looking images typically you're talking about uh a million bytes or more Uh and uh uhhhhhh working with that in in Java and copying it from buffer to buffer  is going to make any kind of preview mode very very slow Um just as an example, uh a typically CPU these days can execute about 215 instructions per Sorry 250 per instructions per main memory access Versus say level 1 where it can do about 4 instructions per main uh per level 1 cache access Right so um I didn't want that thought I actually to get the bytes from the preview  and uh finally I finally got it working last night. So we'll be playing with this in uh section uh tomorrow. Uh Theeeeeeee plan, We'll see if I get it working and then if I can't then it's your turn Is to uh make a webserver that's part of this app So that the webserver actually is uhhh got a back end interface into an application This isn't quite as crazy as it sounds. In fact, many of programs now uh have an in built webserver so that you can interrogate  uhhh the current state of the program so for example if you're developing a game, You might consider a webserver as an alternative way in into the kinda back end of your your game engine so you could look at stats that the program is running you could change things as so as the program is running you could even build a complete a small interpreter so you could say quickly set where the uhhh where the players are or load a particular state file so that kind of thing I've seen it done with uh gas chromachaffs as well where there's a main screen and then there's a behind the scenes webserver which you can connect to  if you know the port and maybe a password Uh so again you can check the status of the engine or the program as it's running So as planned is can we make a webserver that is part of this camera preview and then we'll use it to actually share The image Alright so. We'll make our bit of kind of spyware so that anyone that knows the port number can actually look at the uh the current preview that's going on. right So that's what we're going to make. Ummm Now today, we're gonna talk about uhh files andd uhhh this kinda one really really really big idea and it's gonna this kind of misconception I want to clear up today that a file name is NOT a file and it's an easy trap that we get called into because we think like that all day long we think, open this file and here's the name Right If you could walk out of this lecture Not believing that anymore, then, you made significant progress Instead what I want you to think of isss that a file is an i node That, a file is just the bytes, just the content Forget for a moment that it has a name Forget that it lives inside a directory Forget that it lives inside a hierarchy That's all icing the cake, which we're gonna do seperately from the actual file Right. So how do we think of files? Think of them as just a particular inode and remember this is how we're going to organize our space on the disk Where we initially format it, uhh we'll have a super block SUPER BLOCK But the super block is just a managed information about how we've actually organized this data And in fact on real disks, disk information is so critical to be able to get anything done It's actually replicated several times throughout the disk  Just in case uh we get um a cosmic ray or some other effect which obliterates this particular copy But anyways super block tells us, how many say inodes we've got and and where the very first data block block starts Right. So. If we're using an inode. That means we've stored a file on our disk And remember we looked at last time that each inode might have some Direct entries HEY here's the content and we'll have say about ten of those But if we want to store larger files, Then the game we play is we store a reference a data block that is not actually used for data It's used just to hold pointers to actually data blocks And if we have a larger file, we play this game twice we have now, a reference to a data block That it to itself contains pointers to yet more tables of pointers And then finally huge file,  Then we play this game three times, thriple indirection block and that's it, we don't play after that. Right? We don't try to. We don't have quad indirection blocks Right so that's our contents of our inodes and you remember that inodes have more than just these pointers,  they have a little bit of information as well, a little meta information like the file size ummm, ahhh who owns the file. And as we'll see in a little bit Guess what? you could basically, from C, Discover what's in the inode. And uh. Including the inode number, And remember we talked about some of these things like, Who saw it, when was it last accessed, when was it last modified? When it last changed? And Total number of bytes
Ok so, let's get back up here We said that uh, we don't care about file names The inode is the file Is the big idea. Okay Okay right That's the big idea, great!  So what we're going to do to all going to talk about it after the rest of the lecture Okay so we've got a problem then, if that's the big idea, how are we going organize things into directories How are we actually going to give things names if we're saying their names is not actually part of the file Well, all we're going to say then is the name is actually part of a directory listing. So, a directory then will have A listing, and the listing will be A name And An inode number A name, and an inode number. etc etc etc etc In fact, we can think of a directory as just a file We'll bless it, we'll set a particular binding flag to say this isn't actually a user file, it's actually part of the file system And uh we'll need to read the contents and expect the bytes to mean the following The name followed by an inode number. The name followed by an inode number So that's all the a directory listing is Name followed by inode number And these, inodes then might correspond to one of our files but it might correspond to another subdirectory. Right so here's the big ideas we've had so far right Files don't have names. Directories have, a little map from a name to an inode number. And directories themselves are just files. They have data. What is it a data? This little mapping. So they'll have a data block with this kind of mapping. The good news is that we don't actually need to read these bytes. We've got some posix calls which we'll see in a moment Which actually interprets these bytes for us But what we'll be doing is opening these these directories just using a regular file descriptor And then we could call this posix call to actually weed out um the  the data as if its uh a certain ballistics Right Questions so far? Yesssss Yes so, every directory is gonna have two  special entries which um doesn't uhh the first one dot dot which is the um what parent directory, yes, how do you get out of here. I wanna go back up. right Anddd also, we don't need to store this one directly but we'll come across it in a little bit Ummm In current directory dot So we don't necessarily need to keep that inside the uh inside the the data but mainly the posix core will always see it. It's like uh Yes I can talk about myself So, each directory knows about itself and it knows about  uh it's it's parent. A directory can only have one parent so we're talking about a tree Other questions? Okie dokie. Then let's Okay Alright so let's um Let's uhhh put some contents into a file Okay, my text Hellooooo I am a cat Alright And ctrl D to save. finished Great so normally we do kind of ls to see what's in here um Ok Umm But I can do more than that, I can say give me the inode numbers Here we go Uhh in fact, one of the options for ls is just to say give me it on one per line So now, yeah, I can, you can believe hopefully that every file Really is just an inode number, so if you're talking about a directory name or file name you're not, you're actually that's just gonna be converted into an inode number If i wanted to make another directory so hey I'm a subdir That subdirectory has what? a unique inode number So one way to tell whether you're truly are talking about the same file. you and me is to see if we are uh talking about the same inode number on a particular file system Alright so I lost my I seem to lost the projector, okay alright
So how can we find that the inode if you're the command line, you could just uh pass in uh on the side, ls or from code  uh we've got the following calls, we can ask for a stat, give the status of this file and uh there's two useful variations one is you supply a path,  so for example, I could say  stat on my file demo.c and pass in a pointer to my struct another is I pass in a file descriptor Now if you're going to start reading things from uh the buffer that's set make sure that you check the return value right? so you want to check the uh the result is 0 otherwise its succesful if it's non-zero then that's  that uh C structure uh was never touched and you'll just read garbage or old values so it's a common programming gotcha. just assume that stat just worked  and then try to pull out um uh values and information from that stat where its in fact, stat says huh I don't know file or you don't have permission for that file or hey, it's nice day outside I don't I'll bother to do any work today Um that's not actually a posix error The uh Right so so check the return value of stat Now I mentioned before you can do fdopen and uh fdopen allows you to go from a file descriptor at the posix level up to uh uh a C file pointer complete with buffering and using printf and all that good stuff You can actually go the other way There's uh function called fileno which allows you to extract theeee file descriptor out of C as well Right so we can fill this in And there's one other call call here lstat So there's one thing we haven't talked about yet which is symbolic links we're gonna play with these in bit. we're just gonna mentioned them today was gonna say okay this exists and as a symbolic link is a file that pretends it doesn't exist instead it says HAH I don't exist, what you're actually looking for is over here somewhere and it gives you a redirection so just like you might move house and could set up your mail forwarding that's what a symbolic link can do so, uh you can say, Oh actually the contents that you really want uh read or write are not  here, they're stored in some other directory if you want to be evil you could set the symbolic link to point to another symbolic link which  can point back to the first symbolic link Muahahhahaah at which point your machine catches fire No you won't have been the first person to think of this and your program wont have been the first program to do this so instead the operating says  hold on a moment, I've been following these these symbolic links too many times i'm gonna quit trying to follow them and will give up after a preset number of times But anyway, uh the lstat exists if you actually want information about the symbolic link itself, rather than trying to follow it If you call lstat on a regular file that's fine it'll just be the just be that equilvalent of calling um stat so lstat is useful if you are really interested in the symbolic link itself like who created the symbolic linke, who do I need to blame for this mess right? or when was it created? That's pretty unusual, most of the time we actually want to follow those links right? what most of the time we we just want to imagine that uh these aliases are automatic Right any questions so far? Okay so let's get a have a share of a look to see all the stuff we can kinda discover about the file First files themselves lives on a device yeah we know they have an id number and they have this  security access as simple protection where we can talk about who can do what so we're going to see more of this in the moment but this is the idea about who can read it, who can write it, and who can execute it they also have an owner and this we've got a user and a group I'm not gonna talk about groups much in CS241, just know that they exist Um if you get into linux administration, maybe it's it's useful if you have a lot of kind of team members working inside the same directory um but we're not going to play with them let's just let's just uh umm restrain our attention to users today okay And then the um total number of  locks, in actually uh these happen to be in in multiples of 512 just for historical reasons uhh and so that tells us, for example, whether the uh the 8th direct block entry is valid or not, or we should be using the indirect block as well etc etc so we from the number of blocks for example if that uhhh if that was a sufficiently small enough figure,  you'd know that there wouldn't be any triply indirect blocks or double indirect blocks etc etc etc Right so now I can write code to say, find me all the files which uhhhhhh have been created today or have been created by a certain user Most uh users are actually integers And so the file system doesn't keep a record of user names if you want, you can turn an integer back into a known user name you're gonna have to ask the operating system to do that so at the file system level, we just distinguish different users by different integer numbers
So I said that, hey we'd like to look at different files and maybe call stat on them Um, here's some starting code that maybe we can actually start to find different Look at, look at actually entries within a uh Entries inside the directory So here's the format of reading directories, we say okay I wanna open a particular directory And we're giving it dots. So what does dot mean? Current directory. Yes! So it depends on my process Where whatever the current directories of my my process. I could put it in an absolute directory here for example This opens a file descriptor So one way this could fail would be if you already got too many file descriptors open But it wraps it inside this DIR because we don't care about the actually bytes stored inside this magic file called a directory, we wanna pass it in terms of um uh uh uh the the names for example stored inside and the inode numbers possibly So that's what this uh readdir call does It updates an internal state inside this structure  and uh we can keep calling it and it will iterate all of those entries returning one at a time And then we could extract the name, maybe we care about trying to find a particular name So if strcmp returns 0, great we've got an exact match uh we could say yes we've found it Eventually readdir says okay I give up.  I um the the there's no more entries in which case it returns null So this is fairly kinda idiomatic C code  Where you not only  assign the result of a call to a variable you also uhh check it for something Like whether it's non-zero or not So eventually our while loop finishes we close the file descriptor and free any other internal resources perhaps we've malloced some memory inside there to hold the names and we return 0 saying we didn't find it okay so what's wrong with that code? Don't tell me. Explain it to your neighbor Or take a good guess Okay so here's the code no errors found I'm gonna use it to try to find some file uh each time my little while loop, i'm going to print out the name i found Just run it okay Yay great! It actually all of the entries and remember how we said that we actually dot and dot dot yes, there they are, they're the first two entries  that we actually will see when we  iterate through the contents of my directory so i could start making this into a more useful program, I could start finding things uh for example, uh instead of just dot, i could actually make use of uhh the uhhm main. alright this could be for example uh argv(1) For now i've got a program that's a bit like DIR it's starting to look for things inside a certain directory okay right, so what's the error in this code? Yessss. Thank you, if you find what you're looking for you don't close the file descriptor Aight, the reason why this  I've bring this up because cause it's a really common error and it's really evil one to debug because when is it gonna you that it's gone wrong? somewhere else right? somewhere other time where you actually try to open a file descriptor when you try to open some you know simple file that exists and it's absolutely no reason why it can't open this file and yet your program fails in some bizzare way and its midnight and you've been staring at this for two hours and you wondered, why why did you learn to read?  you know life would've been so much simpler if you could kinda stayed in the yeah stayed outside and ran around and played or something right, so yeah watch out for this. and it's a very common error to forget about frame resources why blame only yourself but blame C C doesn't give us any support to actually uh remember to close resources hardware resources that we've opened and in fact your often find that's true for other languages as well even  with C++, uh we've actually got  to somehow remember to explicitly free those external resources and in this case it's remembering to call closedir So how can we closedir? Well one way is to make sure all possible code paths actually free the resource another thing that  we should probably do with our code if this is actually if we are being paid to write robust code is check the return value and being prepared to print out the actual error so if we actually written good code then our failure might have logged the fact that there were no more free file decriptors for us to use and that would've a strong hint that we were leaking resources
Um by the way A um Some people in the world of C actually use goto right? In this kind of uh Uh this kind of scenario so  we can have a kind of goto cleanup and we have a kinda cleanup right Uh and then yeah we fixed return values as well so Instead of this return here we set a flag or something Okay um whether you do this or not is a fantastic way to get into arguments with everybody Uh there's a lot to be read about how goto is bad but in practice you will find a system level code that does this as a way to to support kind of basic Um exception, exception handling And uh failure cleanup code. Uh where you want to leave early It's not the only other way to do it, the other way is to to actually set create your resources inside a wrapper method and uh uh then, uh you can return early inside your inner method Okay so let's let's let's pretend we didn't talk about goto There we go And fix our code Right, so close uh our directory pointer Right uh Next lecture we'll talk about how to extend this so that we can do uh Directory searching into subdirectories as well Right any questions about this? Alright there are mentioned one gotcha which is remember that you have the parent and your current directory so attempting to do subdirectory searching is like OH I know breadth first search or I know know recursive search! Be careful you don't keep searching yourself forever. Aight Oh be careful you don't keep searching down and up the tree forever your searches are going to take a long time if you go down the tree and back up the tree at the same Uh all is part of your recursive code so you have to remember those special cases remember you're going to see dot and remember you're going to see dot dot Right okay time for side 2 Okay I love this word canonical right it's What's a canonical definition of canonical Can you give me? Two directory paths that refer to the same file? Other words could you write down a string that actually reends referring to the same file but actually when you look at them they're different You're nodding your head how would you do that? Okay Okay, that's a good idea. Okay so, for example, slash home slash angrave slash um Uh one dot text might be the same as just Hey current directory" slash one dot text Okay give me another way that I could refer to these files? Yeah Well some kind of weird double echo race condition thing going on. kay Okay so go up one directory then go back into angrave And then go into one dot text again Okay any other way? Yup? Okay, tilda actually is is a cheat that's actually part of the shell So that so tilda is expanded already. Um how about? dot slash dot slash dot slash dot dot slash angrave slash some subdirectory then go back up turn left right etc right? we could invent these crazy paths which after we've followed them we finally get to the file, I also mentioned these things called symbolic links.  Maybe we follow a symbolic link so we go to the file yeah awesome dot text which actually resolves to our original file So how do I know that these files are actually referred to the same thing? The answer is we need to reduce them down to the canonical form and the beautiful thing about a canonical form is that if you have a canonical path and I have a canonical path and they are identical then they must refer to the same file Why? cause that's the definition of a canonical path So is uhh it's not necessary an absolute path. Not all absolute paths are canonical but you can be sure that if two canonical paths are identical, they are talking about the same file right how do I get the canonical path? Well you give me any path you want I'll call realpath on it it will follow that follow any sym links that you happen to refer to follow any dot dots etc etc etc and then finally it'll give me an actual path. I can use that and later I'll just free it You can pass in a buffer but in practice don't bother just let malloc make sure it gives you enough path enough space Now I mentioned this because actually we can use this for security suppose you were to make a web server you probably don't want a web server to be able to serve all possible files on your hard disk drive Cause if it can, you bet your dollar I'm going to be looking for slash etc slash password Aight. Or your ssh uh private key we'll try to download that And in fact, these kinds of tricks are used to escape the current directory or the root of the webserver and uh we want to try to prevent that so one way when you're checking directories is to convert it into a canonical path and then check that it actually truly starts with the based directory that you care about so for example the user is trying to get an image from your image directory  not trying to download your password file as an image I've encountered numerous server programs that don't do this check so for example, uh I can get a printer to include using uh postscript and other commands to include a local file from the printer and therefore print out the printer's own password and other information you want about the printer whoops So anyways so thats so real path next time we want to write a robust server, remember this it's useful security tool
Okay right Question for your neighbor and yourself Does the inode contain the filename? Choose now Hundred internet points if you get the correct answer Okay Right If you think the answer is  No, it's not part of the inode give yourself a pat on the back or or or or or shake hands with your neighbor alright? if you thought the answer was yes exits are this way and this way there are still majors look there are still majors looking for other people no it does not, remember okay? it does not the inode, the file does not know about it's own file name okay? that's the most important thing the most important point today we've got today okay and it allows us then to do  the following, i can have same file appear twice in my file system this seems impossible if you still think the file name is the file how can i get a file to appear twice? in two different places what do i need to do? yes I could yep hard link it. what's actually to my directory entries? Yes! thank you! remember my directory entries are just name inode number Somewhere over the mountain I've got two entries With a name1 that goes to a node1 and another one in another directory I've got a name to and it happens to point to the same inode number I've better singing otherwise anyway alright so thank you I just made that up okay Yeah so look here's one directory remember all the directory is just some data it all that data is just a name and an inode number inside another directory we've got  a different name somewhere but it happens to point to the same inode number My goodness! So if I go into these two directories try to actually open the file, I open up this file and you can talk about this file when you talk about inodes and I start reading the bytes I'm talking about the same file That means if I change the content of this file then that file in that other directory changes as well why? because it's the same beep file okay? This looks impossible if you're sitting at the command line and you know you got two shells open and you're actually changing the contents of one file  and you've got another one other here and you cd-ed to a different directory  Oh my goodness! this is crazy, no it's not just remember this, it's just an inode we've just got two different places that happen to refer to the same inode number okay how do I do that? I can use a hard link How do I do that? There's a command called ln So link allows me to make another entry to an existing file let's see if I can pull up the manpage a moment So you type this into a terminal and congratulations you've now got two files, two entries which point to the same inode so you could type say for example link hey here's my file slash home blah blah blah blah blah uh file1 this better exists so it can pull out the inode number of that file and then go somewhere else uh blhblahblahhblah file different name alright so for this magic to occur, we want to be able to know when those disk blocks become available  for resuse, that means an inode has to do this has to some reference counting in other words, how many directory entries  actually refer to this inode if i reduce that down to 0 I know nobody cares about me alright and we can resuse that inode and we reuse the disk blocks associated with the file so everytime you link, we're gonna increment the reference count,  everytime we link you add a hard link we implement the reference count now you might wonder, can i do this with directories as well right? could could my filenames here be directories and the answer is yes kind of no right so why yeah kind of no, here's why the operating system the repair tools all assume that directories are tree based structure if you are allowed to start messing with this hard links for directories you could violate that assumption you could set up a directory which has two paths you could set up a uh file system hierarchy which never ends right? you keep going into subdirectories and you come back round to the top somewhere and so all of the tools for following inodes wouldn't be to complete so in practice, filesystems typically prevent you from doing this right? even root cannot do this on most file systems the file systems C code says Hahaha no right nice try but no right so you can only do this with with regular files you can't do it with directories Right Questions? So what have we said? we just said that hard link is easy we just make a another entry inside a directory with a different name for the same inode and you can do it using this link tool, this link command
Right uh we got time to talk about provisions or the mode bits Here's some example ways of changing who can do what to a file you're going to see these numbers uh quite typically 644, 755 and they're written in octal and reading octal is really easy we just decode each digit into three binary bits right? four two and one and so instead reading four turn and one think read write execute so what's this? this is change the mode bits of this particular file sandwich into read and write for me or the owner of sandwhich, read for the group, read for everybody else so if you're not in the group you're not me, you get the read, so you get to see the contents of sandwhich but you cant modify and you can't execute it what's uh 755? what permissions do I get or what permissions does the owner of the file get? read write execute, four two and one. everybody else gets what? read and execute So that's a very common way of setting permissions, there are other ways to do it uh you can do it symbollically so this means hey subtract the write permission from all three uh types of users uh this means subtract read and exewcute permission from the uh owner or other I forget I'll look it up personally I prefer the octal numbers what's wrong with the file that has the following permission? let's suppose on the file system you found a file that was owned by root and had those permissions? what if you find what could you do to this? right what does 7 mean? read write and execute, so first of all here's a file that  anybody can execute anybody can run anybody can read it but also anybody can write it muahahhahaha so now you don't delete the file you changed the contents of the file and next time someone runs it they run the code that you put inside it so if you find a file like this, this is a security risk right so uh you could play with chmod um from the shell you can also use chown to change the owner so for example uh I could change the owner to user angrave on a file but of course I just can't change any old that will be a security risk so only um the  super user can just modify any arbitrary file so only root can can override a particular ownership like this and you could do this from code as well, so you can set the permission bits or the mode bits on on a particular path Alright there's two other bits inside of the mode integer that are useful, set group which I won't talk about. instead let's just finish the lecture with set user ID And uh   There's an example, have you heard of sudo? Right what does sudo do? Okay right, so supposed you have a command called, makemeasandwhich Which only root can execute sudo says okay change into the root user for a moment and run this command right so maybe you wanna format a disk which as a as a mere mortal in the system  you don't permissions to run this command because the command itself has say the following permissions  right makemeasandwhich might be owned by root and might be uh let's see we want it to be um executable by root and everybody can't even can't even read it right so if we could put sudo in front, sudo takes its arguments and runs it as root so on your virtual machines this is quite a useful command if you briefly want to become a root so how does sudo work? sudo has to have root permission to be able to do the things it wants to do like run things as root so the sudo command itself has this set user id bit set so that when it is executed it doesn't run as you as the calling uh user of the process uh it actually runs as a different user it actually runs as root so that's the purpose of this set-user-ID-on-execution bit it's you can change the effective user of the process once the process starts and the example of using that is sudo and uh if you wanna see sudo makemeasandwhich it's a popular xkcd comic right with that, have a wonderful week. I'll see you on friday and uh have fun in discussion section
alright, let's try that alright, good morning ladies and gentlemen minor technical difficulties this morning my laptop decided to freeze one second out of four never seen that before, guess it must be because we're trying to have a demo today right, so here's what we're going to do today I'm going to introduce you to one of the coolest things you can do in system programming and that is memory-mapped files so cast your mind back to when we said that we had virtual memory and our addresses are mapped to different parts of physical memory and this happens magically without our programs having to do anything well now we need to actually take control of that mechanism and we can ask for a file on disk to be mapped directly into our memory that's pretty cool if you think about it if you actually had, say, some structured data on memory, you could immediately jump to a certain area of the file and read it, without having to write read calls, fread calls, fc calls, that kind of stuff you can just say: Hey! I know where is is in memory I can just read that memory and the operating system will say Hah! I don't have those particular bytes actually on RAM yet, let me do it for you! Hold on a second we'll pause your process, and we'll pull in those bytes and we'll release you again so you can immediately see the contents of the file. The other cool thing we can do with this is if we mapped some memory using mmap and we then fork() we can now communicate between two processes directly, using some memory addresses so we'll play with that today if I can get my laptop to restart and play play correctly, okay alright so whilst that is  warming up. I've set it to gas mark 350div class=caption-track-final-caption ui-resizable" draggable="true" contenteditable="true" style="width:8832px">alright, let's try that<div class="ui-resizable-handle ui-resizable-e" style="z-index: 90;"></div></div>fwwar let me tell you about a couple of useful commands here one is dd so if you ever want to just copy some bytes from one place to another and you want to take control of exactly how many bytes to copy rather than, say, copying the whole file, dd is useful it will open one path and open a right path and you can say how many bytes to copy so, for example, the following copies some bytes from /dev/urandom to ~ (tilde) okay you and I know that ~ (tilde) means... the dog was here yes, that it means my home directory so I'm going to make a file called secret.txt" hopefully the NSA doesn't try to decrypt this file because, in fact, it's just random bytes (evil laughter) and how big should it be? well, I want each block size to be 1k and count of 1024 in other words my total file size will be a megabyte I could, if I wanted to overwrite my secret file start reading bytes from /dev/zero and again the file's going to be the samedfan and again, I'm going to make a file that is the same size equivalently, I could have set my block size to be 1 byte, and put in a million here or whatever  [gibberish] so we'll pretend I know that calculation there we go and that would've caused the same number of bytes but it wouldn't have been quite so efficient we would have made very small calls so it would have been a little bit slower I can also use the following file as a place to send my output /dev/null here's some wonderful things about storing things inside /dev/null : you can store as much as you want inside /dev/null but it ain't coming back so this is perfect place to store your your love letters from past girlfriends, dogs, cats, goldfish, whatever because no one will ever find them that you've got this perfect storage of course, it's infinitely compressable as well you can send as many bytes as you want to /dev/null, and it won't use any disk space why? it's not a real place in your disk it's not part of your disk's filesystem there's something special about this /dev you won't find it actually listed in your disk anywhere, oh good my machine has booted up, now we can actually play instead, it's a virtual filesystem hooray! okay good okay, right, so let's go into, what have I got so I want to find anything that talks about CS and ends in a '1' so that star is an example of globbing the filesystem doesn't do that; the shell does the shell says Okay, I'll try to find all matching things that match that pattern you could have done that for parshell for example anyway, so let's go into our demo two today
why did we not find it? oh because I want to go into... oh cd cs241 okay good, right, we're in the right place okay, so we talked about file globbing and uh, oh yes here's another little useful command let's have a look at, say the timestamp for mmap and you'll see I made it this morning at 10:46 yeah, I was busy just before lecture I can change that timestamp just by calling touch, so if I say touch, and here's the file oh I cannot touch it, why? who owns the file? root, right, and only root has read and write permissions okay, so, let's become root, alright, so I can do sudo, and that will give me root permissions I'm going to do sudo -s because I want to stay as root alright, then, let's touch that file and if we do that wait we've just updated the timestamp so why would that be useful with make? what does make use? the makefile, yes, and inside of the makefile you write rules and those rules depend upon the timestamps it compares the modified time of the executable, or the output of each rule and all of the sources so, if we've touched our input file, then we can force make to remake any executables or libraries that depend upon this file so useful, for example, if you've just changed your compiler options say if you wanted to add a debug flag, and rather than, say doing make clean or manually removing stuff just simply updating the timestamp is sufficient by the way, with make, you're not limited to just setting the timestamp at the current time you could even set it tomorrow, so you could say Hey, look, my homework wasn't done until tomorrow" or something so, you could actually modify the other timestamps but we won't play with that today but there's just a cute little useful tool sometimes to be able to modify the meta information about the file let me make a new file, okay, so here's a new empty file and this file only has the permissions of read and write for root let me check my umask that's actually a poor demo, because root is special I'm going to get out of being root let's make another one, touch empty okay so here's a better demo, root is a special case so when I make a file normally, I have read and write permissions and so does my group and everybody else does not have those permissions why is that? in part it's to do with my umask where the umask is one of the options that controls what permissions are taken away from a file so if I change my umask to be 777, I can subtract everything from those files let me make another file now, and look at that now we haven't got any permission to read this file at all or write it, or execute umask is a subtractive operation, it masks out some of the default bits that we would have otherwise set on the permissions of each file it's not the only thing that controls the default permissions of new files but it is part of your process so I'm playing with this inside of the shell but we could also do this inside of a C program aswell and so if you want to securely create a set of files where you don't want anyone to be able to, say, read them or you're going to create a lot of files then setting umask first is a good security operation you're subtracting the bits that you don't want set so in this case I said hey, take everything off, we don't want read or write or anything" if I had said umask, let's do 600 what have I done now? I've taken my own bits off 6, my read and write aren't there, m but I've let through the group and the world access rights so what's a typical umask? a typical umask is 022 that's a typical default value. What does that do? What does that subtract? remember we're thinking in octal, so each one of these values remember, is read write execute combined into an octal number so for ourselves we're subtracting nothing, but what about the group and others? we're subtracting write we don't want anyone to write our files by, anyone else to write our files if you actually read the manpage of write and other things you'll actually find references to umask so here's one other piece that controls the creation of files it does not effect existing files, it's only during the creation of new files and new directories it also creates, effects directories so let's play with this I will make a new directory So let's turn everything off (evil laughter) and I'll make a subdirectory and I will try to make inside subdir1 another file, so mydata.txt oh, I get permission denied, I cannot write into the contents of this directory why not? because we took the execute bit off the directory, so here's something a little strange the execute bit for a directory means, can I actually see the contents of the directory not the name of the directory, because that's not part of the actual directory but the name of the directory is back inside of the closing directory, in the parent directory it's can I actually open the directory and look inside and see what files are stored there so I couldn't go into subdir1 and in fact if I tried to list the contents of subdir1 I get No! you can't open that directory!" because it's not executable
so let's change our permissions so change mod, and I will change it to now what's a reasonable permission for directories? well maybe we want to be able to read write it and execute it, of course and we want other people to be able to read and execute it, so if I do that then now I can make my file and now if I do a d so I can actually see the subdirectory itself you'll see that yes, we're a directory and yes, I've got the read write execute for myself and execute and read for everybody else that was a very quick introduction to umasks and touching things and file globbing. Any quick questions about this? Alright, conceptually not hard, as I said the only surprise is that for directories, two bits is the execute bit that controls whether you can see inside the directory so no the directory's name, but whether you can actually go in and see the contents of a directory what files and other directories did I put inside of it and for the umask, remember it's a mask you're subtracting things that otherwise would have been set and it's only for new files and directories so nothing conceptually very hard now, here's the fun part, let's let's have a look at some of these other filesystems I've already mentioned /dev as  this completely different filesystem that's not actually a part of my disk and so that's the big idea, that I've got one set of paths in POSIX that I start with slash and go from there, everything's underneath this single slash all of my other things that I want to add all of my USB keys I put in all of my virtual directories and virtual filesystems are going to be underneath this root Windows used to have a different idea, it would say I'll put one disk inside of C:\, I'll put one disk inside of D:\ and we better not have more than 26 disks or we'll run out of letters that was the old kind of DOS way of doing things, thank goodness we've gone past that now but anyways back in POSIX we all start here, and we can add the virtual filesystems underneath specific directories of our filesystem so we've got /dev, there's a couple of others here they are: /proc and /sys right, so how can we find out about these? glad you asked! Let's have a look at a little demo here I want you to cast your mind back to before you were born and filesystems were heavy not something you would carry around in your pocket but literally something you had to lift with both hands because it was a huge tape, a huge disk and you'd lift it and you'd mount it onto a spindle and spin it up the command for looking at and thinking about filesystems is mount tell me what's mounted, tell me what's been put into my machine and by default we get a big list and we can see it and we discover, oh look, I've got a whole load of different filesystems mounted on different points inside of my filesystem so I've got one called /srv some of these are going out onto the network, etc I've got something called tmp oh, here are the one's I've just been talking about, /proc and /sys and there'd be /dev somewhere aswell so there are different types a lot of the ones we're looking at here, as you can see, are ext4 which is the modern-day equivalent of ext2 which we've already studied and we could add more to this so if we plug in a USB key, for example you would see it appear here if I mounted a DVD or CD it would appear here our filesystems don't need to be on external devices they can even be inside of a file so here's a file I downloaded earlier it's a .iso image meaning that I could copy these bytes using, which command? dd, yes, onto a say USB key or onto a DVD-ROM, but I actually want to have a look to see what's inside this file it's just a sequence of bytes, it's just a filet' but allegedly this is actually a filesystem inside this file so how can we do that? first of all we need to make a directory where we're going to mount this filesystem so let me call it stuff and you know right now if I look inside stuff there's nothing there! oops, cannot open directory? why is that? probably because my umask, oh alright, okay, thank you umask fix my umask, okay make directory stuff2 so there's nothing inside of that directory what I'm going to do now is that that iso file and say to the kernal, Treat this file that I just downloaded using wget and pretend that it's a real disk somewhere and start being able to read from it now you know that when you write disk commands you actually read in chunks, not at a byte at a time we're not doing fseek() and fread(), we want to read 4K blocks so we need one additional magic command with mount to say, okay, loop it back and wrap it wrap this this file and turn it and treat it as if it's a full as if it is a block-based device so let's do this, let's switch into root mode here okay, where's my little file? let me play with globbing, so there we go match any files that start with that, and I know it's just one of them today okay, and I want to mount it on a particular directory so, we had stuff2 oh, it didn't work because I didn't add the loop option yes the .iso file I want to treat as a block-based device so I need that one last option. Great, it works, and now we can, if I look at my mount listings, see that we've got that file mounted inside of my directory as this iso9660 which is a standard for CD-based filesystems and it's using particular loop-based device to turn it into a block-based device great, let's go and have a look
wrong directory there it is! right, I can now explore this filesystem. In fact I can say hey find me all of the files there we go, find me all of the files that match, say something beginning with efi and I can actually see what's inside of this filesystem let me try and change it say, Angrave was here" and this will fail because our filesystem is read-only so not only do we have umask control what we can do our entire file systems have different capabilities and so our iso9660 our CD-ROM based filesystem is only good for reading from  We cannot today change the contents  and if I actually mounted a different kind of file system, I could I could have actually written into this set of files and that would have changed the outer file, would have changed the .iso and that's the beginnings of how we can make virtual machines we can set up a complete file system for a virtual machine to boot from as just a single file Ok, right, so now I want to unmount it, I think I've shown you everything I want to show you here okay, so how do I unmount things? umount. I don't know what happened to the 'n' right, but it's umount okay, so we better find the thing to umount alright, so here's my mount, I just want to find things to do with that .iso, so let's take the output of mount pipe it into the input of grep and grep will only print me lines that match my pattern so I'm going to look for things that match .iso here it is, that one line, that saves me a bit of eye search trying to find it okay, so now I can umount on angrave/demo2/stuff2 did I miss something? oh cs241 thank you It's busy?!?! Why is it busy? I'll give you a hint: we're currently in there, that's currently our directory so the kernal says, I'm sorry someone's using this device right now, I can't let you unmount that because I've got another process trying to read its contents So let me go up one directory okay, so now I've unmounted it there we go and now there's nothing let inside stuff, we're back to an empty directory again okay so we're seeing the lifestyle, sorry, the lifecycle of mounting and unmounting we've played with grep now let's play with some virtual filesystems alright so if you ever want to just clear the screen clear is useful, if you've messed up your terminal reset tries to do some things reasonable let's have a look at a couple of these files let's have a look at, say, hex dump of zero if I start reading from /dev/zero I can just get a whole load of zeros If I read from /dev/null there's nothing, it's completely empty but they're not the most exciting ones, let's have a look at so next time you want to write a secure program, and you need some secure random numbers, numbers which are actually difficult to guess /dev/random is your choice you could open this, and read from this directory, and it will give you back random bytes random bytes that are difficult for an adversory to guess in advance how does the operating system generate these numbers? by collecting entropy okay what is entropy? well, things like external things can happen to my system so for example, let me press the Shift key and of course, I can't , because I'm not on that machine uh, so what I can do on that machine is look for arriving network packets let me try to generate from random entropy and slowly, when it's got enough entropy, there we go it can give you some more random data so not only does it need to generate random data, it needs to actually keep the meta information about just how much randomness has it collected at this point well look at that, lots of stuff must be happening maybe the disk drive is going, maybe there's some additional network packets happening but it's run out of entropy, so it blocks so it cannot give me anymore bytes at this point without um it cannot reliably give me more bytes at this point which are random so /dev/random is useful if you really want to wait until you've got cryptographically secure bytes if you don't need cryptographically secure bytes if you're prepared to just accept some limitations, then use urandom and that will just happily stream random bytes to you all day long so off we go by the way, with hexdump, you can even ask to see the characters aswell here we go, and perhaps if we waited long enough, we'd see Shakespere so that's one way to generate a lot of random numbers very very quickly we can find some things out about my machine here, lets go into /proc now and first of all, if we do an ls, we can see there's a whole lot of numbers here and some other interesting files that are generated by the kernal these do not exist on the disk drive this listing of files is generated by the kernal because we asked for a particular directory and if we were go to a particular one of these files again, it's generated on the fly as we request bytes from these files so let's have a look at, say, the memory for this file
what have I got here? I've got useful things about how my memory is organized let's have a look at Swap information you see that my Swap file here is about a Gigabyte in size and let's get a look at my CPU okay so I can get a whole lot of data but my CPU I can discover, say what features my CPU has but my favorite thing about CPU is I can discover how many bogomips it has in fact this little particular box has 4 CPU cores and each CPU has 6,000 bogomips a bogomip is one of the most well-known fake measurements of how good a processor is and it's this: when Linux starts up it runs a timing loop to see how quickly a CPU runs before the hardware timer interrupts so we can get an idea of roughly how many instructions we can run per second and that's what this is telling us roughly, our little CPU can run six thounsand million instructions per second that's a pretty fast CPU and of course it's a completely fake measurement we don't ever start to get close to that but it's a cute way of being able to compare one CPU to another and have an idea of how fast the timing loop is if we're just writing a very simple - in Assembler - kind of a litle for loop to wait for, say, a hundred instructions or so so that tells me something about my CPU speed and as you can see I can see how many CPUs I've actually got in my system so I can look at these these system-wides prompters, but I can also discover things about specific processes remember these numbers over here? They're just process numbers how about we find out something about our own process well I've got two ways to do that actually, the shell in a variable, tells me the process number of itself haha! I'm now inside the Matrix here I am inside of the process number of my shell let's see what we can find out about it all sorts of things so we can we can discover something about its memory make that a little bit more readable there's a lot of stuff inside of maps the first thing is, this tells me how the memory of my process is mapped so I remember how I said Hey, some memory's not mapped to anything" well here's the proof the very lowest part of memory is not mapped to anything the first we've got, actually, is memory starting at this virtual address going up to that virtual address and... come back! and it's at this address that memory is actually executable, and it's mapped from a file called /bin/bash then later I've got heap memory, here it is then I've got all of these librarys like ld libc, you could probably guess what's inside of libc all of the C calls that we call and eventually we should find the stack down here aswell oh there it is and there's our current stack I've got schedule information, I've got other status information and I've even got the file descriptors and I can look at even the the command line that was used to start this so if these are readable then that suggests an important security concern which is anything you put on the command line other people can read so it's probably not a good idea, on a shared system to put your passwords, or any other secret information, on the command line because this interface allows people to actually discover what's on the command line of all running processes let's start something in the background so let's start sleep 10 echo so let's go into okay that was the wrong process with a little bit of searching we could have found that command line for echo and discover the secret alright so that's enough of these virtual file systems I think it's time to talk about virtual memory, so page 2 so using virtual memory is and using memory-mapped memory is relatively easy I'm going to show you one version today which is where we have our memory-mapped file and we actually have a real file behind the memory that we're going to use next lecture we'll play with forking and show you how we can use this with IPC aswell
okay so here's our plan we're going to use something called mmap and when you say Hey, I want to map some virtual memory" we need to say what kind of memory do we want? do we want memory that is readable? writable? or executable? some combination of the above? so typically we will want at least read and write access so here's our protection so this is how, if you if your process tried to, say, change a byte of libc the virtual memory hardware would say Hold on a moment!  you don't have write access to that file. I'm going to let you proceed any further and it would raise a signal but we want to do more than that we actually want to be able to modify the file and we're going to actually change the contents of our file just by writing into memory which I think is pretty cool the other thing we're going to see is this map shared which means that changes we make are shared with the file sudo change owner to be angrave run vim, great now, there's a gotcha with using mmap which is that it's not going to automatically extend the file for us so if want to be able to, say, store a few integers in our memory-mapped space then we better make sure that our file is big enough before-hand so let's do that first let me look at a file descriptor and I'll open the file called data I want read and write if it doesn't exist, I want to be able to create it if it does exist, I'm going to truncate it and here's my permission bits, 0600 what does 0600 mean? the 0 and the beginning means I'm going to speak octal and the 6 means I want read and write permission and everyone else, ha! nothing for you we're making this a private file we need a way to be able to extend this file how can I do that? any ideas? how about using seek there's two ways to do this: we could have actually written enough bytes so we could have written size time size number of bytes into my file but another way do it is just to deliberately seek to a new end-point, and we'll write something in there so let's seek on my file descriptor who remembers how to use seek? I want to go this far into the file and remember we can like seek end seek beginning, we can say seek set and I'm going to write just one byte in here so let me write into my file descriptor here's a pointer to some data I want to send I'll just send, say, abc and I'll send those three bytes and in doing that, I've made sure that my file is more than this size so that's just the easiest way of extending the size of a file now we do our map and if it works, we get back a valid address for now I can treat that address as some memory that I can now use so I'm going to write into my memory 12345678 and this other hexidecimal constant called dead code to make sure that the changes in memory are written back to the file after I should unmap it, so how do I do that? I call munmap and we're done so let's compile this undefined reference to seek what did we do wrong there? sudo chmod angrave everything
oops, too much speed okay thank you right so oh yeah, sorry I was doing lseek alright so we got a reasonable address we wrote those bytes into it now actually let's have a look at our file okay here's a letter 'a' that we wrote here's those numbers we wrote 12345678 and deadc0de but that's not what we see inside of the file why? endianess, yes what can you conclude about this particular processor? that 78 56 34 12 we put the largest values of our integer, the 12 and the very end our integers are written in reverse we put the the smallest byte of our integer first in our file and that's a property of the CPU so be careful when working with binary data we have to know how our CPU represents integers and other data formats if we're simply going to just write them into the file likewise, if you're going to read from a particular binary file you need to know whether that structure on the binary file actually can be easily mapped into the CPU that you're trying to work with okay, so that's our file, and look how easy it was to actually change the contents of the file we just wrote into the file as if it was regular memory and if we had a very very large file we could simply write in offsets here and immediately use that data so if this was genetic data we wouldn't need to parse it, we could simply write it and read it directly from our processing loops so it can make working with binary data very very efficient one last comment on this is that memory-mapped files isn't always a free lunch you won't necessarily speed up all operations the kernal, the operating system, the disk drive are designed for fast streaming of data so if your process is simply streaming data in doing some simply processing or filtering of that data as it comes in and streaming it out, memory-mapped files will not give you any significant advantage what it will do for you is when you want to make use of the virtual memory framework to automatically map parts of files directly into address space and with that, my demo's finished. Any questions? you might find this useful in the very last MP if you're trying to your keyserver run fast, but I'll say no more for now. thank you very much, I'll see you in two days.
alright! do we have sound, testing testing yes great!  good morning and welcome to cs 241 here's what we're going to do today i'm going to cast your minds back to 1991 when a little while ago yes tim berners-lee posted the following the world wide web an executive summary the WWW project merges the techniques of information retrieval and hypertext to make an easy but powerful global information system.  little did he know that he would be so right. i'll skip on to the other fun bits like to follow a link are really clicks with a mouse! these are the only operations necessary to access the entire world of data!"  he also says inside the same posting that  making a web is as simple as writing a  few sgml files" so html actually has a history before that which was a larger markup language called sgml eventually as you know we decided to use a slightly simplified markup language called html the www model gets over frustrating incompatibilities of data format between and suppliers and readers by allowing negotiation of format between a smart browser and a smart server so here was tim berners lee's insight, is that what we need to figure out is not the coding and the making it work on all kinds of platforms, yes we need to do that, but it's actually the protocol that is important the protocol between the client and the server the summary does not describe the many exciting opened up by the WWW project  remember at this point he's just talking to a few friends at CERN, a physics lab in Europe such as efficient document caching, a reduction of redundant out of date copies and use of knowledge daemons  there is more information in the online project blah blah blah here, here's a very simple prototype 128.14 and it gives you an IP address  i found an early version of his code version 0.2 it has some bugs in it, it's not even secure but i thought it'd fun to show you the code because here's what your'e going to do in lab tomorow you're going to write a web server i'm going to give you half the code you fill in the rest and you're actually going to use mmap to be able to serve the files back onto a web page and here's the thing about searching at the other end of the scale, large information providers may provide an http server with full text or keyword indexing was tim berners-lee actually thinking about google at this point?  i think maybe not, i think maybe at the time he was thinking about servers that would actually index documents on that machine not about machines that were powerful enough to index the whole WWW project but anyways, next time i meet him i'll ask him what he meant by that comment so yeah, i'll include this text in tomorrow's section, you can read it yourself so let's turn to today's handout  alright, so just as a warmup exercise, how do we mount a disk image? so let's say i've given you a file and that file actually represents a complete file system what do i need to say?  well you're going to use the mount command because it's a file, a stream of bytes, we actually need to use a loopback so we're going to need the -t option because we need to turn it into a block based device  we give it a reference to a file and we give it a point on our existing file system where we would like that file system to appear but the big big idea is 'hey i'm mounting it' i'm adding to my existing file system then i can cd into it and potentially change the files of that file system okay, what is the setuid bit? what's the purpose of that? so on a file i can set the uid bit and if I do what happens when people execute a file with that bit set?  yes! that's right, it's the process that has started is not started as you as the caller it's started under the user of the owner of the file  so for example, if we have a program called sudo, which we do and the owner of that is root then if i've set the UID bit  then when you execute sudo, it doesn't execute as you it actually gets all the privileges of root. so that's a kind of typical use of suid. my goodness, that's not your eyes, that is this projector. there we go, that's a bit better, right. so if for example you wanted to have a program that made some symbolic links and mounted a directory  and you wanted to do all this stuff that requires root and it requires admin access you might make a program and then by using suid  you could then allow other non admin people to run your script and for this script to do administrative things for them  so let's turn our attention to mmap  the purpose of mmap is to give us virtual memory that is backed by a file and when we try to read or write those virtual memory addresses  the kernel will automatically read or write to the file  that's on the file system we don't need to bother with reading it into our data structure our data structure can simply just be at that address okay well let me ask you now um, mention that we've actually got a couple of options  first of all  you have to choose one you have to say  when i'm going to call mmap, i either want a private copy or a shared copy so here's what happens if it's private you say any changes i make to my data structure i don't want them to be pushed back onto the disk i just want my own private copy so now  it's like saying  okay, load this stuff in, i'm going to scribble all over it and i don't want anybody else to know about it it's my own private copy, right? and in fact for efficiency, we don't make an immediate copy of these pages, we do it only when a process attempts to write to those pieces of memory in other words, if i started four copies of your program, i don't need four times as much ram  i will only actually make a copy of a frame when you attempt to write into it
so map private uses copy on write for each uh frame of memory, so for each four kilobyte block behind the scenes it will copy it only when you attempt to write it and that copy is then just like any regular memory that you might have made on the heap once your program is gone, it's gone, there's no store of it it's also private toward a particular process map shared on the other hand is useful when we're going to want to fork a process and then our child and the parent will see the same physical piece of memory so any changes that the child does, the parent will see, to that frame of memory also, it will copy the contents back to the file that we opened so, it's doubly shared, right it says um that i'm going to use this for interprocess communication between my child and my parent and also i'm going to copy  back to the file right so this is two useful ways of using mmap  so most of the time you're probably going to want to say  ok, i want to see it shared so early versions of mmap did just that but we realized that actually maybe sometimes we want to be able to share things with a child and the parent process and not actually have any file on the disk at all we just want to set up some physical ram that it could be seen inside two processes and uh if you want to do that you can, you just need to pass in  map anonymous  by the way if you actually want to work on os x, you need to use map they are synonymous but so this means 'hey i don't actually have a file i just want to mess with virtual memory so that i've got a page of memory or more that i can share between a child and a parent process' what can i do with that, well i might want to simple write values in you can also share a semaphore  remember semaphores? these counting things where i can increment the count if i attempt to decrement the count, it might block if my count attempts to go beneath 0?  so now i can actually use this to synchronize between two different processes we're not gonna go into the details of how to set up a semaphore inside shared memory but a google search  thanks to the world wide web will let you do that right, we can find easy example source code to do that, so that's beyond cs 241. just hey, back of your mind, know that this exists should you ever need to do this  okay so let's have a look at some example code how can we use mmap well we opened a file descriptor  okay so let's open a particular file called alice"  i'm going to open it as read only and then i call mmap  so i'm going to map today one page 4096 bytes and then we can talk about how we want to use these bytes and uh we've got three little bitwise flags that we or together  so there's proc read, proc write, and caught exec yes! i want to execute my files! my bytes1 off with the head said the queen what's the purpose of these bits? do they affect the file on disk?  no, remember with virtual memory we actually declare how our process can use different pieces of addresses yes we can have some addresses that don't map to any piece of physical ram  other addresses might map to some physical ram that we're sharing with hundreds of other processes for example, lib.c, the c library lots and lots of processes want to use the code inside that so rather than having multiple copies inside our physical ram, we just have one copy and have lots of mappings to that for that physical memory to be secure then  we better make sure that all of our different processes can only read it also, we can have another layer of security to say 'actually we're not going to let the cpu execute opcodes from arbitrary pieces of memory'  so we can actually say that our memory is executable or not  so we're not going to put any executable code in today, we're not trying to build say a virtual machine that's going to compile source code into executable bytes today we just want to have some memory that's read or write okay  so i've got two examples here  one where i've got the text of alice with the looking glass  another one where i've got the text of justin bieber's best lyrics  it's a very short file and you can tell me which one of these will work and which one of them won't and why so there's a clue  one of these will work one of these won't yes! yes! right! so we've put some options to say that we want to write to it   and in fact here we are trying later to write to it look i'm just using a pointer into memory and i'm trying to write the first two lines of the jabberwockee poem but i said that my mapping should be shared  in other words changes i make to my virtual memory  should eventually be pushed back into the file  and if i try to do this here's what will happen mmap will fial and in fact i'll get back the address negative one so you'll often see code that compares the pointer to -1  if it is, then we know that mmap failed 
now my code didn't attempt to do any error checking, so i'm just trying to strcat straight into this address which would be -1 and so i will probably get a segfault  in my code  um, i didn't talk about map file and in fact map file is the default and in fact you can it's not necessary to specify but you'll notice that all these things are bitwise OR-ed  so we build up a single integer that represents all of these flags right so, we've got this one we've shared this one which is map private and here's the great thing is that when we specify map private it means to this particular process so we can read justin's lyrics if we want but fortunately we think they're a bit of a cow, so we can do copy on write so we can actually overwrite to our heart's content all of his lyrics if we wish to unfortunately, we can't change what comes what comes out of his mouth he gets to keep his own copy of his lyrics file we're only going to change what's inside ram what's inisde our memory so this is allowed, this is okay even though we said that the file itself is read only and we want to write into it  we're doing that because memory is private and so we get to store our own copy in memory okay um  if you do want to write, once you finished changing things then it's important to call munmap  to release these resources right to say 'okay i've finished with this particular mapping' at which point the system may get around to writing it out to disk if you set it up that way but it doesn't have to immediately and in fact for performance there's no reason  why it might do it between now and some point in the distant distant future  so there's one other useful thing i'm not gonna test this but hey if you ever use this mechanism  if you want to force your changes to be sent back to the file system  call msync it's like nsync, but more musical i'm sorry terrible joke,  right, is that how you spell msync? who knows. okay, they're a boy band, they were allegedly popular  i probably misspelled it  anyways, so! yes, do this but realize if you call msync to many times then you're going to have slow performance because then you're waiting for your pages of memory to be written back to disk  okay, so  we know enough now to start playing with mmap  remember if it doesn't work actually find out what the error message was and think about your options what kind of memory mapping do i want to use so let's use this  and this hints now for how we're going to create our first tim berners-lee kind of web server let's say we want to serve a file back to a client  we actually want to send some bytes we've already made our socket code and we've already set up a file descriptor so somewhere previously i've done something like  okay let's do fd-open on something i've got back from my accept call something like that  so now i can start receiving and sending bytes using the c library to the client and now i want to send the file  okay, so the http protocol says you should write a few lines of text at the beginning like the MIME type, like the content length so yeah pretend i've written those lines now i just want to send the bytes, okay here's how we can do it first of all remember stat? let's use stat to find out the actual size of our file  then i'm actually going to open it so i just need my read-only flag here  that's easy enough we've got that up there and then i want to map that into memory okay this is where you come in what would you write have a look up here to see if you can figure out the options  what options do you need? because once you've got that pointer, we'll check if it's not equal to -1 we can just call fwrite to send those bytes in memory! we'll say look here's the bytes i want to send, send me 1*this number of bytes, and send it to this file descriptor bam we're done! we have the WWW thank you very much i am tim berners-lee anyways, so, right, or you've got missing just this line, so this is the one line that's missing between us and finishing our WWW web server alright, now it's up to you. what are you going to write in this line? take 2 minutes to see if you can write this line  you can write it down here if you want if you're out of space what options do you need for mmap?  okay, so what do we need? right i'm not going to spend any special options today, we need to pass in how many bytes we actually want to map from the file we only want to read through it 
and  actually we could write map  shared map, private, it doesn't matter in this case because we're just going to be reading or writing, I'm sorry, just reading from it and we pass in our file descriptor, here we go, and we don't need any offsets so something like that should work and we'll check to see if that gives us back a reasonable address pointer and if it does great i have immediate access to the bytes in that file don't forget at the end to use unmap and munmap or else very quickly you're going to run out of virtual memory when your WWW project becomes popular okay, right so let's have a demo now of actually using this to talk to two different processes great, so here's my program if we wanted to quit, we could print say the line number of where we failed  so i'm going to in here see if my mmap failed and if it did i'm going to simply quit and my macro quit will include the file and the line numbers so in debugging this, i can see where the problem is alright so let's have a go at this  i'm using map_anon because i'm using this on os x (on a mac) and i don't have a file descriptor to pass in because i'm just trying to communicate between a child and a process  okay, so once i've got the address, here's my plan  i'm going to treat it as pointing to some integers  then i call fork and now i have two processes  in the, in one process let's see what have we got so that's the parent process, so in the parent process i'm going to write these two values 10 and 20 and in the other process okay, here's my attempt at synchronization, we're just going to sleep for a second to make sure the other process has finished  and then we're going to read the values of shared so i've got two processes remember but they're sharing one frame okay, so we'll add those together and see what we get  okay, do you think this will work? let's have a plan, see what happens alright, so we run gcc invalid argument and of course we've got a crazy address why, what did we do wrong?  okay, here's what we did wrong, you've got to choose one, you've got to choose either shared or private so in our options here we we definitely need anon or anonymous because we don't have a file descriptor but we have to say  an options, so suppose we did private, what do you think the result would be ah, we got 0 in the other process! why? because we made it private! okay, what we wanted was... we shared the memory, okay so let's fix this and a second later, yay! great!  right, so there we go, we've managed to toggle information using memory mapped operations between one process and another process  pretty cool huh? well i think it's pretty cool and i think memory mapped files are fantastic when you have a lot of binary data or text data  and you want to be able to write simple code to read it and manipulate it  you'll often find it's very very easy to okay just map the whole file" then call strcomp or call a regular expression on the whole file and we'll let the virtual memory automatically load those pages into memory for us okay any questions about mmap? okay, right, time for part two! this is one of the few times i'm going to use powerpoint, so sit back, relax, turn your brain off you know how i feel about powerpoint, but i've got a few things to say and i've got a few slides which are actually useful we're going to talk today about file systems from a very different perspective  i'm going to talk about file systems by what can we do when think beyond just a single disk and how can we make our file systems robust? okay, this is not a new question, and one answer to this is RAID so we'll talk about RAID and then at the very end of this i'm going to talk about well suppose your problems are bigger than just a single disk array  suppose you want to start a company like Google how can you make a file system that works even beyond a single data center? so what do some of those challenges look like? and i'm just going to cherry pick a few items out of that and give you a reference if you have intentions of building a file system or building a company as big as google right so let's talk about RAID you've probably heard of RAID, it's relevant today even if you're using RAID, but i'm going to talk a little about the history about where it came from  it comes from redundant array of inexpensive disks  so here's where what we got there, first of all due to moore's law where we can pack more transistors on our silicon, and so we saw CPU speeds doubling very quickly however, disks themselves were not increasing in speed yes we learned how to pack more information on them, but the time to access any one piece of information was still dominated by the speed it took for the disk to rotate around so you've probably heard about say 7200RPM or 10000RPM  this sounds like it's spinning very fast, but if you work that out in terms of milliseconds, it's still a long time before it can rotate back to the right spot so we have a rotation time and seek time of actually physically moving the head to the right track on the disk, it takes time even if you can move it very quickly you still have to allow for it to settle so disks are slow  so why don't we spread our disks over multiple disks?  secondly the cost of our disks started to fall dramatically so it became apparent that rather than having one massive really reliable disk, let's actually use cheaper more commodity hardware and instead think algorithmically of how we can improve the rather vile reliability of our data stored on disk so that's just a little bit of historical backdrop
okay, so what are we going to do we're going to take our data and push the bits somehow across multiple disks multiple physical disks and in that way we should be able to improve performance because now our i/o channels are talking to multiple disks simultaneously however, our disks are unreliable and if was to buy a disk today, the promised 30000 hours of performance before it failed, then if i had 100 disks that means that i expect my data on average to exists for two weeks before probability before it goes bad the thirty thousand hours is not a big figure as soon as you have large disk arrays okay if you're wondering how big is thirty thousand hours, if you work forty hours you get to about 2000 hours per year  if you work 24 hours a day you get some small multiple of that so we're talking about a disk that supposedly lasts a few years and as you can see we've shortened it down to just two weeks  so we're going to have to think about how it'll solve this problem of making sure that our disks, our data is reliable if we have a disk failing on average every two weeks okay, so one thing we could do is simply copy the data to two disks! this is called mirroring and you today can go and buy little enclosures that support RAID 1 and all they have is two identical disks and they send it to both and if one disk fails then it doesn't matter you've still got the data on your other disk hopefully the disk array tells you when one disk has died, and hopefully it tells you which disk has died because you're going to be replacing one of them right? so the good news is that if i do this, then my reads are suddenly typically twice as fast! because now i've got potentially two different disks from read from  so i can actually execute two reads concurrently at the same time and using the disk however in terms of writing i've got to bring both disks into sync and then so i have a lowest common denominator and so my writes are no faster plus i've doubled the cost of the storage and that's a hard pill to swallow, maybe we can do better than that well anyways there's RAID 1 alright, today i'm just going to talk about RAID 1, raid 3, raid 5 I don't want to confuse you with too many different levels, so we can at least see how these things were solved right so RAID 3 let's use parity codes and for this example we're going to choose odd even, we'll chose even parity  which means we're always going to write an even number of 1s so if you give me a value that has an odd number of ones in binary data, then my parity bit will also include a 1 why don't i do that, well that means that i can recover my bits if any one of those bits are lost does that make sense? alright, didn't we play this game inside CS 125 right?  here, let me write down a number, here it is, and i'm going to make sure that i've written an even number of ones okay, there we go so here's the number you gave me, here's my parity bit if somebody came along and said haha! you can't have that bit anymore i'm not gonna tell you what it is then i can look across all of the bits i wrote and reverse engineer it, right? I can say oh look i've got an odd number of bits and therefore this missing bit must have been a 1 great, so here's our plan, is that we'll buy another disk to store our parity bit in  and we'll have a say disk for every other bit so in my little example, if i'm writing bytes, octets, then i just need to buy 9 disks so i've already increased the cost of my system by one extra disk yes, the disk has gone  there is no disk, right? it's died we're not trying to deal with bad data, we're trying to deal with missing data literally the disk stops spinning it gets hot, whataever, right. it just makes awful clunking noises and refuses to talk yes, yes, right so this system's only good for being able to recover one bit  right, so i would need all of these in other disks alright so i have my disk 1, disk 3, disk 4, disk 5, disk 6 okay any disadvantages to this? it's pretty cheap, yeah, but now my write performance is limited because i have to always be updating parity information as well okay so here's a little attempt with this. suppose i have a 4 bit computer and 4 bit data  then i've got my four disks, my data, and a check disk as well for storing the parity bit so if i'm storing this 1001 great, that is already even, so i can just write zero, and in these other examples there is say for the light blue one i wrote an odd valued value, so my parity bit, my check disk, includes a 1 right, let's kill a disk there we go. right so you now believe me that if one of my disks dies, oops, there we go. suffered from a small nuclear explosion then i can recover all of the data that was actually originally on that disk by reading all of my other disks  i can now write a little process and reverse engineers what should have been written on that disk 2 and i do that for my entire data set okay there any problems with this? let's think about the chances of another disk dying whilest we're trying to recover the data so we've got this mean time to failure  and mean time to repair  and yeah we can recover the data but it assumes that bad things don't happen whilst we are doing the recovery process  so with raid 1, we'd copy all of the data off one good version back onto a new disk with raid 3, we need to go through all the data on all the disks using the parity to recover it
so um what is this probability  well this is a worked example of the probability of a second failure is determined by the time to repair  divided by the mean time to failure divided by the number of disks and so if we plug in some typical values then we discover we've got a .009 chance of losing all of our data of that one of our disks dying whilst we're trying to recover our data it turns out that this mathematic figure is completely wrong it's not true in real life have you heard of murphy's law? murphy's law turns out to be extremely true for RAID disks  if something goes wrong, and there's other versions that say look if bad things happened once they're going to happen a second time or similar chinese proverbs as well why do you think the second disk dying whilst you're trying to recover is much more likely? there's actually two reasons, yes! yeah, thanks! look if disks had been bought from the same supplier, from the same batch, they're probably going to expire about the same time you know that little bit of grit inside the bearing that caused it to heat up and eventually warp? well that's caused because part of the manufacturing process is sprinkling grit on that spot and if one disk fails after 2000 hours, then probably another one as well the second thing to realize is that this repair process is really hard on the disks  you're going to reading out all of the data and probably trying to use the disk array for whatever production requirement you have at the same time so not only are you trying to sweep through the entire data set, your production process is saying yeah i need this data i need this data i need to write this I need to write this so you're stressing your disk drive much more than normal operation so another department inside this campus experienced this very same problem and it turned out that even though they had RAID, their two mistakes were a) to assume that RAID was perfect and b) not to have any monitoring to tell them when their RAID had failed and so they experienced this very problem that during the repair, a second disk failed, and that was it it was gone and their backup was several months old, whoops alright, so um back to our RAID 3 our performance is only so so because we need to update the check disk for every write right so lastly let's look at raid 5 and raid 5 mixes it up a little bit  or actually literally here's the trick: for different data blocks we'll put the parity bit inside a different disk  we're interleaving the parity across multiple disks  so now we've reduced the bottleneck of storing all the parity information on the same disk and in fact we can now allow multiple reads and writes in parallel right so that's the short intro to raid 1 3 and 5 that's all i expect you to know for cs 241 let's stand back even further and actually talk about a bigger problem which is  okay how do i make something which is even bigger than a data center if i want to have a file system that spans planetary sized data so for example, you're google and you're storing everybody's gmail and you thought running out of storage space on EWS was bad this is from a google engineer you know you have a large storage system when you get notified at a petabyte of storage left I wish I had that problem on my laptop, right? I'm sorry, I've only got a petabyte of storage left. so how could we build a file system that is at this scale?  okay, well what kind of issues do we have? yeah we know that disks fail  and in fact google takes the approach of buying very low commodity hardware and expecting failure and instead putting software and algorithmic refinements on top of commodity hardware  the stories of when google was scaling up other companies couldn't believe the trash that google was bringing into data centers why are you bringing in that old dell box? don't you expect it to fail? the google guys were like yes! we expect it to fail! but that's okay"
they were more interested in keeping their costs down so they have hundreds of thousands of disks and so we expect a large number to fail but it's not just single disks failing, we could have a whole rack go out, power could go out the network cable could be severed. the network port could go bad. etc etc etc all of these things could take down parts of our file system and we need it to be resilient to these kinds of problems at different levels so how do we do it okay, back in 2001  the google file system was pretty simple hey let's just keep 3 copies of every file and we'll put them in distributed places so we'll have one in the east coast, one in the west, and one i can't remember and google at the time was pretty america centric these days google has much broader reach of course and much more of its data is stored outside of the US so what do we do we use something called reed-solomon codes, where rather than storing at actual data that you wish to store, we store an encrypted or transformed version of that data and that transformation uses our s codes now you've actually already played with reed-solomon codes if you have a) played a cd  the data on a cd uses reed-solomon codes because CDs get stretched in fact reed-solomon codes can cope with a scratch up to about a millimeter or so or b) you have communicated with a space probe so, if you've talked to voyager, or mars path finder, you're using reed-solomon codes i imagine a is more likely than b, but you never know! this is uiuc, right? these codes then are very good with bursty and unreliable and missing pieces of data and what's amazing about these little mathematical objects is that their expense is pretty lightweight that space trade-off of reed-solomon codes is pretty small so we use reed-solomon codes and we only need 1.5 times redundancy  so that's how google solves it i've put a link in these slides for those who are interested in this stuff there's lots of great sort of war stories and tidbits about this but here's what you need to know for cs 241 is that we need to think about file systems beyond a mere data center and  one of the approaches to cope with missing data is to use coding theory and to represent our data on the disk okay, right, so that's all i've got for today have a wonderful week and have fun tomorrow in section finishing a streaming webcam and also writing the WWW project and finishing the web server
[introduction] alright good morning and welcome to the signal version of CS241 here's what we're going to do today we briefly talked about signals way back at the beginning of the course cast your mind back to when we were creating processes and we said that hey when a process dies the parent gets notified we get a SIGCHILD right? and we talked about SIGINT for when you press control C as a way to stop a process or if you want to stop a process and you don't want it to prevent you you would call SIGKILL yes? and SIGKILL you cannot catch it you will terminate that process there's actually quite a bit more to signals and that's what we're going to talk about today and we're going to show you how to prevent signals from arriving at your process we're going to talk about some of the terminology about this and finally how to do it correctly with threads as well right so I've got two signals here they are, oh I need a volunteer thank you for volunteering you look like your busy, in fact, thank you for volunteering as well okay right a signal remember is an interrupt so we can interrupt a process from doing something by throwing a signal at it okay so here's an I not for illinois but for SIGINT right there we go okay so come over here you're the kernal thank you, here's my process okay and of course if I type control C we can deliver the signal to the process throw it at them ok look he caught it, right it appears that this process has installed a signal handler and has caught the signal so we delivered it, the process caught it, but the process carries on right? it didn't stop there are some signals however called like SIGKILL that cannot be caught if we were to send this then of course we know that the process dies now where can these signals come from? they can come of course from the process itself the process itself could say hey I'd like to send myself a signal right? you'd like to raise that crazy idea yes? and in fact the system call to do this is called raise so if you call raise, what you're doing is you're sending a signal to yourself alright so if you were to kill yourself you call raise SIGKILL if you want to send yourself SIGINT you say raise SIGINT now here's the exciting part, is that actually you can block signals you can block specific signals here's your signal mask if you'd like to hold that in front of you the amazing thing about this signal mask is that it actually stops  well we can set it to stop a lot of signals but we'll set it up to say block SIGINT because guess what if we want to send SIGKILL I don't care what you do with your mask this is getting delivered SIGKILL you cannot block but you can stop SIGINT now if you set up that mask okay? what do you think is going to happen to the signal you're going to block it right? so it's going to rebound off that piece of paper good guess but not correct, here's what happens to the signal if you're going to hold this and look as if you're going to throw it at the process no just hold it like your like practically in a sporting magazine or something here's what happens, the operating system says okay you've set up your mask, here's what I'll do this signal is pending I'm ready to deliver it to the process anytime you drop your guard down so anytime this mask goes down, we're going to send a signal how are your arms doing? yeah okay right so I'm interested to see some of the terminology right? we've got a pending signal so the word pending is the idea between when we created the signal and when we wish to deliver it so what happens if you think at this moment in time we start pressing control C control C control C control C or we start raise SIGINT raise SIGINT raise SIGINT we keep trying to raise more signals do we get a backlog of all of these signals ready to be thrown at the process? hundreds of balls about to arrive at you any moment you change your SIGMASK and let through SIGINT actually no, there's not a queue of the if you have raised SIGINT, if you've generate a signal, there's only one SIGINT to be delivered whilst we stay in this kind of captured moment in time, think back to par shell and when we talked about preventing zombies yes and we installed a signal handler to catch sigchild right? there's actually a race condition, oh you know what a race condition means now there's a race condition, suppose two children finish at exactly the same time or close to the same time it could be that we've generated SIGCHILD here and we're not going to generate another SIGCHILD for all of the other children that finish at the same time so actually the code that we wrote a while ago is not sufficient because there can't be a queue of the same kind of signal I can still have other signals for example my SIGKILL and I can deliver that but there's never a queue of multiple ones okay why is this? well imagine in an implementation where these signals are really just little bits we've got a little bit ready to fly just like a hardware interrupt where I've got a particular interrupt coming from the particular device I've got a particular signal I want to deliver to a particular process now the other thing we should talk about is what happens if this process calls fork and this process calls exec what might happen to my pending signals? what might happen to my SIGMASK the other thing we have to think about is what happens if this is no longer just a single threaded process but now uses say pthreads what should we do there? so suppose you are a pthread process okay? so in other words you've been compiled with pthreads and now you call pthread_create here's what happens if you call pthread_create you've now got two threads running yes? here's the great news, the second thread inherits your mask alright? so now they're both blocked from SIGINT
what do you think happens if I change my mask? here's what happen: the signal will be delivered to the process and caught by me [something] okay right so the signal in this case was delivered to me right but it couldn't happen until one of us dropped our guard here you go catch raise that so right what do you think happens if we both get rid of our masks it's arbitrary, who's going to throw it? okay who gets the signal? it's random, whichever thread the operating system decides to interrupt with a signal okay? so that's the basics of signal, give our volunteers a round of applause thank you very much why the virtual demo? because sometimes there's more interesting than simply going okay here's the technical details  yes there's a lot of just little annoying technical details but that's okay because you're illinois students you're used to being annoyed oh wait, that's not right so I'm going to run through some of these details they are on the notes, they are on the man pages etc and there will be a multiple choice quiz on this and I'll generate the practice exam shortly alright so what have we got? let's talk about some of this terminology right so we've talked about generating signals what do we are doing? well somewhere deep inside the kernel we've got a little bit set that says okay we want to deliver this particular signal to... to a particular process what's it mean if a signal is pending? it's that time interval between when we've generated it and when we've delivered it to the process okay so it's the period of time... between when we generated it and delivered it we know what it means for a signal to be blocked now it means the process has a signal mask that is preventing that signal from being delivered it's like putting a stop on your mail right? we don't just discard the signal, it just waits until we can actually deliver it what does caught mean? it means you've installed some sort of signal handler and you've decided to take care of that, process that signal in your own fashion in your own special way and then finally disposition right how do you feel about lady gaga's music okay pretty bad at the front here, that's your disposition to that particular signal what' your disposition to this lecture good so far, okay, phew that's another disposition so our disposition is what are we going to do? how do we feel about a particular signal? you know that we can install signal handlers and we can have different actions that occur for different kinds of signals you know that some signals can't be caught but for all of the other ones we can set up a particular disposition so thinking in terms of an implementation you could just think of a disposition as a table of function pointers so one function for each signal in other words, if I get a SIGINT go in here and execute this code so when I install a signal handler, I am changing a particular disposition to that particular signal right so basically it's wutchu gonna do when you get a particular signal? wutchu gonna do when you get SIGINT, wutchu you gonna do if you get SIGTERM, wutchu gonna do if you get SIGCHILD, etc that's your disposition, the sum of all of those actions is your disposition to signals right okay let's have some guesses then do you think your signal disposition is on a per thread or per process basis? make your guess now and I'll tell you the correct answer in five four three and the answer is process! it's on a per process so signals are delivered to processes what do you think the signal disposition is of your child? is it reset to the default? or is it a clone of the parent? make your guess now and I'll tell you in five four three two.. it's a clone! or the same as the parent in other words if you set up your parent to say ignore SIGINTs when you call fork so will your child so this is a bit you know the apple doesn't fall far from the tree if you like rythm and bass, maybe your offspring will as well but if you call exec it's reset right, so now we can start talking a little bit about the code so where would I call SIGPROCMASK? when I don't want yellow balls thrown at me if you say that during an interview they'll think you're crazy right so what's a better answer for SIGPROCMASK? using the correct terminology of signals what am I doing with my mask? blocking, yes! we set up a mask to temporarily block signals
if you are working with a single threaded process and use sigprocmask guess what, if you're compiling with pthreads, then use pthread_sigmask this allows you to have different masks for different threads so now we can talk about whether a signal will be delivered for a multithreaded process and we saw that it will be delivered to one thread and it can be any thread that is not blocking the signal so what does this mean in practice? in practice this means typically in our initialization code before we called pthread_create let's just try and block everything, let's just serve a big mask and say hey we don't want to know about signals right now and then later in one particular thread, we'll say we'll deliver signals to this particular thread and we'll lower our guard, we'll lower the mask for that particular thread so what's it mean when a thread actually gets a signal it means that thread is going to be stopped from executing the code that it's currently working on and they are going to steal it we're going to use its stack to execute the code that we write inside the signal handler so anything it was in the middle of doing, let's say it was in the middle of malloc, let's say it was in the middle of updating a data structure that is put on hold whilst we do whatever is inside our signal handler this is why things can be signal unsafe suppose your halfway through updating your data structure or suppose malloc is updating its data structure and then you try to go in and do something to that datastructure whoops now you're reading and writing from the wrong bytes we can't use mutex locks for this to prevent this because we are actually stealing the thread in order to run our signal handler code so I'll talk about a way around this in a moment where we can take a lot more careful control about when and how we handle particular signals okay so how do I learn more about this? on linux, not on your mac, but on linux, in section 7, there's a whole long article all about signals so we use -s7 to say go to section 7 and we can read all about that so let's talk about appending signals remember appending signals is our signals we're about to throw and pending signals work in the opposite way to our signal disposition that when we call fork the new child has nothing on the other hand if you call exec some sort of exec call pending signals are preserved so that means you could do something like that following let's fork and then in the child... we know there's nothing appending yet because we've just forked right? so let's deliberately raise something here okay so I'm going to raise SIGINT now if I hadn't done a signal mask at this point that could be delivered straight away whoops I've just managed to control C myself but instead in this little example, we're going to suppose... we've already set our mask suppose our mask already includes SIGINT, in other words, I'm not... going to accept your SIGINTs right now, talk to the hand right? I'm blocking this but the next thing we do is we exec something wahahaha what happens now? pending signals preserved the mask gets reset because that's what happens when you... oh, wait wait I'm certain that if in my exec code, if that now changes the mask, it can get my control C, I could actually interrupt a process before it has even started up by generating a pending signal so my other process will get the signal later when the mask is changed and we won't say generated, we'll say delivered! so reasoning about signals and working with them is tricky because we have to think about the timing of when things happen and we have to be careful about what our masks are right so I've talked about pending signals if I want to send a signal, if I'm inside a multithreaded program I want to send a particular thread I can use pthread_kill if I want to just send a signal to my whole process I can send raise, if I want to send it to another process, I can use kill so signals are at the process level however, in a multithreaded process which thread actually catches them and performs a signal handler that you've installed is dependent on the signal mask of all your processes
right so we talked about creating signals and sending them let's actually work with them now I mentioned signals at the beginning of this class, I mean at the very beginning of the semester here's the bad news signal should not be used for multithreaded programs and in fact if you read the linux documentation it would typically say signal should not be used don't use signal! why not? well a) it's not really supported in multithreaded processes but also b) it's definition was inprecise so the way that signals are delivered on different operating systems is ambiguous so fine you managed to get something working on linux and that's all you care about use signal, but the better option is to use sigaction where we have a lot more control over what happens when we generate signals now in addition to installing a signal handler with sigaction instead of signal there's two other ways of dealing with signals, one is to create a file descriptor like a file, that we can read from a stream and what we read from is bytes that tell us about what signals have happened I'm not going to talk about it inside 241 just other than the fact that hey you should know about this and it's a pretty good way of working with signals so you could open one of these inside your own specialized thread and start pulling signals from that file descriptor and interpreting those bytes another way is to use sigwait where sigwait blocks until a signal happens and then it gives you details about which signal occurred and we'll have a look at that today in fact, let's take a break from a moment because I realize this is a lot of factual stuff and let you know about this so I've got fifty questions for you and this is going to be worth four percent of your grade and it's purpose it to help prepare you for the final exam so here's the idea is it's a little homework feel free to work in pairs, what i'd like you to do is actually try and research and try to understand the answers because we're not going to grade this purely on correctness we more care about the fact that you took the time into learning these answers because many of these questions come up in real interviews as well so I've got fifty questions for you, actually the fifty first question is optional it's this, it's draw an imaginary picture of you battling your most evil or tricky CS241 CS programming bug so looking forward to seeing dinosaurs or whatever however else you imagine working on that so can you give me a hand handing these out? here we go if you could hand some of these out for me that would be fantastic you will find that some of these are merely code writing exercises I encourage you actually writing out the code by hand because that's what you're going to do in the final exam some of these are based on information inside the wikibook and some of these will require a quick google search to find the answer maybe we haven't talked about it directly inside lecture yet feel free to write your answers in note form, like i said... this is about doing exam prep and getting points for it as well okay? so the purpose is to help you review the CS241 material yes I'll make additional copy right let's go to aux pc [silence] okay so now I've got the code version of the demo that we did at the beginning of lecture we're going to set up our proc mask, our process mask so that a particular signal can't be sent to our process, can't be delivered to our process right so what's the plan here? well, a long long long time ago, signal sets just used to be an integer however, there was a concern that the number of signals might exceed the number of bits inside the integer on any one platform so to make a more cross platformed solution we have this type called a sigset_t and then there are functions either set all bits, clear all bits, set one bit, etc etc etc we're looking at an example then when we are going to set all the bits inside this little bit mask and then we're going to use that and as you can see this sigprocmac actually allows us to discover the old signal proc, the old mask again so that later on in my code, I can restore the original signal mask so it's typical in well engineered programs then to at the very beginning of the process raise all the guards, raise the whole mask up so that... so that no signals get delivered early on, not until we're ready for them until we're ready to open shop right so we're calling sigprocmask we're saying okay I want to set the mask to my new mask so that's hey stop everything.... and then we raise SIGINT in other words we're pressing control C on ourselves we're trying to interrupt this process now as you and I know, because we set the procmask, that means that that signal is... generated but it's not delivered, it's in a pending state
so now we can carry on, let's change our signal proc mask to whatever it used to be we'll print exiting and we'll return zero right so let's see what happens, how far will we get in this program before it finishes? alright so we've sent out SIGINT nothing happened but then we changed the procmask again and that turned out to be our doom, our downfall by resetting signalprocmask to what it used to be, the signal could be delivered and of course what's the default behavior for SIGINT? kill the process. yes? there can be a delay so the system does not make any guarantees about when the signal will be delivered typically it will be as soon as you make an operating system call and that brings me on to my friday demo, I want to show you something really cool which is not directly related to signals but go on quick question yes, we're going to do that in a moment, we're going to make a thread to handle signals which is a nice engineering solution to working with signals but no I want to show you something called strace strace allows us to look inside the matrix, it allows us to see the operating system calls, it gives us a system trace of what a function is doing alright? so let me show you the code once more of... my little demo here, here it is okay we are going to set the um... called sigfillset, sigprocmask, we're going to write sending sig out, we're going to raise, etc so that's the code, now let's run this again with strace wahhhh lots of output okay, let's... scroll up here and make it a little bit smaller okay we can see every single system call that ran as part of this process you probably recognize quite a few of them right now first of all, what do we do? well after forking we had to call exec to actually load the process then we called break to discover where the beginning of the heap was we called mmap and we said we want to be able to read and write into this space we want it to be private, anonymous, etc  and just give me some space 4096 bytes negative one at the end tells me it's not associated with any file descriptor and then we call open on this LD thing and then we call fstat on that we call oh yeah it returns three sorry file descriptor three and then we call mmap to get that into memory give me a private copy with this file descriptor and here's the address that it goes in then we load the C library also file descriptor three because we closed it and we're going to mmap that so we're pulling the C library into our file system sorry into our virtual memory okay so we set up a few more memory mapped regions okay and here's the beginning of our code we are setting the signal masks see that puts being turned into a low level write call so a tgkill thing which is a low level version of our raise and then we set the signal process mask again and that's when our process gets interrupted by SIGINT so this is pretty cool right? you can actually see what a process does at the operating system level you can get between any process and all of the kernel calls that means that we can set our process up into lala neverland and make arbitrary return values to anything that asks for the system to do so strace is very powerful you can shim into every operating system call and see what it's being called with and see the return values right so that's our sigprocmask little demo let's go back to the handout right so I mentioned this hey instead of using signal, use sigaction here's how we use sigaction we need to give it a signal number and we also set up one of these structs struct sigaction with everything we need to do or we want to say what to do when a signal is delivered okay how do we set it up? inside my struct, I could have a regular handler just like we did with signal here's the function that should be called when the signal is delivered there's actually another function which allows me to get a lot more information about the signal but we're not going to talk about it in 241 but if you wanted to write a more complicated signal handler you might use this other function prototype instead okay what's different tough is that there's a mask a set of signals and these flags and it's important to remember to set up these other two items so here we go, here's some example code, right we're going to have our little struct we'll set up our handlers so that's our callback function let's do something with that mask I'll tell you what that mask does at the moment, typically you either empty it or fill it and then with our flags, typically you either set this to zero or sa_restart and then finally okay let's register for SIGINT this information so this set of signals does not affect delivery of the signal, this set of signals says what should be my mask when I'm actually inside the signal handler so for example, if I'm handling a SIGINT do I want to block all other signals do I want to prevent a SIGTERM from coming in now for our typical easy little programs naw we don't need to worry about them, we don't need to care about these race conditions but if you're writing something complicated when you might have to say prevent SIG control C but also make sure that realtime information, realtime signals are always processed then you might actually use this to work out which signals can temporarily block another signal of a lesser priority to you from being executed of a lesser priority to you from being executed
right so we'll just say hey we don't care we'll let all of the signals interrupt us right so that's a quick outline of this let's have a look at page two cause we're going to use it alright let's fix the code we wrote at the very beginning of the semester then when we talked about eating zombies how do we eat zombies? we call waitpid on them on the parent so our problem is that this signal handler isn't going to be called every time a child exits because if I have two children exiting at the same time, I might only get one signal remember? if a signal is pending, it has been generated I don't start queuing them up so if I had two children finishing at about the same time or if I have temporarily blocked all of my signals then.. then I want to be able to eat multiple zombies so here's how we can do that, the better code to do this then is to keep calling waitpid until there's no more zombies left to reap, until there's no more zombies left to find right so here's the typical way of doing this  there's a  flag we can put in here to say actually... don't wait just return immediately if there is no more children to.. no more zombies to find then let me know about it [silence] and so we better put this inside a loop so here's our plan we'll say while the exit value is a valid child address so while this is greater than zero then I know I've got a valid pid and go around again and eventually I'll run out of child processes to reap okay how we doing for time? good so now it's your turn can you remember what to put inside this? so we've set up our signal hander how do we correctly install it? [silence] okay right so  we've set up the handler we better set up this mask if clearing zombies is the most important thing and we don't want to be interrupted by anything, not even say control C then let's say that we'll set the mask... on a... let's say mask.. what's that? it's going to be sa.sa_mask [writing] and then finally flags we could just say zero but there's something that's useful for real programs which is sa_restart so if you install signal handlers with sa_restart you're making your life a little bit easier in the rest of your program if you were to read say about write or read other function calls at the system levle sorry, other system calls you discover that some of them will simply return immediately without doing anything and give you an error which is E_interrupted or E_retry and E_interrupted means hey I was interrupted by a signal so I chose not to do anything ah thanks operating system, that's really helpful why don't you try again? do you want to play again? and so we have to write code that checks for the specific error condition that says I was interrupted and I want to restart well specifying this restart parameter in here... makes our programming a little bit easier because the number of times that happens is reduced it's I'm afraid not 100% but, it does do the restart for you automatically on some function calls again it's not worth knowing the big list, it's just worth actually going to say man -s7 signals and reading more about it if you are interested
great okay so we've got time for a final little demo and what we're going to do is instead of the system stealing one of our threads to handle a signal we are going to explicitly create a thread that pulls signals one at a time and handles them so its more code to write but it's less likely to.. it own't suffer from asynchronous signal problems if we're careful about how we... process our signals so let's.. I'll show you what I mean so what we're looking at today is... using SIGWAIT and I'm going to put that inside a thread who's only job is to say okay tell me the next signal that's delivered we can tell it in this case the mask is which signals do I care about [silence] so if I get a SIGINT, do some code, if I get SIGTERM do some code so for example, Java, if you sent it a SIGHUP will print out a whole load of debugging information about the garbage collector and other internals of the... stack traces and other internals of the JVM the apache webserver if you send it a SIGHUP signal will reread its configuration files so that you can make updates to the webserver without having to restart the process and deny people that are currently connected to it so this might be a way to do this, you could say oh look if I've got um... SIGHUP if I get this signal... then print something out or reread my configuration data today I'm just going to show you a demo with just a couple of these and we've got a little default case for our own purposes that calls fprintf which we wouldn't call normally inside the signal handler because it could be that the thread that we've stolen it from is already inside fprintf or inside malloc etc but by using our own explicit thread, we can do this, we can do it in a safe way right so let's have a look at a demo... yay okay great right so here's our plan we will set because we're a multithreaded process we will set our sigmask before creating other threads so that when we create a new thread, it inherits the same mask and our default mask today rather than just saying okay ignore everything what I'm going to do is addset and just put in two bits the bit for SIGINT and the bit for SIGTERM that means that if someone sends me a SIGINT of course there's no thread that is prepared to catch it both threads are blocking these signals and here's my application code sleep one, print dot and because I want to see the dots immediately I'm turning to my C library to immediately flush anything inside the C buffers so we can see the dots appear one a second and inside my thread, here we go, today I've got my... my important code that's going to present some debugging information what is that? oh it's just the name of the signal that was delivered okay so let's compile this right if I was going to compile it... like this, what will we see? it will complain right? undefined reference no one defined pthread_sigmask what we forgot to do is to tell gcc that we're trying to compile a multithreaded program so... here we go let's give it a pthread option good and now we've got ourselves a little demo and every second it's printing out dot and then flushing the buffer so if we now send it a signal... our single thread wakes up, returns from SIGWAIT and runs the code inside that case statement which just prints out SIGINT where did the control C come from? oh that's just the shell telling us that it sent a control C and so I can say ok stop stop stop stop stop and of course it never stops alright and but I can still call SIGQUIT and that will terminate the program and with that have a wonderful weekend and I'll publish a online version of these questions in subversion. thank you very much! thank you very much!
[silence] alright good morning class, how are you? hello myself how are you? right I am great thank you let's try again, good morning class how are you? okay great so here's our plan for today, we're going to run through and talk about these final exam questions if you're sitting by yourself please move until you're sitting next to somebody if you worked on these questions with your neighbors why not find a different neighbor that can maybe give you insight into the things you thought you knew and the things that you didn't think you know so please find some interesting neighbors at this moment secondly, I'll give you some tips on doing the streaming merge sort I'll talk about MP deadlines, we'll do an ask me anything and if we have time we'll do some tips on learning and prep for the final exam right so at this moment please find a neighbor and we'll take a few moments for you to compare answers and find out ask your neighbor stuff that you were unsure about [silence]
[silence] here we go so I did a quick poll to see which questions people would like me to go over in lecture I'll get through some of them today, others we'll get through before the end of the semester here's the game is that this is all stuff that CS241 UIUC students should know, it'd be embarrassing if you graduated and you didn't know this stuff, if you weren't able to explain it to other people say... in an interview or if you're on a team and you're getting more mature right? and so the idea is to say look this is less about okay learning in the classroom and you should start to be independent learners and also kind of use each other as resources and of course we have the wonderful WWW project with all sorts of factual information out there so I'm going to encourage you to actually be able to be independent researchers when it comes to CS knowledge okay so let's go through some of these but first let's take a little break and talk about what's coming up next week right the big one is the key value competition the very last MP is due at the end of the semester so Wednesday one minute before midnight all entries before then will be graded realize that if a hundred people were to submit at that moment, it would take say three minutes times one hundred, it'll take over 300 minutes before you see your result so if you want to leave it to the very last minute, be my guest, but realize that you're playing with fire you may not have a second chance of course to fix anything so early submissions you should see results early late submissions it'll take hundreds of minutes before you see a response before all of that, here's some other good news hey guess what there's going to be a last chance perhaps you got a zero on the MP because you were busy doing something else right or just made a silly mistake or don't panic you can still reclaim 75% of your points if you've already got at least 75% on a particular MP, you can ignore that MP and of course take the maximum of these grading runs and all prior runs so for everything except key value this applies on Monday, if you didn't finish MP merge part 2, here's your chance and by the way, we have made MP merge part 2 a little bit easier to earn for points if you can pass part two you get 95%, if you beat the TA's solution, you get the remaining 5% in the very first run of MP merge streaming, only 25% of the class were able to succeed at this task which it was a new MP and actually to be honest, it surprised me that it was hard so today I'm going to...  today, however, one is I'm going to give you a couple of hints and secondly you're different people than before right? you're brighter, smarter, better looking, ah that doesn't matter but you're brighter and smarter and so you should now be able to finish MP merge part 2 and do much better than you could than at the beginning of the semester right so we'll come back to that at the end of this class if you already did well, we're going to give you some bonus points instead yes at the back? uhh I believe there was a context page and I heard this anecdotally from the grading TAs, that only 25% of students... but I tell you what, I will ensure that an email is sent out in the near future certainly before the weekend okay right so yes I realize it's a busy time at the end of the semester, that's kind of always how it works isn't it? so see my FAQ, help I'm working too hard, yeah I'm sorry learning is hard right? also don't confuse recognition like oh I know this I have seen this before with actual ability to do something... yes? yes there will be something on piazza very shortly or the home page to say the URL for that similarly a URL for the key value as well alright so as you know, there's a big difference between being able to say oh I recognize this to hey I can actually recall this vs hey I can actually use this information vs I can actually debug a version of this vs hey I can create something based on this which satisfies additional constraints right? we're talking about different levels of  bloom's taxonomy of understanding and learning
right so yeah learning is hard I'm sorry if I knew a way to do the matrix for instance I know how to do systems programming, that would be fantastic but we can't do that just yet right so let's have a look at one of these problems today and this will actually help with the rest of the homework which is perhaps you can do this, I'll give you the answer in a moment, perhaps you should be able to do this, this is actually based on a final exam question remember the bitwise operators? these are not the logical operators, these are bitwise operators so we can use ampersand & for masking for example this is or | left << and right shift >> or right shift and left shift and so we want to use these to write some pseudocode as to how the hardware works right? can we actually write some C like code that would convert a pointer here it is here's my little pointer to one byte and determine the page number and the offset right so this shouldn't be too hard if you know your bitwise operators I'll give you just 30 seconds for you and your neighbor to have a go [silence] okay so here's the plan, we think of our virtual memory address in terms of two halves the lower bits will be our offset and we're just going to ignore those for a moment they'll come back to play at the very end when we add them back in and we've got a page number as well so the upper bits are our page number right so we can use our bitwise operators to extract this from our single pointer for the offset we want to write a mask so that we only see the lowest bits so we're going to say pointer & and now I want something that represents the twelve lowest bits, in other words if I was writing in binary it'd be 1 2 3 4 1 2 3 4 1 2 3 4 so that would be my binary representations and all the upper bits would be zero right can I convert that into hexadecimal remember hexadecimal each hexdigit corresponds to four bits right? so we should and it with 0xfff and the upper bits of this number are all zeroes right what about the page number? I want to take these bits and shift them to the right twelve times well I could divide by four thousand ninety six but instead why don't we just shift there we go so now I've got my page number if my hardware implemented a single level page table I could then use this to look up an entry inside that single level page table that would give me what? what's it called? what do we get when we look inside the page table? the frame! yes the physical frame so if I still use this, look it up inside the page table, I get a physical frame if I take that frame, I can now combine it with the offset to give me the actual address so the final address.. would be... take the frame shift it... left by twelve, put it into the right place and or it or add in the offset and that would give me the actual RAM address, the actual piece of RAM that I want to read or write to of course we're writing C code, my assumption is that our hardware engineers are not writing C code, they are probably writing verilog or vhdl or some other lower level hardware language alright so let's see if you can play with page tables then for this little example here's a virtual address this time I've got eight bit pages, they're tiny, and the following page table so using this, what is the physical address associated with this virtual address? so we're going to have to take this address and cleave it into a page number and a offset [silence] and the answer is... it's a trick question, you can't answer it yes? because... where's the offset going to be? the offset is going to be the lowest eight bits so the upper hexadecimal digits are your page numbers and I didn't give you... enough entries of this table, its somewhere off here so I didn't actually give you this particular entry right so let me stencil it in, so somewhere deep, much lower in the page table, there happens to be entry number 010203 and if we were to look up there and we found an address like... BAAD now you can tell me the actual physical address, I've got to take this and combine it with the original offset so in other words, the final address will be BAAD04 would be our physical address
questions about that? so you see when you use a page table things are slow because our page table itself is stored in memory so anytime your process wants to do anything read or write a piece of memory it first of all has to read this memory of the page table in order to calculate where to go in memory you've slowed everything down so to speed everything back up, we need a cache, what is that cache called? yes the TLB, the translation lookaside buffer because most of the time when we use an address, we use it again in the near future and so hopefully we have a cache hit, hopefully we have a high likelihood that we don't need to actually go back to our table to discover the answer so the TLB is part of the memory management unit, its job is to short circuit this lookup so that we can actually have good performance alright what does peterson's solution solve? do you know? does your neighbor know? if your neighbor said the critical section problem, congratulations you should sit next to that neighbor in a future class yes the critical section problem how dare I ask questions which are from weeks and weeks and weeks ago here's why, if you want long term memory of CS241 content the best way to actually learn something for the long term is to use your long term memory and so I'll be talking about that in terms of revision for the final and beyond right so it solves the critical section problem right malloc is thread safe but not signal safe the malloc you wrote was not actually thread safe but now you know about mutex locks you could have written a little lock and unlock around your code and made your malloc thread safe but it's not signal safe why? what's special about signal handling that's different from threads not quite yeah you're interrupting the process okay right yes you might interrupt malloc whilst it's executing malloc code reenter malloc and the data structure could be in a inconsistent state so it's a bit like... an analogy here might be you have a whole load of chefs coming in so you say I tell you what I'll have mutex locks so that only one chef at at time is allowed to use my kitchen so that's thread safe with signals, what you do to the chef is you say actually hold on chef I'm going to get you to come back to the room and cook this different recipe they walk in, there's the same thread, but now the kitchen is in disarray, the oven is already got something inside it, already set to a particular temperature and now your chef attempts to use these resources whoops, we can now get our memory data structures into an inconsistent state or we might try to lock a mutex that we've just locked resulting in deadlock because we were the thread that actually locked the mutex right and... here's one little challenge for you, okay think back in time to sempahores how do semaphores work? remember they don't let their count go below zero if you call sem_wait, it might block until someone else calls sem_post so I'm going to finish this code to make a barrier or rather you're going to finish this code to make a barrier what I want is so that the first four threads when they call this code are blocked but when the fifth thread arrives they all may continue but not before alright so how are you going to finish this code and what are the initial values for sempahore a and semaphore b alright this is a timed challenge you've got until I've done two laps of this and finished singing ackey breakey heart fortunately I sing very quietly  [silence]
 alright so we've got five threads walked into a barrie ow! what do we have going on here? well each time they walk into a barrier, they try to wait on A and then they increment a count if the count is something, hey let's post to the other semaphore and then let's always post to something else so this first semaphore sA looks like it's being used to define a critical section why should this be inside the critical section? we only want one thread at at time to be incrementing count or checking its value so if we make this post back to A then we can ensure that one thread at a time is incrementing the count so we can't have a race condition so that suggests the first value of sA is what? one, yes! so we allow one thread through but if another thread comes at the same time, it's forced to wait until the first thread has posted right so we're doing one at a time right now we said five threads so this is going to be if our count has gone up to five cause we're doing it after we've incremented the count what do we do? we post to sB this suggests if I want my early threads to wait... maybe I should set this to zero because why don't i wait down here and I'll wait until that count is incremented to one okay does this code work? does it let through any threads before the fifth thread arrives? can any threads get through? if I send it four threads can any of them get through? where do they get stuck? yeah the sem_wait waiting for sB so the first four threads get stuck at that line all waiting for the count to go up by one but on the fifth thread we call sem_post great we're done right? our code is complete. actually what happens instead? yeah one thread is lucky the other four not so much, one thread is going to say great I was able to continue the other four of course are going to wait forever but there's something we can do to that one lucky thread that is going to give us a domino effect right? and that is what? let's sem_post so as that thread walks out the door, it bumps up the count again freeing the next prisoner that prisoner, that thread walks out, bumps up the count, freeing the next prisoner and so on and so on until we have all five threads have left our barrier so that's correct code, what would have happened if we had switched these two around? perhaps you can explain it to your neighbor and decide if your neighbor's explanation is any good so what would happen there's not a barrier anymore, yes, before we called sem_wait we've added one to the count so now every thread will simply get through the moment it arrives so it'd be a useless barrier alright thanks for playing today's review questions right so let's talk about some other stuff first of all Monday I'm leaning towards having no quiz on Monday, no more quizzes but I'd like to just take a quick survey, if you would like one more quiz this semester on Monday do this, this way, if you'd like no more quizzes for the rest of the semester... do that Yes I'll still be dropping three the last quiz will be a quiz of all possible questions okay is that sufficient information for you to be able to make up your minds are you ready? go [something] has it, there were more people pointing in that direction so there will not be a quiz next week, no more quizzes right the next thing we'll talk about yes you can generate your own quiz simply by concatenating all possible PDFs okay so let's see we've got... we've done MP deadlines, streaming sort, oh yes right section tomorrow, section there is no prep for section, in section you will get your webserver finished we may add one small little thing to it as well and then the rest of the section time will be spent on MP development and MP finishing and MP questions plus there's an opportunity for you to give feedback on section experiences back to your course assistants etc so please come to section, also please bring your answers to section for points right? to get the four percent, bring your printed copies to section thank you very much right okay [silence] right once upon a time I had some data and my data arrived in chunks here it is there was a little callback that said hey I've got 256 numbers for you before returning, you have to copy those numbers out into your own area because by the time you return, that little buffer is going to be overwritten with the next set of numbers so that's the callback, to be given all of these, unfortunately you didn't know how many times you're going to be called back other than the fact that to make the MP simpler there was going to be 2^n number down here so it might be 4 6 8 16 32 etc etc etc
so our task then was to turn this into a merge sort problem in other words.. that two neighboring chunks of data should be combined each individual chunk was sorted using queuesort and we had say eight threads available to start doing all this merging now the naive TAs solution was actually not that hard to beat here's all it did it simply copied all of these into a large array and we made a fair guess about how big a size it should be but we did use realloc just in case the data was going to be larger than expected but we didn't start off with something small like hey 16 or 32 we gave it a big number because if realloc does need to realloc for space then it used to call malloc, it needs to then do a memcpy to move all of that data and talking to memory is slow so we made a good guesstimate about how big a buffer we would need it simply waited until we got all the pieces and then it used the part one code and then it printed out the whole result right how can we do better? in this regrade of this we're actually going to put in a small delay between each one to assure that there's actually some significant computational time to work on these items so some things that we can do which are better, obviously we've got 8 threads we could get started sorting this data before we see the very last piece of data the other thing we can do is at the very end we could actually start printing the results before we finished the final merge so in the very final merge, as we're pulling these two yellow pieces together if I got to here, I don't even need to write this data back I could be printing it out to a file as I merge these results together, so there's actually two optimization ideas right so what's the simplest way of doing some of these early merges well one is to say hey doing this stuff thinking about all these different levels is really really complicated for my tired brain and so get something simple working, here's a really simple idea is look at these in pairs look a lot of merging actually just takes down here at the smallest level so we could get some speed up just by thinking about these small blocks right so every time I see an odd numbered block, I'm going to start off the merge process to make myself a bigger block and so I could probably write that code just to deal with these smaller blocks the accounting, keeping track of all the statuses of these little blocks is not too hard and then when I finish making all of my lighter blue, my cyan blocks, then I'll just... give the rest of the problem to my original part1 code and just let it run through that right I should probably stop here because unfortunately... you are all two bright, you want to do better than this here's the danger, A writing C code is hard I'll give you an example of that on Friday when I talk about Toyota's C code and their embedded code inside their memory management unit various swear words have been defined to describe just what a mess this C code was so that's the first thing, look writing C code is hard, writing any code is hard second is that thinking about this algorithm is hard and sometimes it's good just to come up with something which you have high confidence in working, get that working and then have a go at something more complicated so I'll give you some hints about something that's a bit more complicated without going into a full algorithm and it's this let's label our blocks 0 1 2 3 4 you get the idea and also, we'll keep track of the blocks as to how much data they contain which is sorted so initially after we've done the queuesort I've got one block size of data and later up here I've got two block sizes of data so if I keep these labels then my labels correspond to where my blocks start in memory so let me call this block 0, this block 2, this block 4, this block 6 if I do this, then I can make the following observation my block size gives me a strong hint to which pairs I should be merging together so for example, on my cyan here, if I gave you block 4, you could say oh you should be merging that with block 6 if I gave you block 6, you could say oh you should be merging that with block 4 once they are of sufficient size so if I gave you a block 4 of size 2, you'd say okay great that needs to be merged with block 6 of size 2 if block 6 of size 2 is not yet ready, then do nothing and we can go the other way, hey here's block 6 of size 2, you should merge with block 4 of size 2 if block 4 of size 2 is not yet ready, do nothing, don't panic, don't worry about it because at some point block 4 will be ready in the future and it will merge with me
so how can I determine which blocks to put together okay let's have a look at this one, this is still zero and block four but this time the size is size 4 so if I gave you block 4 of size 4, you would say oh you should be merging with block 0 if I gave you block 0 with size 4, you'd say oh that should be merged with block 4 okay have I given you enough examples yet to see how we can determine which two blocks should be merged together I'm using exclusive or I'm xoring with the block number, the size so for example, here's block 8 of size 4 8 xored with 4 is 12 I'm flipping the lowest bit in the block number and eventually in my little example here I merge 8 with size 8, with 0 with size 8 one of these will come in last and I'll do the final merge and say oh look here's all the data I needed to merge, I'm done, I can start writing out the data if that is too complicated to turn into code I have two advices that's okay! take CS 373 473 then your brain will explode  learn about things like topological sort which I can't spell this morning and that's okay you'll remember this lecture with fondness, oh that was so easy compared to this topological sort is when you start to think about dependencies between actions and it has some relevance to this task in hand but you don't need, the other piece of advice is don't panic, you don't need to go this far to beat the naive TA's solution okay so let's turn ourselves back to some of these questions right some of these I will not address today, I'll talk about them on Friday, remember you are getting points for learning and not simply printing out the right answer let's do which scheduling algorithm describes the smallest average wait time? results in the smallest average wait time, the answer here is going to be preemptive shortest job first why? well you can construct examples where we might have a very long job and a whole sequence of small jobs and if you did that, the long job you want to put at the very end otherwise it holds up everybody else, it holds up all of the other processes waiting to run so how do we assure that the longest job is put at the very end? answer: shortest job first, yes! preemptive priority you would have to make sure the priorities are based on the length of the job which is not necessarily true the longest average response time, what's response time? well think about a webserver, a webserver might start giving you some packets, some results pretty early on but it might take several more milliseconds before you get the full response, we care about how early can we get the beginning, how long do we have to wait before we start to see some output? just the early output right so what's the longest average response time? first come first serve could give us a long average response time because the very last job submitted is not going to give us a response until finally all of the other processes have completed if we wanted a fast response time, what we should do is give each process access to the CPU as early as possible so what's an example of doing that? round robin yes! so round robin with a nice short preemptive, nice short quanta so that each gets to do some meaningful amount of work and start generating output okay minimizes response time round robin, waiting time shortest job first, total response time so this is response time of course all processes again round robin would be useful here how am i doing for time? right the other questions I will address on Friday I will mention I'll just finish with one important idea right psychological research has shown that if you want to learn stuff, if you want to remember stuff, the most important thing you can do is remember stuff what do we mean by that? is use your long term memory? how do i do that? easy start with a blank piece of paper, write down everything you know about every topic inside CS241 tomorrow, come back to the same piece of paper and write down more, do not use your notes, just write down more if you vaguely remember something put some question marks and some helpful hints the third day, do the same again the fourth day give up and yeah use your notes but you will discover that in trying to remember things, in actually exercising your brain stuff we start to come out of it in drips and drabs at first but it will actually ensure that you have a long term understanding of this material and with that have a wonderful week I'll see you on Friday!